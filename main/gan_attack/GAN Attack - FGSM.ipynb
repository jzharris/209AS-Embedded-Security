{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack attempt, using a cGAN to train D and a second GAN, uGAN, to refine D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second attempt at training the GAN D/G to provide **valid** and **representable** data from unknown classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF 2.1.0\n",
      "Keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution() # default for TF 2.0\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "from tensorflow import keras  # Import the tf version of keras.\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, \\\n",
    "                                    LeakyReLU, Conv2DTranspose, Reshape\n",
    "# import keras.backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "print('TF', tf.__version__)\n",
    "print('Keras', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import pickle\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "\n",
    "import os.path\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility \n",
    "# np.random.seed(0)\n",
    "# tf.random.set_seed(0)\n",
    "\n",
    "# Enlargen plots\n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EASY_MODE: if True, Split Learning NN is used as the Discriminator in the GAN. This is good for testing, but\n",
    "# bypasses the black-box paradigm! Use with caution\n",
    "EASY_MODE = True\n",
    "\n",
    "# Black-box params (optimized for MNIST)\n",
    "depth = 9\n",
    "filters = 33\n",
    "dense = 110\n",
    "num_classes = 10\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "target_rows, target_cols = 28, 28    # governed by the chosen model\n",
    "input_shape = (target_rows, target_cols, 1)\n",
    "\n",
    "# Attack params:\n",
    "attack_params = {\n",
    "    'our_class': 0,                             # the label indices that we want to preserve (and the data we own)\n",
    "    'attacker_clients': 5,                      # attacker controls X number of clients and their data\n",
    "    'attack_classes': [1],                      # the label(s) we want to poison\n",
    "    'flip_to': [7],                             # must be len(attack_classes) - flips the target label ('1') to new class ('7')\n",
    "    'prime_trigger': 0.00, #0.11                # the D test accuracy that, after which, we will move on from priming\n",
    "    'prime_first_iteration': True,              # whether to always prime on the first iteration\n",
    "    'prime_by_ckpt': True,                      # whether to prime manually (False) or by loading a checkpoint file (True)\n",
    "    'attack_trigger': 0.8,                      # the D accuracy (wrt Black-box) that, after which, we will commence an attack\n",
    "    'd_refinement_batch_num': 1,                # number of batches to refine D with: G -> BB <-> D\n",
    "    'd_refinement_batch_size': 100,             # number of attack images in each refinement batch: G -> BB <-> D\n",
    "    'train_dataset': None,                      # attack dataset - fixed in the beginning by choosing the attacking clients\n",
    "                                                # - this is the only data we have access to throughout the training process\n",
    "    'attacks_per_epoch': 10,                    # how many times to attack per epoch\n",
    "    'prime_exit_trigger': 1.0,                  # how good D has to be on the current blackbox model to exit priming\n",
    "    'refine_exit_trigger': 1.0,                 # how good D has to be after refinement*\n",
    "    'train_bb_every_n_its': 7,                  # only train the BB model while querying if (it % train_bb_every_n_its == 0)\n",
    "    'cgan_query_every_n_its': 4,                # only query BB with cGAN every N iterations\n",
    "    'refine_using_ugan': True,                  # use the uGAN to generate images to refine D with via uG -> BB -> D\n",
    "    'accumulate_g_queries': True,               # whether to keep uGAN imgs every iteration, or to just use most recent (False)\n",
    "    'flush_g_queries_every_bb_train': True,     # whether to keep uGAN imgs after new BB is trained, or preserved them (False)\n",
    "}\n",
    "\n",
    "# Split Learning training params:\n",
    "split_training_params = {\n",
    "    'minibatch_size': None,                     # number of samples to operate on at one time\n",
    "                                                #  - can vary to optimize computing requirements\n",
    "                                                #  - if None, will evaluate the client's whole batch regardless of its size\n",
    "    'apply_gradients_after': 20,                # after averaging the gradients from X clients, we will apply them to the model\n",
    "    'epochs': 1,                                # number of epochs to train for\n",
    "    'shuffle_clients': True,                    # whether to shuffle the clients during training\n",
    "    'eval_batch_size': 256,                     # batch size when evaluating test set (not split by clients),\n",
    "    'train_dataset': None,                      # training set - indexed by client\n",
    "    'test_dataset': None,                       # testing set - not batched\n",
    "    'ckpt_folder': \"blackbox_checkpoint\",       # folder where to store the checkpoints\n",
    "    'batch_limit': None,                        # how many batches to train on, maximum, per epoch\n",
    "}\n",
    "\n",
    "# cGAN training params:\n",
    "cgan_training_params = {\n",
    "    'minibatch_size': split_training_params['minibatch_size'],\n",
    "    'batch_size': 256,                          # number of images to generate from cG at once\n",
    "    'noise_dim': 100,                           # noise vector for cG\n",
    "    'epochs': 25,                               # number of epochs to train cGAN\n",
    "    'use_blackbox': False,                      # if True, copies the Blackbox model into D (easy check)\n",
    "    'd_ckpt_folder': \"discriminator_checkpoint\",# folder where to store the d checkpoints\n",
    "    'bb_ckpt_folder': \"blackbox_checkpoint\",    # folder where the blackbox default ckpt is kept\n",
    "    'g_ckpt_folder': \"generator_checkpoint\",    # folder where to store the g checkpoints\n",
    "    'batches_per_epoch': 100,                   # number of batches to train on per epoch\n",
    "    'd_trigger': 0.98,                          # train D if g_accuracy is >= X\n",
    "    'g_trigger': 1.01,                          # train G if g_accuracy is < X\n",
    "    'loop_times': 0,                            # number of times to apply softmax -> onehot encoding\n",
    "    'uncertain_loop_times': 1,                  # number to use in the uncertain_loss used by D\n",
    "    'softmax_power': 2,                         # number used in softmax -> onehot encoding operation\n",
    "    'd_reset_percentage': 1.0,                  # reset D if the test d_accuracy dips below X% of the original accuracy\n",
    "    'early_stop_trigger': 4,                    # stop training early, if g_accuracy has not improved for X epochs\n",
    "    'stop_sensitivity': 0.05,                   # \"no improvement\" is when the g_accuracy has not moved more than X% from prev\n",
    "    'g_nudge_trigger': 3,                       # if \"no improvement\" for X epochs, turn on D for one turn\n",
    "    'g_nudge_probability': 0.20,                # probability of nudging this sample, if enabled\n",
    "    'd_priming_epoch_limit': 1000,              # number of epochs to stop at for priming\n",
    "    'd_refine_epoch_limit': 50,                 # number of epochs to stop at for refining D\n",
    "    'save_best_g': False,                       # whether to save the best G during training, or to just use the last one\n",
    "    'd_restore_after_nudge': True,              # whether to restore D back to normal at the end of the epoch if it was nudged\n",
    "    'reset_g_every_it': False,                  # whether to restore cG back to init at the end of Step 5 if not -> Step 6\n",
    "}\n",
    "\n",
    "# FGSM training params:\n",
    "fgsm_training_params = {\n",
    "    'epochs': 15\n",
    "}\n",
    "\n",
    "# uGAN training params:\n",
    "# ugan_training_params = {\n",
    "#     'minibatch_size': split_training_params['minibatch_size'],\n",
    "#     'is_conditional': True,                     # whether to use the cGAN or uGAN architecture\n",
    "#     'batch_size': 256,                          # number of images to generate from uG at once\n",
    "#     'noise_dim': 100,                           # noise vector for uG\n",
    "#     'epochs': 15,                               # number of epochs to train uGAN\n",
    "#     'd_ckpt_folder': \"discriminator_checkpoint\",# folder where to store the d checkpoints\n",
    "#     'bb_ckpt_folder': \"blackbox_checkpoint\",    # folder where the blackbox default ckpt is kept\n",
    "#     'g_ckpt_folder': \"generator_checkpoint\",    # folder where to store the g checkpoints\n",
    "#     'batches_per_epoch': 100,                   # number of batches to train on per epoch\n",
    "#     'loop_times': 0,                            # number of times to apply softmax -> onehot encoding\n",
    "#     'uncertain_loop_times': 1,                  # number to use in the uncertain_loss used by D\n",
    "#     'softmax_power': 2,                         # number used in softmax -> onehot encoding operation\n",
    "#     'early_stop_trigger': 4,                    # stop training early, if g_accuracy has not improved for X epochs\n",
    "#     'stop_sensitivity': 0.05,                   # \"no improvement\" is when the g_accuracy has not moved more than X% from prev\n",
    "#     'save_best_g': False,                       # whether to save the best G during training, or to just use the last one\n",
    "#     'reset_g_every_it': True,                   # whether to restore uG back to init at the end of Step 5 if not -> Step 6\n",
    "# }\n",
    "\n",
    "# Data parsing params\n",
    "clients_per_class = 100                         # number of clients per label. Each client only has access to one label\n",
    "                                                # - each unique class is divided into X number of subsets\n",
    "\n",
    "# Dataset params\n",
    "separated_folder = \"./separated_dataset\"\n",
    "os.makedirs(separated_folder, exist_ok=True)\n",
    "separated_train_path = os.path.join(separated_folder, \"train_separated.pkl\")\n",
    "separated_test_path = os.path.join(separated_folder, \"test_separated.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255    # range is [0, 1]\n",
    "x_test /= 255     # range is [0, 1]\n",
    "\n",
    "if target_rows != img_rows or target_cols != img_cols:\n",
    "    # resize x_train\n",
    "    x_train_resized = []\n",
    "    for x_ in x_train:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_train_resized.append(x_)\n",
    "    x_train = np.asarray(x_train_resized)\n",
    "\n",
    "    # resize x_test\n",
    "    x_test_resized = []\n",
    "    for x_ in x_test:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_test_resized.append(x_)\n",
    "    x_test = np.asarray(x_test_resized)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "y: (60000, 10) (10000, 10)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "print('X:', x_train.shape, x_test.shape)\n",
    "print('y:', y_train.shape, y_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "BUFFER_SIZE = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training seperation\n",
      "loaded testing seperation\n"
     ]
    }
   ],
   "source": [
    "# Separating the data by class\n",
    "if os.path.isfile(separated_train_path):\n",
    "    with open(separated_train_path, 'rb') as f:\n",
    "        x_train_dict, y_train_dict = pickle.load(f)\n",
    "        print('loaded training seperation')\n",
    "else:\n",
    "    x_train_dict = {}\n",
    "    y_train_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_train_dict[target_label] = []\n",
    "        y_train_dict[target_label] = []\n",
    "        for i, label in enumerate(y_train):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_train_dict[target_label].append(x_train[i])\n",
    "                y_train_dict[target_label].append(y_train[i])\n",
    "    \n",
    "    with open(separated_train_path, 'wb') as f:\n",
    "        pickle.dump([x_train_dict, y_train_dict], f)\n",
    "        print('saved training seperation')\n",
    "\n",
    "if os.path.isfile(separated_test_path):\n",
    "    with open(separated_test_path, 'rb') as f:\n",
    "        x_test_dict, y_test_dict = pickle.load(f)\n",
    "        print('loaded testing seperation')\n",
    "else:\n",
    "    x_test_dict = {}\n",
    "    y_test_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_test_dict[target_label] = []\n",
    "        y_test_dict[target_label] = []\n",
    "        for i, label in enumerate(y_test):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_test_dict[target_label].append(x_test[i])\n",
    "                y_test_dict[target_label].append(y_test[i])\n",
    "\n",
    "    with open(separated_test_path, 'wb') as f:\n",
    "        pickle.dump([x_test_dict, y_test_dict], f)\n",
    "        print('saved testing seperation')\n",
    "    \n",
    "# convert dicts to lists\n",
    "x_train_seperated = [np.array(x_train_dict[i]) for i in range(10)]\n",
    "y_train_seperated = [np.array(y_train_dict[i]) for i in range(10)]\n",
    "\n",
    "x_test_seperated = [np.array(x_test_dict[i]) for i in range(10)]\n",
    "y_test_seperated = [np.array(y_test_dict[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "plt.figure()\n",
    "plt.title('Data separation per class')\n",
    "plt.bar(x_train_dict.keys(), [len(v) for v in x_train_dict.values()], color='tab:blue')\n",
    "plt.bar(x_test_dict.keys(), [len(v) for v in x_test_dict.values()], color='orange', width=0.6)\n",
    "plt.legend(['x_train', 'x_test'], loc='center right', framealpha=1.0)\n",
    "plt.xlabel('class label')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data into batches for clients to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients per class:  99.6 ~= 100\n",
      "Total number of clients: 996\n",
      "Average batch size: 60.6\n"
     ]
    }
   ],
   "source": [
    "# Separate the data into a long list of batches, each batch representing a client training with that batch of images.\n",
    "# After each batch, a new client will have the opportunity to train their batch of images.\n",
    "# Batches are shuffled to simulate many clients training the model at once.\n",
    "\n",
    "client_counts = {}\n",
    "batch_sizes = {}\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "def ceil(a,b):\n",
    "    return -(-a//b)\n",
    "\n",
    "for class_idx in range(len(x_train_seperated)):\n",
    "    # Get batches from class data:\n",
    "    n_samples_per_class = len(x_train_seperated[class_idx])\n",
    "    samples_per_client = n_samples_per_class / clients_per_class\n",
    "    better_batch_size = int(math.ceil(samples_per_client))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(ceil(n_samples_per_class, better_batch_size)):\n",
    "        x_batches.append((class_idx, x_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        y_batches.append((class_idx, y_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        count += 1\n",
    "    client_counts[class_idx] = count\n",
    "    batch_sizes[class_idx] = better_batch_size\n",
    "        \n",
    "# double check that the clients_per_class is upheld per class\n",
    "# (blue bars should be uniform, orange should change according to class):\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('class label')\n",
    "ax1.set_ylabel('client count', color=color)\n",
    "plt.bar(client_counts.keys(), [v for v in client_counts.values()], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'orange'\n",
    "ax2.set_ylabel('batch size', color=color)  # we already handled the x-label with ax1\n",
    "plt.bar(batch_sizes.keys(), [v for v in batch_sizes.values()], color=color, width=0.6)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylim(0, np.mean([v for v in batch_sizes.values()])*2)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()\n",
    "\n",
    "print('Clients per class:  {} ~= {}'.format(np.mean([v for v in client_counts.values()]), clients_per_class))\n",
    "print('Total number of clients: {}'.format(np.sum([v for v in client_counts.values()])))\n",
    "print('Average batch size: {}'.format(np.mean([v for v in batch_sizes.values()])))\n",
    "\n",
    "split_batch_size = np.floor(np.mean([v for v in batch_sizes.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the attacker's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 clients to choose from:\n",
      "Classes of attack clients: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Choosing the following clients as the attackers:\n",
      "[ 4 88 91 10 69]\n"
     ]
    }
   ],
   "source": [
    "x_batches_filtered_i = [i for i, batch in enumerate(x_batches) if batch[0] == attack_params['our_class']]\n",
    "y_batches_filtered_i = [i for i, batch in enumerate(y_batches) if batch[0] == attack_params['our_class']]\n",
    "assert x_batches_filtered_i == y_batches_filtered_i\n",
    "\n",
    "x_batches_filtered = list(map(x_batches.__getitem__, x_batches_filtered_i))\n",
    "y_batches_filtered = list(map(y_batches.__getitem__, y_batches_filtered_i))\n",
    "\n",
    "print('{} clients to choose from:'.format(len(x_batches_filtered)))\n",
    "print('Classes of attack clients:', [f[0] for f in x_batches_filtered])\n",
    "print()\n",
    "\n",
    "attack_clients = np.random.choice(len(x_batches_filtered), attack_params['attacker_clients'], replace=False)\n",
    "print('Choosing the following clients as the attackers:\\n{}'.format(attack_clients))\n",
    "x_attack_batches = list(map(x_batches_filtered.__getitem__, attack_clients))\n",
    "y_attack_batches = list(map(y_batches_filtered.__getitem__, attack_clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset length: 996 996\n",
      "New dataset length:      991 991\n"
     ]
    }
   ],
   "source": [
    "# remove the attackers from the original training dataset\n",
    "# BREAKS THE ORIGINAL X_BATCHES AND Y_BATCHES!\n",
    "print('Original dataset length:', len(x_batches), len(y_batches))\n",
    "\n",
    "x_attackers_i = list(map(x_batches_filtered_i.__getitem__, attack_clients))\n",
    "y_attackers_i = list(map(y_batches_filtered_i.__getitem__, attack_clients))\n",
    "\n",
    "x_batches = [batch for i, batch in enumerate(x_batches) if i not in x_attackers_i]\n",
    "y_batches = [batch for i, batch in enumerate(y_batches) if i not in y_attackers_i]\n",
    "\n",
    "print('New dataset length:     ', len(x_batches), len(y_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data for Split Learning\n",
    "split_train_dataset = (x_batches, y_batches)\n",
    "split_test_dataset = (x_test, y_test)\n",
    "\n",
    "# place into train params:\n",
    "split_training_params['train_dataset'] = split_train_dataset\n",
    "split_training_params['test_dataset'] = split_test_dataset\n",
    "\n",
    "# Build attack dataset\n",
    "attack_train_dataset = (x_attack_batches, y_attack_batches)\n",
    "attack_params['train_dataset'] = attack_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0; Max: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Show min and max of the dataset (ensure you are using the right normalization)\n",
    "min_ = np.inf\n",
    "max_ = -np.inf\n",
    "for batch in x_batches:\n",
    "    min__ = np.min(batch[1])\n",
    "    max__ = np.max(batch[1])\n",
    "    min_ = min(min_, min__)\n",
    "    max_ = max(max_, max__)\n",
    "print('Min: {}; Max: {}'.format(min_, max_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "\n",
    "def start_piece_(input_shape, filters=4):\n",
    "    assert filters >= 1\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def blackbox_piece_(model, depth=1, filters=4):\n",
    "    assert depth >= 1\n",
    "    assert filters >= 1\n",
    "    \n",
    "    # for now, we will just give the black-box all the CNN layers\n",
    "    for i in range(depth-1):\n",
    "        model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def approximator_piece_(model, depth=1, filters=4):\n",
    "    assert depth >= 1\n",
    "    assert filters >= 1\n",
    "    \n",
    "    # for now, we will just give the approximator_piece piece the same complexity as bb (since we have shown it doens't matter)\n",
    "    model = blackbox_piece_(model, depth, filters)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def end_piece_(model, dense_breadth=128, num_classes=10):\n",
    "    assert dense_breadth >= num_classes\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_breadth, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the params are acceptable:\n",
    "assert depth >= 1\n",
    "assert filters >= 1\n",
    "assert dense >= num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitLearning:\n",
    "    \n",
    "    def __init__(self, split_training_params):\n",
    "        self.minibatch_size = split_training_params['minibatch_size']\n",
    "        self.batches_per_train_step = split_training_params['apply_gradients_after']\n",
    "        self.eval_batch_size = split_training_params['eval_batch_size']\n",
    "        self.shuffle_clients = split_training_params['shuffle_clients']\n",
    "        self.ckpt_folder = split_training_params['ckpt_folder']\n",
    "        \n",
    "        # define the NN model\n",
    "        self.model = self.blackbox_model()\n",
    "        \n",
    "        # define loss function\n",
    "        self.cross_entropy = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define metrics\n",
    "        self.acc_train_avg = None\n",
    "        self.loss_train_avg = None\n",
    "        \n",
    "        # setup checkpointing\n",
    "        self.init_ckpt()\n",
    "        \n",
    "        # setup ops\n",
    "        self.setup_ops()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Black-box model\n",
    "        \n",
    "    def blackbox_model(self):\n",
    "        model = start_piece_(input_shape, filters)\n",
    "        model = blackbox_piece_(model, depth, filters)\n",
    "        model = end_piece_(model, dense, num_classes)\n",
    "        return model\n",
    "    \n",
    "    def model_loss(self, y_true, y_pred):\n",
    "        return self.cross_entropy(y_true, y_pred)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Train\n",
    "    \n",
    "    def setup_ops(self):\n",
    "        # INSPIRED BY: https://stackoverflow.com/questions/42156957/how-to-update-model-parameters-with-accumulated-gradients\n",
    "        # https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\n",
    "        \n",
    "        self.tvs = self.model.trainable_variables\n",
    "        self.accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in self.tvs]\n",
    "        self.accum_counter = tf.Variable(0.0, trainable=False)\n",
    "    \n",
    "    def train(self, datasets, iteration, g_dataset=None, batch_limit=None):\n",
    "        # setup checkpointing\n",
    "        self.setup_ckpt(iteration)\n",
    "        \n",
    "        # setup bb_dataset (stores labels if g_dataset is passed in)\n",
    "        bb_dataset = []\n",
    "        \n",
    "        g_dataset_acc = tf.keras.metrics.Accuracy()\n",
    "        \n",
    "        # initialize the metrics each new epoch\n",
    "        if self.acc_train_avg is not None:\n",
    "            del self.acc_train_avg\n",
    "        if self.loss_train_avg is not None:\n",
    "            del self.loss_train_avg\n",
    "        self.acc_train_avg = tf.keras.metrics.Accuracy()\n",
    "        self.loss_train_avg = tf.keras.metrics.Mean()\n",
    "        \n",
    "        # append all datasets together for training:\n",
    "        x_batches = []\n",
    "        y_batches = []\n",
    "        for dataset in datasets:\n",
    "            x_batches_, y_batches_ = dataset\n",
    "            x_batches = x_batches + x_batches_\n",
    "            y_batches = y_batches + y_batches_\n",
    "        # if g_dataset is not None, add those batches to the end:\n",
    "        if g_dataset is not None:\n",
    "            g_x_batches, g_y_batches = g_dataset\n",
    "            g_batch_idxs = list(range(len(x_batches), len(x_batches)+len(g_x_batches)))\n",
    "            x_batches = x_batches + g_x_batches\n",
    "            y_batches = y_batches + g_y_batches\n",
    "        else:\n",
    "            g_batch_idxs = []\n",
    "            \n",
    "        # setup progress bar\n",
    "        total_batches = batch_limit if batch_limit is not None and batch_limit < len(x_batches) else len(x_batches)\n",
    "        pbar = tqdm_notebook(total=total_batches)\n",
    "        \n",
    "        batch_idxs = list(range(len(x_batches)))\n",
    "        if self.shuffle_clients:\n",
    "            # shuffle the batches each time\n",
    "            random.shuffle(batch_idxs)\n",
    "            \n",
    "        for i, batch_idx in enumerate(batch_idxs):\n",
    "            x_batch = x_batches[batch_idx][1]\n",
    "            y_batch = y_batches[batch_idx][1]\n",
    "            \n",
    "            if batch_idx in g_batch_idxs:\n",
    "                # this is a g_x_batch! don't apply gradients, but store the prediction\n",
    "                logit_batch = self.pred_step(x_batch)\n",
    "                g_dataset_acc(tf.argmax(y_batch, 1), tf.argmax(logit_batch, 1))\n",
    "                bb_dataset.append((x_batch, y_batch, logit_batch))\n",
    "            else:\n",
    "                self.train_step(i, x_batch, y_batch, len(batch_idxs) - 1)\n",
    "            pbar.update(1)\n",
    "            pbar.set_description('train_acc={:.2f}%'.format(self.acc_train_avg.result()*100))\n",
    "            \n",
    "            if batch_limit is not None and i-1 >= batch_limit:\n",
    "                break\n",
    "        pbar.close()\n",
    "        print('train_acc={:.4f}%'.format(self.acc_train_avg.result()*100))\n",
    "        print('accuracy of blackbox on G dataset: {:.4f}%'.format(g_dataset_acc.result()*100))\n",
    "        \n",
    "        # save checkpoints\n",
    "        self.checkpoint()\n",
    "        \n",
    "        return bb_dataset\n",
    "        \n",
    "    def pred_step(self, x_batch):\n",
    "        logit_batch = []\n",
    "        # Iterate over the client's batch in minibatches:\n",
    "        j = 0\n",
    "        while(j < len(x_batch)):\n",
    "            if self.minibatch_size is None:\n",
    "                # use whole batch (no minibatch)\n",
    "                x_minibatch = x_batch\n",
    "            else:\n",
    "                x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "\n",
    "            logits = self.model(x_minibatch, training=True) # TODO: should this be False?\n",
    "            logit_batch = logit_batch + list(logits.numpy())\n",
    "\n",
    "            if self.minibatch_size is None:\n",
    "                break\n",
    "            else:\n",
    "                j += self.minibatch_size\n",
    "                \n",
    "        return logit_batch\n",
    "        \n",
    "    def train_step(self, i, x_batch, y_batch, limit):\n",
    "        # Iterate over the client's batch in minibatches:\n",
    "        j = 0\n",
    "        while(j < len(x_batch)):\n",
    "            if self.minibatch_size is None:\n",
    "                # use whole batch (no minibatch)\n",
    "                x_minibatch = x_batch\n",
    "                y_minibatch = y_batch\n",
    "            else:\n",
    "                x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                y_minibatch = y_batch[j:(j+self.minibatch_size)]\n",
    "\n",
    "            # run the gradients\n",
    "            loss_value, grads = self.grad(x_minibatch, y_minibatch)\n",
    "\n",
    "            # accumulate them\n",
    "            self.accumulate_grads(grads)\n",
    "\n",
    "            if self.minibatch_size is None:\n",
    "                break\n",
    "            else:\n",
    "                j += self.minibatch_size\n",
    "\n",
    "        # perform a train step every batches_per_train_step number of batches:\n",
    "        if (i > 0 and i % self.batches_per_train_step == 0) or i == limit:\n",
    "            # Run the train_step ops to update the weights based on our accumulated gradients\n",
    "            self.optimize()\n",
    "            self.zero_out()\n",
    "    \n",
    "    def grad(self, inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(inputs, training=True)\n",
    "            loss_value = self.model_loss(targets, logits)\n",
    "            \n",
    "        # evaluate accuracy and append acc and loss to arrays\n",
    "        self.acc_train_avg(tf.argmax(targets, 1), tf.argmax(logits, 1))\n",
    "        self.loss_train_avg(loss_value)\n",
    "        \n",
    "        return loss_value, tape.gradient(loss_value, self.model.trainable_variables)\n",
    "    \n",
    "    def accumulate_grads(self, grads):\n",
    "        # add to accum_vars the new gradients\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.accum_vars[i].assign_add(grad)\n",
    "        # increment the counter by 1\n",
    "        self.accum_counter.assign_add(1.0)\n",
    "        \n",
    "    def optimize(self):\n",
    "        # apply the gradients in accum_vars, dividing by the number in accum_counter\n",
    "        self.optimizer.apply_gradients(\n",
    "            [(accum_var / self.accum_counter, tv) \\\n",
    "                for (accum_var, tv) in zip(self.accum_vars, self.model.trainable_variables)]\n",
    "        )\n",
    "    \n",
    "    def zero_out(self):\n",
    "        # reset accum_vars and accum_counter back to 0\n",
    "        for i, tv in enumerate(self.accum_vars):\n",
    "            self.accum_vars[i].assign(tf.zeros_like(tv))\n",
    "        self.accum_counter = tf.Variable(0.0, trainable=False)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = None\n",
    "        self.internal_iteration = None\n",
    "        self.iteration_offset = 0\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        # setup fresh checkpointer every new iteration\n",
    "        if self.internal_iteration is None or iteration != self.internal_iteration - self.iteration_offset:\n",
    "            ckpt_save_folder = os.path.join('checkpoints', 'it_{}'.format(iteration + self.iteration_offset), self.ckpt_folder)\n",
    "            os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "        \n",
    "            if self.ckpt is not None:\n",
    "                del self.ckpt\n",
    "            if self.manager is not None:\n",
    "                del self.manager\n",
    "\n",
    "            self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "            self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "            self.internal_iteration = iteration + self.iteration_offset\n",
    "    \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved checkpoint: {}\".format(save_path))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        parent_folder = os.path.join('checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                self.iteration_offset = largest_it\n",
    "                print('Restored latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found, starting with a fresh network')\n",
    "        else:\n",
    "            if load_default:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    self.iteration_offset = it_restore\n",
    "                print('Restored latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "        \n",
    "    def evaluate(self, dataset):\n",
    "        '''\n",
    "        NOTE: dataset here is tailored for standard 'test' dataset provided by Keras\n",
    "        '''\n",
    "        \n",
    "        x, y = dataset\n",
    "        \n",
    "        acc_test_avg = tf.keras.metrics.Accuracy()\n",
    "        loss_test_avg = tf.keras.metrics.Mean()\n",
    "        for i in range(0, len(x), self.eval_batch_size):\n",
    "            # get batch\n",
    "            x_batch = x[i:i+self.eval_batch_size]\n",
    "            y_batch = y[i:i+self.eval_batch_size]\n",
    "            \n",
    "            # evaluate\n",
    "            logits = self.model(x_batch, training=False)\n",
    "            acc_test_avg(tf.argmax(y_batch, 1), tf.argmax(logits, 1))\n",
    "            loss_test_avg(self.model_loss(y_batch, logits))\n",
    "        \n",
    "        if self.acc_train_avg is not None and self.loss_train_avg is not None:\n",
    "            print('Train Accuracy: {:.3f} | Loss: {:.3f}'.format(self.acc_train_avg.result(), self.loss_train_avg.result()))\n",
    "        print('Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test_avg.result(), loss_test_avg.result()))\n",
    "        print()\n",
    "        \n",
    "    def predict(self, dataset, return_tensors=True):\n",
    "        '''\n",
    "        Returns a list of label batches of each client that was in the dataset\n",
    "        '''\n",
    "        \n",
    "        x, _ = dataset\n",
    "        labels = []\n",
    "        \n",
    "        for i, client_x in enumerate(x):\n",
    "            x_batch = client_x[1]\n",
    "            label_batch = []\n",
    "            \n",
    "            # run through every minibatch:\n",
    "            j = 0\n",
    "            while(j < len(x_batch)):\n",
    "                if self.minibatch_size is None:\n",
    "                    # use whole batch (no minibatch)\n",
    "                    x_minibatch = x_batch\n",
    "                else:\n",
    "                    x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                    \n",
    "                # evaluate\n",
    "                preds = self.model(x_batch, training=False)\n",
    "                if not return_tensors:\n",
    "                    preds = tf.nn.softmax(preds)\n",
    "                    preds = tf.argmax(preds, axis=1)\n",
    "                    \n",
    "                label_batch = label_batch + list(preds.numpy())\n",
    "                \n",
    "                if self.minibatch_size is None:\n",
    "                    break\n",
    "                else:\n",
    "                    j += self.minibatch_size\n",
    "            \n",
    "            # add to list\n",
    "            labels.append(label_batch)\n",
    "            \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D:\n",
    "    '''\n",
    "    The Discriminator portion of the GAN. Accepts a network, otherwise creates a new model.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, discriminator=None):\n",
    "        \n",
    "        self.ckpt_folder = gan_training_params['d_ckpt_folder']\n",
    "        self.bb_ckpt_folder = gan_training_params['bb_ckpt_folder']\n",
    "        self.loop_times = gan_training_params['loop_times']\n",
    "        self.softmax_power = gan_training_params['softmax_power']\n",
    "        self.minibatch_size = gan_training_params['minibatch_size']\n",
    "        \n",
    "        # make FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "        if discriminator is not None:\n",
    "            self.model = discriminator\n",
    "        else:\n",
    "            self.model = self.discriminator_model()\n",
    "            \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define entropies\n",
    "        self.cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        self.bin_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            \n",
    "        # setup checkpointing\n",
    "        self.ckpt = None\n",
    "        self.manager = None\n",
    "        \n",
    "        # save the initial weights\n",
    "        if discriminator is None:\n",
    "            self.save_initial_weights()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Discriminator model\n",
    "    \n",
    "    def discriminator_model(self):\n",
    "        model = start_piece_(input_shape, filters)\n",
    "        model = approximator_piece_(model, depth, filters)\n",
    "        model = end_piece_(model, dense, num_classes)\n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Loss\n",
    "    \n",
    "    def loss(self, fake_discrimination, labels):\n",
    "        matches = self.matches_labels(fake_discrimination, labels, loop_times=self.loop_times)\n",
    "        # we want the discriminator to NOT be fooled by these fake images\n",
    "        cross_entropy = self.bin_cross_entropy(tf.zeros_like(matches), matches)\n",
    "        return cross_entropy\n",
    "    \n",
    "    def entropy(self, y_true, y_pred):\n",
    "        return self.cat_cross_entropy(y_true, y_pred)\n",
    "        \n",
    "    def matches_labels(self, fake_output, labels, loop_times=0):\n",
    "        '''\n",
    "        Only works if the Discriminator is already trained on real images!!\n",
    "        1. Performs a softmax -> onehot conversion (differentiable approx.)\n",
    "        2. Multiplies this by the onehot version of the onehot attack label\n",
    "        3. Sums to reduce dimension\n",
    "        \n",
    "        - if the sum is close to 1, the nn thinks that the image is a part of the attack class\n",
    "        - if the sum is close to 0, the nn thinks that the image is not of the attack class\n",
    "        - the sum should not be in between, due to the onehot conversion we perform in step 1\n",
    "        '''\n",
    "        # 1.\n",
    "        my_power = self.softmax_power\n",
    "        for i in range(loop_times):\n",
    "            fake_output = self.soft_onehot(fake_output)\n",
    "        \n",
    "        # 2.\n",
    "        matches = tf.math.multiply(fake_output, labels)\n",
    "        \n",
    "        # 3.\n",
    "        reduced = tf.math.reduce_sum(matches, axis=-1)\n",
    "        \n",
    "        return reduced\n",
    "        \n",
    "    def soft_onehot(self, softmax, my_power=8):\n",
    "        '''\n",
    "        Shown to not really work... vanishing gradients problem\n",
    "        '''\n",
    "        soft_extreme = softmax ** my_power\n",
    "        norm = tf.reduce_sum(soft_extreme, axis=-1)\n",
    "        almost_onehot = tf.math.divide(soft_extreme, tf.reshape(norm, (-1, 1)))\n",
    "        return almost_onehot\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        ckpt_save_folder = os.path.join('checkpoints', 'it_{}'.format(iteration), self.ckpt_folder)\n",
    "        os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "        if self.ckpt is not None:\n",
    "            del self.ckpt\n",
    "        if self.manager is not None:\n",
    "            del self.manager\n",
    "\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "        \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved D checkpoint: {}\".format(save_path))\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Load/save weights\n",
    "    \n",
    "    def save_initial_weights(self):\n",
    "        print('saving initial weights for D')\n",
    "        init_folder = os.path.join('checkpoints', 'init', self.ckpt_folder)\n",
    "        os.makedirs(init_folder, exist_ok=True)\n",
    "        self.model.save_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def load_initial_weights(self):\n",
    "        print('loading initial weights for D')\n",
    "        init_folder = os.path.join('checkpoints', 'init', self.ckpt_folder)\n",
    "        self.model.load_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False, use_blackbox=False):\n",
    "        iteration_offset = 0\n",
    "        parent_folder = os.path.join('checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                iteration_offset = largest_it\n",
    "                print('Restored D to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found for D, starting with a fresh network')\n",
    "        else:\n",
    "            if load_default:\n",
    "                if use_blackbox:\n",
    "                    checkpoint_directory = os.path.join(parent_folder, 'default', self.bb_ckpt_folder)\n",
    "                else:\n",
    "                    checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    iteration_offset = it_restore\n",
    "                print('Restored D to checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        return iteration_offset\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluation\n",
    "\n",
    "    def discriminate(self, generated_images, training=True):\n",
    "        return self.model(generated_images, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G:\n",
    "    '''\n",
    "    The Generator portion of the GAN. Generates images given a conditional label.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, is_conditional=True, identifier=None):\n",
    "        self.is_conditional = is_conditional\n",
    "        self.identifier = identifier\n",
    "        \n",
    "        self.ckpt_folder = self.g_identifier() + gan_training_params['g_ckpt_folder']\n",
    "        self.noise_dim = gan_training_params['noise_dim']\n",
    "        self.uncertain_loop_times = gan_training_params['uncertain_loop_times']\n",
    "        self.softmax_power = gan_training_params['softmax_power']\n",
    "        \n",
    "        # make FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "        self.input_shapes = []\n",
    "        if is_conditional:\n",
    "            self.model = self.c_generator_model()\n",
    "        else:\n",
    "            self.model = self.u_generator_model()\n",
    "            \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define entropies\n",
    "        self.cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        self.bin_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            \n",
    "        # setup checkpointing\n",
    "        self.ckpt = None\n",
    "        self.manager = None\n",
    "        \n",
    "        # save initial weights\n",
    "        self.save_initial_weights()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Generator model\n",
    "    \n",
    "    def g_identifier(self):\n",
    "        return self.identifier if self.identifier is not None else ''\n",
    "    \n",
    "    def c_generator_model(self):\n",
    "        '''\n",
    "        CONDITIONAL version of G\n",
    "        '''\n",
    "        ACTIVATION = keras.layers.Activation(\"tanh\")\n",
    "        \n",
    "        # Prepare noise input\n",
    "        self.input_shapes.append((self.noise_dim,))\n",
    "        input_z = keras.layers.Input((self.noise_dim,))\n",
    "        dense_z_1 = keras.layers.Dense(1024)(input_z)\n",
    "        act_z_1 = ACTIVATION(dense_z_1)\n",
    "        dense_z_2 = keras.layers.Dense(128 * 7 * 7)(act_z_1)\n",
    "        bn_z_1 = keras.layers.BatchNormalization()(dense_z_2)\n",
    "        reshape_z = keras.layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,))(bn_z_1)\n",
    "\n",
    "        # Prepare Conditional (label) input\n",
    "        self.input_shapes.append((num_classes,))\n",
    "        input_c = keras.layers.Input((num_classes,))\n",
    "        dense_c_1 = keras.layers.Dense(1024)(input_c)\n",
    "        act_c_1 = ACTIVATION(dense_c_1)\n",
    "        dense_c_2 = keras.layers.Dense(128 * 7 * 7)(act_c_1)\n",
    "        bn_c_1 = keras.layers.BatchNormalization()(dense_c_2)\n",
    "        reshape_c = keras.layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,))(bn_c_1)\n",
    "\n",
    "        # Combine input source\n",
    "        concat_z_c = keras.layers.Concatenate()([reshape_z, reshape_c])\n",
    "\n",
    "        # Image generation with the concatenated inputs\n",
    "        up_1 = keras.layers.UpSampling2D(size=(2, 2))(concat_z_c)\n",
    "        conv_1 = keras.layers.Conv2D(64, (5, 5), padding='same')(up_1)\n",
    "        act_1 = ACTIVATION(conv_1)\n",
    "        up_2 = keras.layers.UpSampling2D(size=(2, 2))(act_1)\n",
    "        #\n",
    "        drop_1 = keras.layers.Dropout(0.1)(up_2)\n",
    "        #\n",
    "        conv_2 = keras.layers.Conv2D(1, (5, 5), padding='same')(drop_1)\n",
    "        act_2 = keras.layers.Activation(\"tanh\")(conv_2)\n",
    "        model = keras.models.Model(inputs=[input_z, input_c], outputs=act_2)\n",
    "        return model\n",
    "    \n",
    "    def u_generator_model(self):\n",
    "        '''\n",
    "        NORMAL version of G\n",
    "        '''\n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        self.input_shapes.append((self.noise_dim,))\n",
    "        model.add(Dense(7*7*256, use_bias=False, input_shape=(self.noise_dim,)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Reshape((7, 7, 256)))\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "\n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Loss\n",
    "    \n",
    "    def loss(self, fake_discrimination, labels):\n",
    "        # we want the discriminator to be fooled by these fake images\n",
    "        cross_entropy = self.cat_cross_entropy(fake_discrimination, labels)\n",
    "        return cross_entropy\n",
    "    \n",
    "    def u_loss(self, fake_discrimination):\n",
    "        '''\n",
    "        Loss that measures how close the output is to having a single peak.\n",
    "        In other words we are measuring how certain the model thinks it is\n",
    "        correct, regardless of the answer\n",
    "        1. Performs a softmax -> onehot conversion (differentiable approx.)\n",
    "        2. Compare to the original output -- return this cat crossentropy\n",
    "        '''\n",
    "        fake_output = tf.identity(fake_discrimination)\n",
    "        \n",
    "        # 1.\n",
    "        my_power = self.softmax_power\n",
    "        for i in range(self.uncertain_loop_times):\n",
    "            fake_output = self.soft_onehot(fake_output)\n",
    "            \n",
    "        # 2.\n",
    "        return self.cat_cross_entropy(fake_output, fake_discrimination)\n",
    "        \n",
    "    def soft_onehot(self, softmax, my_power=8):\n",
    "        '''\n",
    "        Shown to not really work... vanishing gradients problem\n",
    "        '''\n",
    "        soft_extreme = softmax ** my_power\n",
    "        norm = tf.reduce_sum(soft_extreme, axis=-1)\n",
    "        almost_onehot = tf.math.divide(soft_extreme, tf.reshape(norm, (-1, 1)))\n",
    "        return almost_onehot\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        ckpt_save_folder = os.path.join('checkpoints', 'it_{}'.format(iteration), self.ckpt_folder)\n",
    "        os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "        if self.ckpt is not None:\n",
    "            del self.ckpt\n",
    "        if self.manager is not None:\n",
    "            del self.manager\n",
    "\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "        \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved {}G checkpoint: {}\".format(self.g_identifier(), save_path))\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Load/save weights\n",
    "    \n",
    "    def save_initial_weights(self):\n",
    "        print('saving initial weights for {}G'.format(self.g_identifier()))\n",
    "        init_folder = os.path.join('checkpoints', 'init', self.ckpt_folder)\n",
    "        os.makedirs(init_folder, exist_ok=True)\n",
    "        self.model.save_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def load_initial_weights(self):\n",
    "        print('loading initial weights for {}G'.format(self.g_identifier()))\n",
    "        init_folder = os.path.join('checkpoints', 'init', self.ckpt_folder)\n",
    "        self.model.load_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        iteration_offset = 0\n",
    "        parent_folder = os.path.join('checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                iteration_offset = largest_it\n",
    "                print('Restored {}G to latest checkpoint from {}'.format(self.g_identifier(), checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found for {}G, starting with a fresh network'.format(self.g_identifier()))\n",
    "        else:\n",
    "            if load_default:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    iteration_offset = it_restore\n",
    "                print('Restored {}G to checkpoint from {}'.format(self.g_identifier(), checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        return iteration_offset\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluation\n",
    "        \n",
    "    def generate(self, inputs, training=True):\n",
    "        generated_images = self.model(inputs, training=training)\n",
    "        return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cGAN:\n",
    "    '''\n",
    "    The cGAN. Trains the G and D.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, discriminator_model=None):\n",
    "        self.is_conditional = True\n",
    "        self.noise_dim = gan_training_params['noise_dim']\n",
    "        self.batch_size = gan_training_params['batch_size']\n",
    "        self.batches_per_epoch = gan_training_params['batches_per_epoch']\n",
    "        self.d_trigger = gan_training_params['d_trigger']\n",
    "        self.g_trigger = gan_training_params['g_trigger']\n",
    "        self.early_stop_trigger = gan_training_params['early_stop_trigger']\n",
    "        self.stop_sensitivity = gan_training_params['stop_sensitivity']\n",
    "        self.g_nudge_trigger = gan_training_params['g_nudge_trigger']\n",
    "        self.g_nudge_probability = gan_training_params['g_nudge_probability']\n",
    "        self.minibatch_size = gan_training_params['minibatch_size']\n",
    "        self.d_restore_after_nudge = gan_training_params['d_restore_after_nudge']\n",
    "\n",
    "        # define the D and G models\n",
    "        self.g = G(gan_training_params, is_conditional=self.is_conditional, identifier='c_')\n",
    "        \n",
    "        self.d = D(gan_training_params, discriminator_model)\n",
    "            \n",
    "        # stack G on top of D\n",
    "        self.gd = self.stack_models()\n",
    "        print(self.gd.summary())\n",
    "        \n",
    "        # define losses\n",
    "        self.mse = tf.keras.losses.MeanSquaredError()\n",
    "        \n",
    "        # define metrics\n",
    "        self.gen_loss_train_avg = None\n",
    "        self.gen_acc_train_avg = None\n",
    "        self.disc_loss_train_avg = None\n",
    "        self.disc_loss_refine_avg = None\n",
    "        \n",
    "        # define plotting metrics\n",
    "        self.gen_loss_train_arr = []\n",
    "        self.gen_acc_train_arr = []\n",
    "        self.disc_loss_train_arr = []\n",
    "        self.disc_acc_test_arr = []\n",
    "        \n",
    "        # seed for image generation\n",
    "        num_examples_to_generate = 16\n",
    "        self.seed = tf.random.normal([num_examples_to_generate, self.noise_dim])\n",
    "        \n",
    "        # labels for image generation\n",
    "        label_pattern = [i % (num_classes) for i in range(num_examples_to_generate)]\n",
    "        self.eval_labels = tf.one_hot(label_pattern, num_classes, dtype=tf.dtypes.float32)\n",
    "        \n",
    "        # setup checkpointing\n",
    "        self.internal_iteration = None\n",
    "        self.iteration_offset = 0\n",
    "        self.save_ckpts = True\n",
    "        \n",
    "        # initialize d and g checkpoints\n",
    "        self.d.init_ckpt()\n",
    "        self.g.init_ckpt()\n",
    "        \n",
    "        # setup early stop metrics\n",
    "        self.early_stop = False\n",
    "        self.no_change_inc = 0\n",
    "        self.prev_g_acc = None\n",
    "        self.best_g_acc = None\n",
    "        self.nudge_flag = False\n",
    "        \n",
    "    def stack_models(self):\n",
    "        inputs = []\n",
    "        for input_shape in self.g.input_shapes:\n",
    "            inputs.append(keras.layers.Input(input_shape))\n",
    "        \n",
    "        outputG = self.g.model(inputs)\n",
    "        \n",
    "        # output of G needs to be converted from [-1, 1] to [0, 1] spectrum\n",
    "        outputG_converted = 0.5 * outputG + 0.5\n",
    "        \n",
    "        outputD = self.d.model(outputG_converted)\n",
    "        return keras.models.Model(inputs=inputs, outputs=outputD)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Trainer\n",
    "        \n",
    "    def train(self, iteration, save_best=False):\n",
    "        # setup checkpointing\n",
    "        self.setup_ckpts(iteration)\n",
    "        \n",
    "        # initialize the metrics each new epoch\n",
    "        if self.gen_acc_train_avg is not None:\n",
    "            del self.gen_acc_train_avg\n",
    "        if self.gen_loss_train_avg is not None:\n",
    "            del self.gen_loss_train_avg\n",
    "        if self.disc_loss_train_avg is not None:\n",
    "            del self.disc_loss_train_avg\n",
    "        \n",
    "        self.gen_loss_train_avg = tf.keras.metrics.Mean()\n",
    "        self.gen_acc_train_avg = tf.keras.metrics.Accuracy()\n",
    "        self.disc_loss_train_avg = tf.keras.metrics.Mean()\n",
    "        \n",
    "        pbar = tqdm_notebook(total=self.batches_per_epoch)\n",
    "        \n",
    "        for i in range(self.batches_per_epoch):\n",
    "            # nudge generator if nothing is happening:\n",
    "            if self.nudge():\n",
    "                if not self.nudge_flag:\n",
    "                    self.nudge_flag = True\n",
    "                train_discriminator = True\n",
    "            else:\n",
    "                train_discriminator = (self.gen_acc_train_avg.result() >= self.d_trigger)\n",
    "            \n",
    "            # logic for training the generator\n",
    "            train_generator = (self.gen_acc_train_avg.result() < self.g_trigger)\n",
    "            \n",
    "            self.c_train_step(train_discriminator=train_discriminator, train_generator=train_generator)\n",
    "            pbar.update(1)\n",
    "            pbar.set_description('g_acc={:.2f}, g_loss={:.2f}, d_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                                     self.gen_loss_train_avg.result(),\n",
    "                                                                                     self.disc_loss_train_avg.result()))\n",
    "        \n",
    "        print('g_acc={:.2f}, g_loss={:.2f}, d_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                  self.gen_loss_train_avg.result(),\n",
    "                                                                  self.disc_loss_train_avg.result()))\n",
    "        \n",
    "        # reload from pre-nudge state\n",
    "        if self.nudge_flag:\n",
    "            if self.d_restore_after_nudge:\n",
    "                self.d.restore(it_restore=iteration)\n",
    "            self.nudge_flag = False\n",
    "        \n",
    "        # save checkpoints\n",
    "        # only checkpoint d if we are the cGAN\n",
    "        self.checkpoint_d()\n",
    "        if save_best:\n",
    "            if self.best_g_acc is None or self.gen_acc_train_avg.result() >= self.best_g_acc:\n",
    "                self.best_g_acc = self.gen_acc_train_avg.result()\n",
    "                self.checkpoint_g()\n",
    "        else:\n",
    "            self.checkpoint_g()\n",
    "        \n",
    "        # check for early stop\n",
    "        self.early_stop_check()\n",
    "    \n",
    "    def c_train_step(self, train_discriminator, train_generator):\n",
    "        noise = tf.random.normal([self.batch_size, self.noise_dim])\n",
    "        random_classes = tf.random.uniform(shape=(self.batch_size, ), maxval=num_classes, dtype=tf.dtypes.int32)\n",
    "        labels = tf.one_hot(random_classes, num_classes, dtype=tf.dtypes.float32)\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            fake_discrimination = self.gd([noise, labels], training=train_generator)\n",
    "\n",
    "            gen_loss = self.g.loss(fake_discrimination, labels)\n",
    "            disc_loss = self.d.loss(fake_discrimination, labels)\n",
    "            \n",
    "            # evaluate accuracy and append acc and loss to arrays\n",
    "            self.gen_loss_train_avg(gen_loss)\n",
    "            self.gen_acc_train_avg(tf.argmax(labels, 1), tf.argmax(fake_discrimination, 1))\n",
    "            self.disc_loss_train_avg(disc_loss)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.g.model.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.d.model.trainable_variables)\n",
    "\n",
    "        if train_generator:\n",
    "            self.g.optimizer.apply_gradients(zip(gradients_of_generator, self.g.model.trainable_variables))\n",
    "        if train_discriminator:\n",
    "            self.d.optimizer.apply_gradients(zip(gradients_of_discriminator, self.d.model.trainable_variables))\n",
    "            \n",
    "    def nudge(self):\n",
    "        nudge = False\n",
    "        if self.no_change_inc >= self.g_nudge_trigger:\n",
    "            nudge = random.random() < self.g_nudge_probability\n",
    "        return nudge\n",
    "    \n",
    "    def refine_discriminator(self, input_datasets, blackbox_labelss, iteration):\n",
    "        self.setup_ckpts(iteration)\n",
    "        assert len(input_datasets) == len(blackbox_labelss)\n",
    "        disc_loss_refine_avg = tf.keras.metrics.Mean()\n",
    "        disc_acc_refine_avg = tf.keras.metrics.Accuracy()\n",
    "        optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        for k in range(len(input_datasets)):\n",
    "            # perform for every pair of data:\n",
    "            \n",
    "            input_dataset = input_datasets[k]        # (x, y) --> x: [[ client ... [(id, data) ...]]\n",
    "            blackbox_labels = blackbox_labelss[k]    #               [[ client ... [label_batch ...]]\n",
    "            \n",
    "            x, _ = input_dataset\n",
    "\n",
    "            # compare the two using MSE\n",
    "            for i, client_x in enumerate(x):\n",
    "                x_batch = client_x[1]\n",
    "\n",
    "                # run through every minibatch:\n",
    "                j = 0\n",
    "                while(j < len(x_batch)):\n",
    "                    if self.minibatch_size is None:\n",
    "                        # use whole batch (no minibatch)\n",
    "                        x_minibatch = x_batch\n",
    "                        y_minibatch = blackbox_labels[i]\n",
    "                    else:\n",
    "                        x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                        y_minibatch = blackbox_labels[i][j:(j+self.minibatch_size)]\n",
    "                        \n",
    "                    with tf.GradientTape() as refine_tape:\n",
    "                        # predict each minibatch of the input_dataset and match it with its counterpart from the blackbox\n",
    "                        label_batch = self.d.discriminate(x_minibatch)\n",
    "                        refine_loss = self.mse(y_minibatch, label_batch)\n",
    "                        disc_loss_refine_avg(refine_loss)\n",
    "                        disc_acc_refine_avg(tf.argmax(y_minibatch, 1), tf.argmax(label_batch, 1))\n",
    "\n",
    "                    # train the discriminator, one client batch at a time\n",
    "                    gradients_of_discriminator = refine_tape.gradient(refine_loss, self.d.model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients_of_discriminator, self.d.model.trainable_variables))\n",
    "\n",
    "                    if self.minibatch_size is None:\n",
    "                        break\n",
    "                    else:\n",
    "                        j += self.minibatch_size\n",
    "                    \n",
    "        return disc_loss_refine_avg.result(), disc_acc_refine_avg.result()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def setup_ckpts(self, iteration):\n",
    "        if self.save_ckpts:\n",
    "            # setup fresh checkpointer every new iteration\n",
    "            if self.internal_iteration is None or (self.internal_iteration != (iteration + self.iteration_offset)):\n",
    "                self.internal_iteration = iteration + self.iteration_offset\n",
    "                self.d.setup_ckpt(self.internal_iteration)\n",
    "                self.g.setup_ckpt(self.internal_iteration)\n",
    "    \n",
    "    def checkpoint_d(self):\n",
    "        if self.save_ckpts:\n",
    "            self.d.checkpoint()\n",
    "    \n",
    "    def checkpoint_g(self):\n",
    "        if self.save_ckpts:\n",
    "            self.g.checkpoint()\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        tmp_offset = self.d.restore(it_restore, load_default, use_blackbox=False)\n",
    "        self.iteration_offset = self.g.restore(it_restore, load_default)\n",
    "        assert tmp_offset == self.iteration_offset\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Early stop\n",
    "        \n",
    "    def early_stop_check(self):\n",
    "        if self.prev_g_acc is not None:\n",
    "            perc_diff = abs(self.gen_acc_train_avg.result() - self.prev_g_acc) / self.prev_g_acc\n",
    "            #print(perc_diff, self.stop_sensitivity)\n",
    "            if perc_diff <= self.stop_sensitivity:\n",
    "                self.no_change_inc += 1\n",
    "                print('> no change inc: {}/{}'.format(self.no_change_inc, self.early_stop_trigger))\n",
    "                if self.no_change_inc >= self.early_stop_trigger:\n",
    "                    self.early_stop = True\n",
    "                    self.no_change_inc = 0\n",
    "            else:\n",
    "                self.no_change_inc = 0\n",
    "\n",
    "        self.prev_g_acc = self.gen_acc_train_avg.result()\n",
    "        \n",
    "    def reset_early_stop(self):\n",
    "        self.no_change_inc = 0\n",
    "        self.prev_g_acc = None\n",
    "        self.best_g_acc = None\n",
    "        self.nudge_flag = False\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "            \n",
    "    def generate_images(self, predictions=None, labels=None):\n",
    "        # Notice `training` is set to False.\n",
    "        # This is so all layers run in inference mode (batchnorm).\n",
    "        \n",
    "        if predictions is None:\n",
    "            predictions = self.g.generate([self.seed, self.eval_labels], training=False)\n",
    "            predictions = 0.5 * predictions + 0.5\n",
    "            labels = self.eval_labels\n",
    "        assert predictions.shape[0] >= 16\n",
    "        assert labels is not None\n",
    "        assert len(labels) == len(predictions)\n",
    "\n",
    "        categories = [self.g.g_identifier()+str(x) for x in list(range(10))]\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        for i in range(16):\n",
    "            ax = plt.subplot(4, 4, i+1)\n",
    "            if self.is_conditional:\n",
    "                ax.title.set_text(categories[np.argmax(labels[i])])\n",
    "            plt.imshow(predictions[i, :, :, 0] * 255.0, cmap='gray')\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def generate_dataset(self, batch_num, batch_size, verbose=False):\n",
    "        '''\n",
    "        Generates a list of batches (x_batch, y_batch) to pass into the black-box model\n",
    "        '''\n",
    "        x_batches = []\n",
    "        y_batches = []\n",
    "        for b in range(batch_num):\n",
    "            \n",
    "            # create a list of random ints\n",
    "            seed = tf.random.normal([batch_size, self.noise_dim])\n",
    "            gen_labels = np.random.randint(num_classes, size=batch_size)\n",
    "            y_batch = self.onehot_vals(gen_labels)\n",
    "            \n",
    "            predictions = self.g.generate([seed, y_batch], training=False)\n",
    "            x_batch = 0.5 * predictions + 0.5\n",
    "            \n",
    "            x_batches.append((None, x_batch)) # making into a tuple to match previous dataset scheme\n",
    "            y_batches.append((None, y_batch))\n",
    "            \n",
    "        if verbose:\n",
    "            self.generate_images(x_batches[0][1], y_batches[0][1])\n",
    "        return [x_batches, y_batches]\n",
    "    \n",
    "    def onehot_vals(self, a):\n",
    "        b = np.zeros((a.size, num_classes), dtype=np.float32)\n",
    "        b[np.arange(a.size), a] = 1\n",
    "        return b\n",
    "        \n",
    "    def evaluate_gan(self, dataset):\n",
    "        \n",
    "        if self.gen_acc_train_avg is not None:\n",
    "            print('G Train Acc:     {:.3f} | Loss: {:.3f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                self.gen_loss_train_avg.result()))\n",
    "            print('D Train Acc:     NaN   | Loss: {:.3f}'.format(self.disc_loss_train_avg.result()))\n",
    "        disc_acc_test = self.evaluate_discriminator(dataset)\n",
    "        \n",
    "        # define plotting metrics\n",
    "        self.gen_loss_train_arr.append(self.gen_loss_train_avg.result())\n",
    "        self.gen_acc_train_arr.append(self.gen_acc_train_avg.result())\n",
    "        self.disc_loss_train_arr.append(self.disc_loss_train_avg.result())\n",
    "        self.disc_acc_test_arr.append(disc_acc_test)\n",
    "        \n",
    "        return disc_acc_test\n",
    "        \n",
    "    def evaluate_discriminator(self, dataset, verbose=True):\n",
    "        \n",
    "        x, y = dataset\n",
    "        \n",
    "        acc_test_avg = tf.keras.metrics.Accuracy()\n",
    "        loss_test_avg = tf.keras.metrics.Mean()\n",
    "        for i in range(0, len(x), self.batch_size):\n",
    "            # get batch\n",
    "            x_batch = x[i:i+self.batch_size]\n",
    "            y_batch = y[i:i+self.batch_size]\n",
    "            \n",
    "            # evaluate\n",
    "            logits = self.d.discriminate(x_batch, training=False)\n",
    "            acc_test_avg(tf.argmax(y_batch, 1), tf.argmax(logits, 1))\n",
    "            loss_test_avg(self.d.entropy(y_batch, logits))\n",
    "            \n",
    "        if verbose:\n",
    "            print('D Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test_avg.result(), loss_test_avg.result()))\n",
    "            print()\n",
    "        \n",
    "        return acc_test_avg.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGSM:\n",
    "    '''\n",
    "    The Discriminator portion of the GAN. Accepts a network, otherwise creates a new model.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, fgsm_training_params):\n",
    "        \n",
    "        self.ckpt_folder = fgsm_training_params['fgsm_ckpt_folder']\n",
    "#         self.bb_ckpt_folder = gan_training_params['bb_ckpt_folder']\n",
    "#         self.loop_times = gan_training_params['loop_times']\n",
    "#         self.softmax_power = gan_training_params['softmax_power']\n",
    "#         self.minibatch_size = gan_training_params['minibatch_size']\n",
    "        \n",
    "        # make FUNCTIONAL version of FGSM 'substitute' network\n",
    "        self.model = self.discriminator_model()\n",
    "            \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define entropies\n",
    "        self.cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        self.bin_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            \n",
    "        # setup checkpointing\n",
    "        self.ckpt = None\n",
    "        self.manager = None\n",
    "        \n",
    "        # save the initial weights\n",
    "        self.save_initial_weights()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Discriminator model\n",
    "    \n",
    "    def discriminator_model(self):\n",
    "        model = start_piece_(input_shape, filters)\n",
    "        model = approximator_piece_(model, depth, filters)\n",
    "        model = end_piece_(model, dense, num_classes)\n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Loss\n",
    "    \n",
    "    def loss(self, fake_discrimination, labels):\n",
    "        matches = self.matches_labels(fake_discrimination, labels, loop_times=self.loop_times)\n",
    "        # we want the discriminator to NOT be fooled by these fake images\n",
    "        cross_entropy = self.bin_cross_entropy(tf.zeros_like(matches), matches)\n",
    "        return cross_entropy\n",
    "    \n",
    "    def entropy(self, y_true, y_pred):\n",
    "        return self.cat_cross_entropy(y_true, y_pred)\n",
    "        \n",
    "    def matches_labels(self, fake_output, labels, loop_times=0):\n",
    "        '''\n",
    "        Only works if the Discriminator is already trained on real images!!\n",
    "        1. Performs a softmax -> onehot conversion (differentiable approx.)\n",
    "        2. Multiplies this by the onehot version of the onehot attack label\n",
    "        3. Sums to reduce dimension\n",
    "        \n",
    "        - if the sum is close to 1, the nn thinks that the image is a part of the attack class\n",
    "        - if the sum is close to 0, the nn thinks that the image is not of the attack class\n",
    "        - the sum should not be in between, due to the onehot conversion we perform in step 1\n",
    "        '''\n",
    "        # 1.\n",
    "        my_power = self.softmax_power\n",
    "        for i in range(loop_times):\n",
    "            fake_output = self.soft_onehot(fake_output)\n",
    "        \n",
    "        # 2.\n",
    "        matches = tf.math.multiply(fake_output, labels)\n",
    "        \n",
    "        # 3.\n",
    "        reduced = tf.math.reduce_sum(matches, axis=-1)\n",
    "        \n",
    "        return reduced\n",
    "        \n",
    "    def soft_onehot(self, softmax, my_power=8):\n",
    "        '''\n",
    "        Shown to not really work... vanishing gradients problem\n",
    "        '''\n",
    "        soft_extreme = softmax ** my_power\n",
    "        norm = tf.reduce_sum(soft_extreme, axis=-1)\n",
    "        almost_onehot = tf.math.divide(soft_extreme, tf.reshape(norm, (-1, 1)))\n",
    "        return almost_onehot\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        ckpt_save_folder = os.path.join('checkpoints', 'it_{}'.format(iteration), self.ckpt_folder)\n",
    "        os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "        if self.ckpt is not None:\n",
    "            del self.ckpt\n",
    "        if self.manager is not None:\n",
    "            del self.manager\n",
    "\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "        \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved D checkpoint: {}\".format(save_path))\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Load/save weights\n",
    "    \n",
    "    def save_initial_weights(self):\n",
    "        print('saving initial weights for D')\n",
    "        init_folder = os.path.join('checkpoints', 'init', self.ckpt_folder)\n",
    "        os.makedirs(init_folder, exist_ok=True)\n",
    "        self.model.save_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def load_initial_weights(self):\n",
    "        print('loading initial weights for D')\n",
    "        init_folder = os.path.join('checkpoints', 'init', self.ckpt_folder)\n",
    "        self.model.load_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False, use_blackbox=False):\n",
    "        iteration_offset = 0\n",
    "        parent_folder = os.path.join('checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                iteration_offset = largest_it\n",
    "                print('Restored D to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found for D, starting with a fresh network')\n",
    "        else:\n",
    "            if load_default:\n",
    "                if use_blackbox:\n",
    "                    checkpoint_directory = os.path.join(parent_folder, 'default', self.bb_ckpt_folder)\n",
    "                else:\n",
    "                    checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    iteration_offset = it_restore\n",
    "                print('Restored D to checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        return iteration_offset\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluation\n",
    "\n",
    "    def discriminate(self, generated_images, training=True):\n",
    "        return self.model(generated_images, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGSMTrainer:\n",
    "    \n",
    "    def __init__(self, fgsm_training_params, discriminator_model):\n",
    "        \n",
    "        self.fgsm = FGSM(fgsm_training_params)\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Trainer\n",
    "        \n",
    "    def train(self, iteration, save_best=False):\n",
    "        # setup checkpointing\n",
    "        self.setup_ckpts(iteration)\n",
    "        \n",
    "        # initialize the metrics each new epoch\n",
    "        if self.gen_acc_train_avg is not None:\n",
    "            del self.gen_acc_train_avg\n",
    "        if self.gen_loss_train_avg is not None:\n",
    "            del self.gen_loss_train_avg\n",
    "        \n",
    "        self.gen_loss_train_avg = tf.keras.metrics.Mean()\n",
    "        if self.is_conditional:\n",
    "            self.gen_acc_train_avg = tf.keras.metrics.Accuracy()\n",
    "        \n",
    "        pbar = tqdm_notebook(total=self.batches_per_epoch)\n",
    "        \n",
    "        for i in range(self.batches_per_epoch):\n",
    "            # logic for training the generator\n",
    "            train_generator = True\n",
    "            \n",
    "            if self.is_conditional:\n",
    "                self.c_train_step(train_generator=train_generator)\n",
    "                pbar.update(1)\n",
    "                pbar.set_description('g_acc={:.2f}, g_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                          self.gen_loss_train_avg.result()))\n",
    "            else:\n",
    "                self.u_train_step(train_generator=train_generator)\n",
    "                pbar.update(1)\n",
    "                pbar.set_description('g_loss={:.8f}'.format(self.gen_loss_train_avg.result()))\n",
    "        \n",
    "        if self.is_conditional:\n",
    "            print('g_acc={:.2f}, g_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                       self.gen_loss_train_avg.result()))\n",
    "        else:\n",
    "            print('g_loss={:.2f}'.format(self.gen_loss_train_avg.result()))\n",
    "        \n",
    "        # save checkpoints\n",
    "        if save_best:\n",
    "            if self.is_conditional:\n",
    "                if self.best_g_acc is None or self.gen_acc_train_avg.result() >= self.best_g_acc:\n",
    "                    self.best_g_acc = self.gen_acc_train_avg.result()\n",
    "                    self.checkpoint_g()\n",
    "            else:\n",
    "                # TODO: maybe make a best_ug_loss?\n",
    "                self.checkpoint_g()\n",
    "        else:\n",
    "            self.checkpoint_g()\n",
    "        \n",
    "        # check for early stop\n",
    "        self.early_stop_check()\n",
    "    \n",
    "    def c_train_step(self, train_generator):\n",
    "        noise = tf.random.normal([self.batch_size, self.noise_dim])\n",
    "        random_classes = tf.random.uniform(shape=(self.batch_size, ), maxval=num_classes, dtype=tf.dtypes.int32)\n",
    "        labels = tf.one_hot(random_classes, num_classes, dtype=tf.dtypes.float32)\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            fake_discrimination = self.gd([noise, labels], training=train_generator)\n",
    "\n",
    "            gen_loss = self.g.u_loss(fake_discrimination) + self.g.loss(fake_discrimination, labels)\n",
    "            \n",
    "            # evaluate accuracy and append acc and loss to arrays\n",
    "            self.gen_loss_train_avg(gen_loss)\n",
    "            self.gen_acc_train_avg(tf.argmax(labels, 1), tf.argmax(fake_discrimination, 1))\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.g.model.trainable_variables)\n",
    "\n",
    "        if train_generator:\n",
    "            self.g.optimizer.apply_gradients(zip(gradients_of_generator, self.g.model.trainable_variables))\n",
    "    \n",
    "    def u_train_step(self, train_generator):\n",
    "        '''\n",
    "        Train G, knowing we are trying to generate the most appropriate dataset to pass to BB\n",
    "        '''\n",
    "        noise = tf.random.normal([self.batch_size, self.noise_dim])\n",
    "        random_classes = tf.random.uniform(shape=(self.batch_size, ), maxval=num_classes, dtype=tf.dtypes.int32)\n",
    "\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            fake_discrimination = self.gd(noise, training=train_generator)\n",
    "\n",
    "            gen_loss = self.g.u_loss(fake_discrimination)\n",
    "            \n",
    "            # evaluate accuracy and append acc and loss to arrays\n",
    "            self.gen_loss_train_avg(gen_loss)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.g.model.trainable_variables)\n",
    "\n",
    "        if train_generator:\n",
    "            self.g.optimizer.apply_gradients(zip(gradients_of_generator, self.g.model.trainable_variables))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def setup_ckpts(self, iteration):\n",
    "        if self.save_ckpts:\n",
    "            # setup fresh checkpointer every new iteration\n",
    "            if self.internal_iteration is None or (self.internal_iteration != (iteration + self.iteration_offset)):\n",
    "                self.internal_iteration = iteration + self.iteration_offset\n",
    "                self.g.setup_ckpt(self.internal_iteration)\n",
    "    \n",
    "    def checkpoint_g(self):\n",
    "        if self.save_ckpts:\n",
    "            self.g.checkpoint()\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        self.iteration_offset = self.g.restore(it_restore, load_default)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Early stop\n",
    "        \n",
    "    def early_stop_check(self):\n",
    "        if self.is_conditional:\n",
    "            if self.prev_g_acc is not None:\n",
    "                perc_diff = abs(self.gen_acc_train_avg.result() - self.prev_g_acc) / self.prev_g_acc\n",
    "                #print(perc_diff, self.stop_sensitivity)\n",
    "                if perc_diff <= self.stop_sensitivity:\n",
    "                    self.no_change_inc += 1\n",
    "                    print('> no change inc: {}/{}'.format(self.no_change_inc, self.early_stop_trigger))\n",
    "                    if self.no_change_inc >= self.early_stop_trigger:\n",
    "                        self.early_stop = True\n",
    "                        self.no_change_inc = 0\n",
    "                else:\n",
    "                    self.no_change_inc = 0\n",
    "\n",
    "            self.prev_g_acc = self.gen_acc_train_avg.result()\n",
    "        else:\n",
    "            # TODO: maybe make a prev_ug_loss?\n",
    "            pass\n",
    "        \n",
    "    def reset_early_stop(self):\n",
    "        self.no_change_inc = 0\n",
    "        self.prev_g_acc = None\n",
    "        self.best_g_acc = None\n",
    "        self.nudge_flag = False\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "            \n",
    "    def generate_images(self, predictions=None, labels=None):\n",
    "        # Notice `training` is set to False.\n",
    "        # This is so all layers run in inference mode (batchnorm).\n",
    "        \n",
    "        if predictions is None:\n",
    "            predictions = self.g.generate([self.seed, self.eval_labels], training=False)\n",
    "            predictions = 0.5 * predictions + 0.5\n",
    "            labels = self.eval_labels\n",
    "        assert predictions.shape[0] >= 16\n",
    "        assert labels is not None\n",
    "        assert len(labels) == len(predictions)\n",
    "\n",
    "        if self.is_conditional:\n",
    "            categories = [self.g.g_identifier()+str(x) for x in list(range(10))]\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        for i in range(16):\n",
    "            ax = plt.subplot(4, 4, i+1)\n",
    "            if self.is_conditional:\n",
    "                ax.title.set_text(categories[np.argmax(labels[i])])\n",
    "            plt.imshow(predictions[i, :, :, 0] * 255.0, cmap='gray')\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def generate_dataset(self, batch_num, batch_size, verbose=False):\n",
    "        '''\n",
    "        Generates a list of batches (x_batch, y_batch) to pass into the black-box model\n",
    "        '''\n",
    "        x_batches = []\n",
    "        y_batches = []\n",
    "        for b in range(batch_num):\n",
    "            \n",
    "            # create a list of random ints\n",
    "            seed = tf.random.normal([batch_size, self.noise_dim])\n",
    "            gen_labels = np.random.randint(num_classes, size=batch_size)\n",
    "            y_batch = self.onehot_vals(gen_labels)\n",
    "            \n",
    "            if self.is_conditional:\n",
    "                predictions = self.g.generate([seed, y_batch], training=False)\n",
    "            else:\n",
    "                predictions = self.g.generate(seed, training=False)\n",
    "            x_batch = 0.5 * predictions + 0.5\n",
    "            \n",
    "            x_batches.append((None, x_batch)) # making into a tuple to match previous dataset scheme\n",
    "            y_batches.append((None, y_batch))\n",
    "            \n",
    "        if verbose:\n",
    "            self.generate_images(x_batches[0][1], y_batches[0][1])\n",
    "        return [x_batches, y_batches]\n",
    "    \n",
    "    def onehot_vals(self, a):\n",
    "        b = np.zeros((a.size, num_classes), dtype=np.float32)\n",
    "        b[np.arange(a.size), a] = 1\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemTrainer:\n",
    "    \n",
    "    def __init__(self, split_training_params, cgan_training_params, fgsm_training_params, attack_params):\n",
    "        # Datasets:\n",
    "        self.split_train_dataset = split_training_params['train_dataset']\n",
    "        assert self.split_train_dataset is not None\n",
    "        self.split_test_dataset = split_training_params['test_dataset']\n",
    "        assert self.split_test_dataset is not None\n",
    "        self.attack_train_dataset = attack_params['train_dataset']\n",
    "        assert self.attack_train_dataset is not None\n",
    "        \n",
    "        # Split Learning params:\n",
    "        self.split_epochs = split_training_params['epochs']\n",
    "        self.split_batch_limit = split_training_params['batch_limit']\n",
    "        \n",
    "        # GAN params:\n",
    "        self.cgan_training_params = cgan_training_params\n",
    "        self.fgsm_training_params = fgsm_training_params\n",
    "        self.cgan_epochs = cgan_training_params['epochs']\n",
    "        self.use_blackbox= cgan_training_params['use_blackbox']\n",
    "        self.d_reset_percentage = cgan_training_params['d_reset_percentage']\n",
    "        self.d_priming_epoch_limit = cgan_training_params['d_priming_epoch_limit']\n",
    "        self.d_refine_epoch_limit = cgan_training_params['d_refine_epoch_limit']\n",
    "        self.save_best_cg = cgan_training_params['save_best_g']\n",
    "        self.reset_c_g_every_it = cgan_training_params['reset_g_every_it']\n",
    "        \n",
    "        # Attack params:\n",
    "        self.prime_first_iteration = attack_params['prime_first_iteration']\n",
    "        self.prime_exit_trigger = attack_params['prime_exit_trigger']\n",
    "        self.refine_exit_trigger = attack_params['refine_exit_trigger']\n",
    "        self.prime_trigger = attack_params['prime_trigger']\n",
    "        self.prime_by_ckpt = attack_params['prime_by_ckpt']\n",
    "        self.attack_trigger = attack_params['attack_trigger']\n",
    "        self.attack_classes = attack_params['attack_classes']\n",
    "        self.d_refinement_batch_num = attack_params['d_refinement_batch_num']\n",
    "        self.d_refinement_batch_size = attack_params['d_refinement_batch_size']\n",
    "        self.train_bb_every_n_its = attack_params['train_bb_every_n_its']\n",
    "        self.cgan_query_every_n_its = attack_params['cgan_query_every_n_its']\n",
    "        self.refine_using_ugan = attack_params['refine_using_ugan']\n",
    "        self.accumulate_g_queries = attack_params['accumulate_g_queries']\n",
    "        self.flush_g_queries_every_bb_train = attack_params['flush_g_queries_every_bb_train']\n",
    "        \n",
    "        # create the Split Learning Trainer\n",
    "        self.split = SplitLearning(split_training_params)\n",
    "        \n",
    "        # create the cGAN Trainer\n",
    "        if not self.use_blackbox:\n",
    "            # treat the Split Learning NN as a Black-box\n",
    "            self.cgan = cGAN(cgan_training_params)\n",
    "        else:\n",
    "            # use the Split Learning NN as the GAN's Discriminator as an easy check:\n",
    "            self.cgan = cGAN(cgan_training_params, discriminator_model=self.split.model)\n",
    "            \n",
    "        # create FGSM Trainer, depend on cGAN's D\n",
    "        self.fgsm = None # TODO\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Training\n",
    "        \n",
    "    def train_system(self):\n",
    "        '''\n",
    "        Train the entire system, updating D while performing Split Learning, and train GAN until ready for attack\n",
    "        '''\n",
    "        \n",
    "        iteration = 0\n",
    "        all_g_queries = [] # [(g_dataset, queried_labels) ...] \n",
    "        while(True):\n",
    "            \n",
    "            # Increment the iteration count:\n",
    "            iteration += 1\n",
    "            print('*'*40)\n",
    "            print('Iteration {}'.format(iteration))\n",
    "            print()\n",
    "        \n",
    "            # Prime the Black-box and D models (normal client, normal training):\n",
    "            d_acc = self.cgan.evaluate_discriminator(self.split_test_dataset, verbose=True)\n",
    "            if d_acc < self.prime_trigger or (self.prime_first_iteration and iteration == 1):\n",
    "                if self.prime_by_ckpt:\n",
    "                    # prime BB and D by loading in their default checkpoints\n",
    "                    self.split.restore(load_default=True)\n",
    "                    self.cgan.d.restore(load_default=True)\n",
    "                    \n",
    "                    print('o'*40)\n",
    "                    print('SKIPPED STEPS 1 & 2: Primed by checkpoint')\n",
    "                    print('o'*40)\n",
    "                    print()\n",
    "                else:\n",
    "                    ########################################################################\n",
    "                    # Step 1: \"Prime\" the Split Learning model if the model is not trained enough:\n",
    "                    print('~'*40)\n",
    "                    print('Step 1: Priming Split Learning')\n",
    "                    for e in tqdm_notebook(range(self.split_epochs)):\n",
    "                        print('-'*20)\n",
    "                        print('Epoch {}/{}'.format(e+1, self.split_epochs))\n",
    "                        # the attacker is pretending to be a normal client:\n",
    "                        self.split.train([self.split_train_dataset, self.attack_train_dataset], iteration, \n",
    "                                         batch_limit=self.split_batch_limit)\n",
    "                        self.split.evaluate(self.split_test_dataset)\n",
    "\n",
    "                    ########################################################################\n",
    "                    # Step 2: \"Prime\" D:\n",
    "                    print('~'*40)\n",
    "                    print('Step 2: Priming D')\n",
    "\n",
    "                    blackbox_labels = self.split.predict(self.attack_train_dataset)\n",
    "\n",
    "                    pbar = tqdm_notebook(total=self.d_priming_epoch_limit)\n",
    "                    d_prime_acc = None\n",
    "                    prime_inc = 0\n",
    "                    while (d_prime_acc is None or d_prime_acc < self.prime_exit_trigger) and prime_inc < self.d_priming_epoch_limit:\n",
    "                        d_refine_loss, d_prime_acc = self.cgan.refine_discriminator([self.attack_train_dataset], \n",
    "                                                                                    [blackbox_labels],\n",
    "                                                                                    iteration)\n",
    "                        pbar.set_description('d_prime_acc: {:.3f}'.format(d_prime_acc))\n",
    "                        pbar.update(1)\n",
    "                        prime_inc += 1\n",
    "                    pbar.close()\n",
    "                    \n",
    "                    # save checkpoints\n",
    "                    self.cgan.checkpoint_d()\n",
    "                    print('d_prime_acc: {:.3f}'.format(d_prime_acc))\n",
    "\n",
    "                # do not proceed if D is not close enough to the Split Learning model:\n",
    "                d_acc = self.cgan.evaluate_discriminator(self.split_test_dataset, verbose=True)\n",
    "                if d_acc < self.prime_trigger:\n",
    "                    # D is not trained enough, we will train the Black-box model more and then prime D again\n",
    "                    self.cgan.d.load_initial_weights()\n",
    "                    continue\n",
    "            else:\n",
    "                print('x'*40)\n",
    "                print('SKIPPED STEPS 1 & 2')\n",
    "                print('x'*40)\n",
    "                print()\n",
    "\n",
    "            ################################################################################\n",
    "            # Step 3.1: Train uGAN on D:\n",
    "            print('~'*40)\n",
    "            print('Step 3.1: Training uG')\n",
    "            print(' - performed until uG converges with the current D')\n",
    "            self.ugan.reset_early_stop()\n",
    "            for e in tqdm_notebook(range(self.ugan_epochs)):\n",
    "                print('-'*20)\n",
    "                print('Epoch {}/{}'.format(e+1, self.ugan_epochs))\n",
    "                self.ugan.train(iteration, save_best=False)\n",
    "                self.ugan.generate_images()\n",
    "\n",
    "                if self.get_early_stop_check(self.ugan):\n",
    "                    print('** Early stop! **')\n",
    "                    print()\n",
    "                    break\n",
    "                \n",
    "            # Step 3.2: Train cGAN on D:\n",
    "            if (iteration-1) % self.cgan_query_every_n_its == 0:\n",
    "                print('~'*40)\n",
    "                print('Step 3.2: Training cG')\n",
    "                print(' - performed until cG converges with the current D')\n",
    "                self.cgan.reset_early_stop()\n",
    "                for e in tqdm_notebook(range(self.cgan_epochs)):\n",
    "                    print('-'*20)\n",
    "                    print('Epoch {}/{}'.format(e+1, self.cgan_epochs))\n",
    "                    self.cgan.train(iteration, save_best=self.save_best_cg)\n",
    "                    self.cgan.generate_images()\n",
    "\n",
    "                    if self.get_early_stop_check(self.cgan):\n",
    "                        print('** Early stop! **')\n",
    "                        print()\n",
    "                        break\n",
    "\n",
    "                # reload G with the best weights we found during training:\n",
    "                if self.save_best_cg:\n",
    "                    self.cgan.g.restore(it_restore=iteration)\n",
    "                    self.cgan.generate_images()\n",
    "            else:\n",
    "                print('x'*40)\n",
    "                print('SKIPPED STEP 3.2')\n",
    "                print('x'*40)\n",
    "                print()\n",
    "                    \n",
    "            ################################################################################\n",
    "            # Step 4: Train Split Learning, but now add images from G\n",
    "            print('~'*40)\n",
    "            print('Step 4: Training Split Learning (and gathering Black-box labels from {}G)'.format(self.ugan.g.g_identifier()))\n",
    "            # the attacker weaves their images into the Black-box training step:\n",
    "            ug_dataset = self.ugan.generate_dataset(batch_num=self.d_refinement_batch_num,\n",
    "                                                    batch_size=self.d_refinement_batch_size, verbose=True)\n",
    "            g_dataset = ug_dataset\n",
    "            \n",
    "            if (iteration-1) % self.cgan_query_every_n_its == 0:\n",
    "                cg_dataset = self.cgan.generate_dataset(batch_num=self.d_refinement_batch_num,\n",
    "                                                        batch_size=self.d_refinement_batch_size, verbose=True)\n",
    "                # append the two g_datasets together\n",
    "                g_dataset[0] = g_dataset[0] + cg_dataset[0]\n",
    "                g_dataset[1] = g_dataset[1] + cg_dataset[1]\n",
    "            \n",
    "            if iteration % self.train_bb_every_n_its == 0:\n",
    "                queried_dataset = self.split.train([self.split_train_dataset, self.attack_train_dataset], iteration, \n",
    "                                                   g_dataset=g_dataset)\n",
    "                if self.flush_g_queries_every_bb_train:\n",
    "                    all_g_queries = []\n",
    "            else:\n",
    "                # do not train bb - only get the queried labels\n",
    "                print('only querying this iteration')\n",
    "                queried_dataset = self.split.train(datasets=[], iteration=iteration, g_dataset=g_dataset)\n",
    "            \n",
    "            # do not proceed if D is not close enough to the Split Learning model:\n",
    "            d_acc = self.cgan.evaluate_discriminator(self.split_test_dataset, verbose=False)\n",
    "            if d_acc < self.attack_trigger:\n",
    "                ###########################################################################\n",
    "                # Step 5: Refine D using the blackbox_labels we gathered and the dataset that we have available to us\n",
    "                print('~'*40)\n",
    "                print('Step 5: Refining D')\n",
    "                \n",
    "                blackbox_labels = self.split.predict(self.attack_train_dataset)\n",
    "                queried_labels = [x[2] for x in queried_dataset]\n",
    "\n",
    "                if self.accumulate_g_queries:\n",
    "                    # gather previous queries\n",
    "                    all_g_queries.append((g_dataset, queried_labels))\n",
    "                else:\n",
    "                    # only use the queries from this iteration\n",
    "                    all_g_queries = [(g_dataset, queried_labels)]\n",
    "                datasets = [self.attack_train_dataset] + [x[0] for x in all_g_queries]\n",
    "                labels = [blackbox_labels] + [x[1] for x in all_g_queries]\n",
    "                \n",
    "                pbar = tqdm_notebook(total=self.d_refine_epoch_limit)\n",
    "                d_refine_acc = None\n",
    "                refine_inc = 0\n",
    "                while (d_refine_acc is None or d_refine_acc < self.refine_exit_trigger) and refine_inc < self.d_refine_epoch_limit:\n",
    "                    d_refine_loss, d_refine_acc = self.cgan.refine_discriminator(datasets, labels, iteration)\n",
    "                    pbar.set_description('d_refine_acc: {:.3f}'.format(d_refine_acc))\n",
    "                    pbar.update(1)\n",
    "                    refine_inc += 1\n",
    "                pbar.close()\n",
    "                print('d_refine_acc: {:.3f}'.format(d_refine_acc))\n",
    "            \n",
    "                # do not proceed if D is not close enough to the Split Learning model:\n",
    "                d_acc = self.cgan.evaluate_discriminator(self.split_test_dataset, verbose=True)\n",
    "                if d_acc < self.attack_trigger:\n",
    "                    # D is not trained enough, we will train the Black-box model more and continue refining D\n",
    "                    if self.reset_c_g_every_it:\n",
    "                        self.cgan.g.load_initial_weights()\n",
    "                        \n",
    "                    if self.reset_u_g_every_it:\n",
    "                        self.ugan.g.load_initial_weights()\n",
    "                    continue\n",
    "            else:\n",
    "                print('x'*40)\n",
    "                print('SKIPPED STEP 5')\n",
    "                print('x'*40)\n",
    "                print()\n",
    "                \n",
    "            print('All done!')\n",
    "            break\n",
    "            \n",
    "            \n",
    "    def train_sl(self):\n",
    "        iteration = 1\n",
    "        \n",
    "        # Train the Split Learning model:\n",
    "        print('~'*40)\n",
    "        print('Training Split Learning')\n",
    "        for e in tqdm_notebook(range(self.split_epochs)):\n",
    "            if e == 0:\n",
    "                print('~'*40)\n",
    "            self.split.train([self.split_train_dataset], iteration)\n",
    "            self.split.evaluate(self.split_test_dataset)\n",
    "            \n",
    "    def train_gan(self, original_disc_acc, reset_d_every_epoch=False):\n",
    "        \n",
    "        iteration = 1\n",
    "        \n",
    "        # Train the GAN for X epochs, and see if the generator can produce anything:\n",
    "        print('~'*40)\n",
    "        print('Training GAN')\n",
    "        for e in tqdm_notebook(range(self.cgan_epochs)):\n",
    "            if e == 0:\n",
    "                print('~'*40)\n",
    "            print('-'*40)\n",
    "            print('Epoch {}/{}'.format(e+1, self.cgan_epochs))\n",
    "            self.cgan.train(iteration)\n",
    "            self.cgan.generate_images()\n",
    "            \n",
    "            disc_acc_test = self.cgan.evaluate_gan(self.split_test_dataset)\n",
    "            \n",
    "            if reset_d_every_epoch or disc_acc_test < original_disc_acc * self.d_reset_percentage:\n",
    "                # reset D back to the original weights, so as not to diverge D too much over training time\n",
    "                self.cgan.d.restore(load_default=True, use_blackbox=self.use_blackbox)\n",
    "                self.cgan.evaluate_discriminator(self.split_test_dataset)\n",
    "            \n",
    "            if self.get_early_stop_check(self.cgan):\n",
    "                break\n",
    "    \n",
    "    def get_early_stop_check(self, gan):\n",
    "        '''\n",
    "        Check if any models have triggered an early stop in their training\n",
    "        '''\n",
    "        early_stop = copy(gan.early_stop)\n",
    "        gan.early_stop = False\n",
    "        return early_stop\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "                \n",
    "    def plot_gan_training(self):\n",
    "        gen_loss_train_arr = self.cgan.gen_loss_train_arr\n",
    "        gen_acc_train_arr = self.cgan.gen_acc_train_arr\n",
    "        disc_loss_train_arr = self.cgan.disc_loss_train_arr\n",
    "        disc_acc_test_arr = self.cgan.disc_acc_test_arr\n",
    "        \n",
    "        epochs = list(range(max([len(gen_loss_train_arr), len(gen_acc_train_arr), \n",
    "                                 len(disc_loss_train_arr), len(disc_acc_test_arr)])))\n",
    "        epochs = [e + 1 for e in epochs]\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Generator Loss during Training')\n",
    "        plt.plot(epochs, gen_loss_train_arr)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Generator Accuracy during Training')\n",
    "        plt.plot(epochs, gen_acc_train_arr)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Discriminator Loss during Training')\n",
    "        plt.plot(epochs, disc_loss_train_arr)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Discriminator Accuracy (Test) during Training')\n",
    "        plt.plot(epochs, disc_acc_test_arr)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over all attack classes to see if we can estimate all classes from D!\n",
    "\n",
    "def test_entire_system():\n",
    "    print('='*40)\n",
    "    print('Training Entire System:')\n",
    "    print('='*40)\n",
    "    \n",
    "    slg = SystemTrainer(split_training_params, cgan_training_params, fgsm_training_params, attack_params)\n",
    "    slg.train_system()\n",
    "    \n",
    "    return slg\n",
    "\n",
    "def test_SplitLearning(slg):\n",
    "    print('='*40)\n",
    "    print('Training Split Learning:')\n",
    "    print('='*40)\n",
    "    \n",
    "    slg.train_sl()\n",
    "    \n",
    "    return slg\n",
    "\n",
    "def test_GAN(slg):\n",
    "    print('='*40)\n",
    "    print('Training GAN for attacking ANY class:')\n",
    "    print('='*40)\n",
    "\n",
    "    # load pretrained weights if they exist:\n",
    "    slg.split.restore(load_default=True)# (load_default=True, it_restore=1)\n",
    "    #slg.gan.restore(load_default=True)# (load_default=True, it_restore=1)\n",
    "    # slg.gan.save_ckpts = False # don't save the training ckpts for this test\n",
    "\n",
    "    # This SHOULD have the restored weights from split\n",
    "    print()\n",
    "    print('Double checking that the D in the GAN has been trained:')\n",
    "    original_disc_acc = slg.gan.evaluate_discriminator(slg.split_test_dataset)\n",
    "    print()\n",
    "\n",
    "    slg.train_gan(original_disc_acc=original_disc_acc, reset_d_every_epoch=False)\n",
    "    \n",
    "    return slg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# slg = SystemTrainer(split_training_params, gan_training_params)\n",
    "# slg.train_sl()\n",
    "# raise Exception('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_training_params:\n",
      "{'apply_gradients_after': 20,\n",
      " 'batch_limit': None,\n",
      " 'ckpt_folder': 'blackbox_checkpoint',\n",
      " 'epochs': 1,\n",
      " 'eval_batch_size': 256,\n",
      " 'minibatch_size': None,\n",
      " 'shuffle_clients': True}\n",
      "\n",
      "cgan_training_params:\n",
      "{'batch_size': 256,\n",
      " 'batches_per_epoch': 100,\n",
      " 'bb_ckpt_folder': 'blackbox_checkpoint',\n",
      " 'd_ckpt_folder': 'discriminator_checkpoint',\n",
      " 'd_priming_epoch_limit': 1000,\n",
      " 'd_refine_epoch_limit': 50,\n",
      " 'd_reset_percentage': 1.0,\n",
      " 'd_restore_after_nudge': True,\n",
      " 'd_trigger': 0.98,\n",
      " 'early_stop_trigger': 4,\n",
      " 'epochs': 25,\n",
      " 'g_ckpt_folder': 'generator_checkpoint',\n",
      " 'g_nudge_probability': 0.2,\n",
      " 'g_nudge_trigger': 3,\n",
      " 'g_trigger': 1.01,\n",
      " 'loop_times': 0,\n",
      " 'minibatch_size': None,\n",
      " 'noise_dim': 100,\n",
      " 'reset_g_every_it': False,\n",
      " 'save_best_g': False,\n",
      " 'softmax_power': 2,\n",
      " 'stop_sensitivity': 0.05,\n",
      " 'uncertain_loop_times': 1,\n",
      " 'use_blackbox': False}\n",
      "\n",
      "ugan_training_params:\n",
      "{'batch_size': 256,\n",
      " 'batches_per_epoch': 100,\n",
      " 'bb_ckpt_folder': 'blackbox_checkpoint',\n",
      " 'd_ckpt_folder': 'discriminator_checkpoint',\n",
      " 'early_stop_trigger': 4,\n",
      " 'epochs': 15,\n",
      " 'g_ckpt_folder': 'generator_checkpoint',\n",
      " 'is_conditional': True,\n",
      " 'loop_times': 0,\n",
      " 'minibatch_size': None,\n",
      " 'noise_dim': 100,\n",
      " 'reset_g_every_it': True,\n",
      " 'save_best_g': False,\n",
      " 'softmax_power': 2,\n",
      " 'stop_sensitivity': 0.05,\n",
      " 'uncertain_loop_times': 1}\n",
      "\n",
      "attack_params:\n",
      "{'accumulate_g_queries': True,\n",
      " 'attack_classes': [1],\n",
      " 'attack_trigger': 0.8,\n",
      " 'attacker_clients': 5,\n",
      " 'attacks_per_epoch': 10,\n",
      " 'cgan_query_every_n_its': 4,\n",
      " 'd_refinement_batch_num': 1,\n",
      " 'd_refinement_batch_size': 100,\n",
      " 'flip_to': [7],\n",
      " 'flush_g_queries_every_bb_train': True,\n",
      " 'our_class': 0,\n",
      " 'prime_by_ckpt': True,\n",
      " 'prime_exit_trigger': 1.0,\n",
      " 'prime_first_iteration': True,\n",
      " 'prime_trigger': 0.0,\n",
      " 'refine_exit_trigger': 1.0,\n",
      " 'refine_using_ugan': True,\n",
      " 'train_bb_every_n_its': 7}\n"
     ]
    }
   ],
   "source": [
    "print('split_training_params:')\n",
    "pprint({i:split_training_params[i] for i in split_training_params if 'dataset' not in i})\n",
    "print()\n",
    "print('cgan_training_params:')\n",
    "pprint(cgan_training_params)\n",
    "print()\n",
    "print('fgsm_training_params:')\n",
    "pprint(fgsm_training_params)\n",
    "print()\n",
    "print('attack_params:')\n",
    "pprint({i:attack_params[i] for i in attack_params if 'dataset' not in i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Training Entire System:\n",
      "========================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-63343a54606e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mslg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_entire_system\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-ad14959a1bbf>\u001b[0m in \u001b[0;36mtest_entire_system\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'='\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mslg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSystemTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_training_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcgan_training_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mugan_training_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattack_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mslg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_system\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-c6da8720e75c>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, split_training_params, cgan_training_params, ugan_training_params, attack_params)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m# create the Split Learning Trainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSplitLearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_training_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# create the cGAN Trainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-74396af03ab7>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, split_training_params)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# define the NN model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblackbox_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# define loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-74396af03ab7>\u001b[0m in \u001b[0;36mblackbox_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mblackbox_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_piece_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblackbox_piece_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend_piece_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-8e084e988e7f>\u001b[0m in \u001b[0;36mstart_piece_\u001b[1;34m(input_shape, filters)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    183\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    746\u001b[0m           \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2114\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2115\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2116\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2117\u001b[0m       \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2118\u001b[0m       \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         dtype=self.dtype)\n\u001b[0m\u001b[0;32m    159\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         caching_device=caching_device)\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         **kwargs_for_getter)\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    140\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         shape=shape)\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m                         shape=None):\n\u001b[0;32m    196\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2594\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2596\u001b[1;33m         shape=shape)\n\u001b[0m\u001b[0;32m   2597\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2598\u001b[0m     return variables.RefVariable(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1409\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1411\u001b[1;33m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[0;32m   1412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m   def _init_from_args(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1540\u001b[0m           \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initializer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1541\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[1;32m-> 1542\u001b[1;33m                 \u001b[0minitial_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1543\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[0;32m   1544\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    120\u001b[0m           (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[0;32m    121\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m       \u001b[0minit_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m       \u001b[0mvariable_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m    786\u001b[0m       \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m     return op(\n\u001b[1;32m--> 788\u001b[1;33m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"random_uniform\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m     \u001b[0mminval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"min\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"max\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mshape_tensor\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# not convertible to Tensors becasue of mixed content.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m       \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    315\u001b[0m                                          as_ref=False):\n\u001b[0;32m    316\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    256\u001b[0m   \"\"\"\n\u001b[0;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 258\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext_handle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_logical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\u001b[0m in \u001b[0;36m_initialize_logical_devices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m       \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_DeleteDeviceList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "slg = test_entire_system()\n",
    "raise Exception('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slg = test_GAN(slg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slg.plot_gan_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
