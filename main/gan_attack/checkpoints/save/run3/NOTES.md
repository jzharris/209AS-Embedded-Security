This is a run testing if when the D is constantly refined w/o BB training further, 
does G converge eventually? (ie, is there a measurable point when we should start training BB again?)

it 0:   G=xxxx  D=0.109     BB=0.181
it 1:   G=0.20  D=0.165
it 2:   G=0.60  D=0.146
it 3:   G=0.66  D=0.121
it 4:   G=0.92  D=0.102     BB=0.628
it 5:   G=0.92  D=0.139 
it 6:   G=0.97  D=0.122
it 7:   G=0.92  D=0.102
it 8:   Primed->D=0.103     BB=0.833
it 9:   G=0.80  D=0.109     BB=0.883
it 10:  G=0.92  D=0.138
it 11:  G=xxxx  D=0.109     BB=0.992