{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack attempt, training both G and D in the GAN, using all classes to train the G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First attempt at training the GAN D/G to provide **valid** and **representable** data from unknown classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF 2.1.0\n",
      "Keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution() # default for TF 2.0\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "from tensorflow import keras  # Import the tf version of keras.\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, \\\n",
    "                                    LeakyReLU, Conv2DTranspose, Reshape\n",
    "# import keras.backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "print('TF', tf.__version__)\n",
    "print('Keras', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "import os.path\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility \n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Enlargen plots\n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EASY_MODE: if True, Split Learning NN is used as the Discriminator in the GAN. This is good for testing, but\n",
    "# bypasses the black-box paradigm! Use with caution\n",
    "EASY_MODE = True\n",
    "\n",
    "# Black-box params (optimized for MNIST)\n",
    "depth = 9\n",
    "filters = 33\n",
    "dense = 110\n",
    "num_classes = 10\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "target_rows, target_cols = 28, 28    # governed by the chosen model\n",
    "input_shape = (target_rows, target_cols, 1)\n",
    "\n",
    "# Split Learning training params:\n",
    "split_training_params = {\n",
    "    'minibatch_size': None,                     # number of samples to operate on at one time\n",
    "                                                #  - can vary to optimize computing requirements\n",
    "                                                #  - if None, will evaluate the client's whole batch regardless of its size\n",
    "    'apply_gradients_after': 20,                # after averaging the gradients from X clients, we will apply them to the model\n",
    "    'epochs': 25,                               # number of epochs to train for\n",
    "    'shuffle_clients': True,                    # whether to shuffle the clients during training\n",
    "    'eval_batch_size': 256,                     # batch size when evaluating test set (not split by clients),\n",
    "    'train_dataset': None,                      # training set - indexed by client\n",
    "    'test_dataset': None,                       # testing set - not batched\n",
    "}\n",
    "\n",
    "# GAN training params:\n",
    "gan_training_params = {\n",
    "    'batch_size': 256,                          # number of images to generate from G at once\n",
    "    'noise_dim': 100,                           # noise vector for G\n",
    "    'epochs': 100,                              # number of epochs to train GAN\n",
    "    'use_blackbox': True                        # if True, copies the Blackbox model into D (easy check)\n",
    "}\n",
    "\n",
    "# Data parsing params\n",
    "clients_per_class = 100                         # number of clients per label. Each client only has access to one label\n",
    "                                                # - each unique class is divided into X number of subsets\n",
    "\n",
    "# Dataset params\n",
    "separated_folder = \"./separated_dataset\"\n",
    "os.makedirs(separated_folder, exist_ok=True)\n",
    "separated_train_path = os.path.join(separated_folder, \"train_separated.pkl\")\n",
    "separated_test_path = os.path.join(separated_folder, \"test_separated.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup checkpoint folders\n",
    "blackbox_checkpoint_folder = \"blackbox_checkpoint\"\n",
    "discriminator_checkpoint_folder = \"discriminator_checkpoint\"\n",
    "generator_checkpoint_folder = \"generator_checkpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = (x_train - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
    "# x_train /= 255    # range is [0, 1]\n",
    "x_test = (x_test - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
    "# x_test /= 255     # range is [0, 1]\n",
    "\n",
    "if target_rows != img_rows or target_cols != img_cols:\n",
    "    # resize x_train\n",
    "    x_train_resized = []\n",
    "    for x_ in x_train:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_train_resized.append(x_)\n",
    "    x_train = np.asarray(x_train_resized)\n",
    "\n",
    "    # resize x_test\n",
    "    x_test_resized = []\n",
    "    for x_ in x_test:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_test_resized.append(x_)\n",
    "    x_test = np.asarray(x_test_resized)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "y: (60000, 10) (10000, 10)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "print('X:', x_train.shape, x_test.shape)\n",
    "print('y:', y_train.shape, y_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "BUFFER_SIZE = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training seperation\n",
      "loaded testing seperation\n"
     ]
    }
   ],
   "source": [
    "# Separating the data by class\n",
    "if os.path.isfile(separated_train_path):\n",
    "    with open(separated_train_path, 'rb') as f:\n",
    "        x_train_dict, y_train_dict = pickle.load(f)\n",
    "        print('loaded training seperation')\n",
    "else:\n",
    "    x_train_dict = {}\n",
    "    y_train_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_train_dict[target_label] = []\n",
    "        y_train_dict[target_label] = []\n",
    "        for i, label in enumerate(y_train):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_train_dict[target_label].append(x_train[i])\n",
    "                y_train_dict[target_label].append(y_train[i])\n",
    "    \n",
    "    with open(separated_train_path, 'wb') as f:\n",
    "        pickle.dump([x_train_dict, y_train_dict], f)\n",
    "        print('saved training seperation')\n",
    "\n",
    "if os.path.isfile(separated_test_path):\n",
    "    with open(separated_test_path, 'rb') as f:\n",
    "        x_test_dict, y_test_dict = pickle.load(f)\n",
    "        print('loaded testing seperation')\n",
    "else:\n",
    "    x_test_dict = {}\n",
    "    y_test_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_test_dict[target_label] = []\n",
    "        y_test_dict[target_label] = []\n",
    "        for i, label in enumerate(y_test):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_test_dict[target_label].append(x_test[i])\n",
    "                y_test_dict[target_label].append(y_test[i])\n",
    "\n",
    "    with open(separated_test_path, 'wb') as f:\n",
    "        pickle.dump([x_test_dict, y_test_dict], f)\n",
    "        print('saved testing seperation')\n",
    "    \n",
    "# convert dicts to lists\n",
    "x_train_seperated = [np.array(x_train_dict[i]) for i in range(10)]\n",
    "y_train_seperated = [np.array(y_train_dict[i]) for i in range(10)]\n",
    "\n",
    "x_test_seperated = [np.array(x_test_dict[i]) for i in range(10)]\n",
    "y_test_seperated = [np.array(y_test_dict[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "plt.figure()\n",
    "plt.title('Data separation per class')\n",
    "plt.bar(x_train_dict.keys(), [len(v) for v in x_train_dict.values()], color='tab:blue')\n",
    "plt.bar(x_test_dict.keys(), [len(v) for v in x_test_dict.values()], color='orange', width=0.6)\n",
    "plt.legend(['x_train', 'x_test'], loc='center right', framealpha=1.0)\n",
    "plt.xlabel('class label')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data into batches for clients to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients per class:  99.6 ~= 100\n",
      "Total number of clients: 996\n",
      "Average batch size: 60.6\n"
     ]
    }
   ],
   "source": [
    "# Separate the data into a long list of batches, each batch representing a client training with that batch of images.\n",
    "# After each batch, a new client will have the opportunity to train their batch of images.\n",
    "# Batches are shuffled to simulate many clients training the model at once.\n",
    "\n",
    "client_counts = {}\n",
    "batch_sizes = {}\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "def ceil(a,b):\n",
    "    return -(-a//b)\n",
    "\n",
    "for class_idx in range(len(x_train_seperated)):\n",
    "    # Get batches from class data:\n",
    "    n_samples_per_class = len(x_train_seperated[class_idx])\n",
    "    samples_per_client = n_samples_per_class / clients_per_class\n",
    "    better_batch_size = int(math.ceil(samples_per_client))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(ceil(n_samples_per_class, better_batch_size)):\n",
    "        x_batches.append((class_idx, x_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        y_batches.append((class_idx, y_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        count += 1\n",
    "    client_counts[class_idx] = count\n",
    "    batch_sizes[class_idx] = better_batch_size\n",
    "        \n",
    "# double check that the clients_per_class is upheld per class\n",
    "# (blue bars should be uniform, orange should change according to class):\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('class label')\n",
    "ax1.set_ylabel('client count', color=color)\n",
    "plt.bar(client_counts.keys(), [v for v in client_counts.values()], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'orange'\n",
    "ax2.set_ylabel('batch size', color=color)  # we already handled the x-label with ax1\n",
    "plt.bar(batch_sizes.keys(), [v for v in batch_sizes.values()], color=color, width=0.6)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylim(0, np.mean([v for v in batch_sizes.values()])*2)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()\n",
    "\n",
    "print('Clients per class:  {} ~= {}'.format(np.mean([v for v in client_counts.values()]), clients_per_class))\n",
    "print('Total number of clients: {}'.format(np.sum([v for v in client_counts.values()])))\n",
    "print('Average batch size: {}'.format(np.mean([v for v in batch_sizes.values()])))\n",
    "\n",
    "split_batch_size = np.floor(np.mean([v for v in batch_sizes.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch and shuffle automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data for Split Learning\n",
    "split_train_dataset = (x_batches, y_batches)\n",
    "split_test_dataset = (x_test, y_test)\n",
    "\n",
    "# place into train params:\n",
    "split_training_params['train_dataset'] = split_train_dataset\n",
    "split_training_params['test_dataset'] = split_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "\n",
    "def start_piece_(input_shape, filters=4):\n",
    "    assert filters >= 1\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def blackbox_piece_(model, depth=1, filters=4):\n",
    "    assert depth >= 1\n",
    "    assert filters >= 1\n",
    "    \n",
    "    # for now, we will just give the black-box all the CNN layers\n",
    "    for i in range(depth-1):\n",
    "        model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def approximator_piece_(model, depth=1, filters=4):\n",
    "    assert depth >= 1\n",
    "    assert filters >= 1\n",
    "    \n",
    "    # for now, we will just give the approximator_piece piece the same complexity as bb (since we have shown it doens't matter)\n",
    "    model = blackbox_piece_(model, depth, filters)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def end_piece_(model, dense_breadth=128, num_classes=10):\n",
    "    assert dense_breadth >= num_classes\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_breadth, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the params are acceptable:\n",
    "assert depth >= 1\n",
    "assert filters >= 1\n",
    "assert dense >= num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitLearning:\n",
    "    \n",
    "    def __init__(self, split_training_params):\n",
    "        self.minibatch_size = split_training_params['minibatch_size']\n",
    "        self.batches_per_train_step = split_training_params['apply_gradients_after']\n",
    "        self.eval_batch_size = split_training_params['eval_batch_size']\n",
    "        self.shuffle_clients = split_training_params['shuffle_clients']\n",
    "        \n",
    "        # define the NN model\n",
    "        self.model = self.blackbox_model()\n",
    "        \n",
    "        # define loss function\n",
    "        self.cross_entropy = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define metrics\n",
    "        self.acc_train_avg = None\n",
    "        self.loss_train_avg = None\n",
    "        \n",
    "        # setup checkpointing\n",
    "        self.init_ckpt()\n",
    "        \n",
    "        # setup ops\n",
    "        self.setup_ops()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Black-box model\n",
    "        \n",
    "    def blackbox_model(self):\n",
    "        model = start_piece_(input_shape, filters)\n",
    "        model = blackbox_piece_(model, depth, filters)\n",
    "        model = end_piece_(model, dense, num_classes)\n",
    "        return model\n",
    "    \n",
    "    def model_loss(self, y_true, y_pred):\n",
    "        return self.cross_entropy(y_true, y_pred)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Train\n",
    "    \n",
    "    def setup_ops(self):\n",
    "        # INSPIRED BY: https://stackoverflow.com/questions/42156957/how-to-update-model-parameters-with-accumulated-gradients\n",
    "        # https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\n",
    "        \n",
    "        self.tvs = self.model.trainable_variables\n",
    "        self.accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in self.tvs]\n",
    "        self.accum_counter = tf.Variable(0.0, trainable=False)\n",
    "    \n",
    "    def train(self, dataset, iteration):\n",
    "        # setup checkpointing\n",
    "        self.setup_ckpt(iteration)\n",
    "        \n",
    "        # initialize the metrics each new epoch\n",
    "        if self.acc_train_avg is not None:\n",
    "            del self.acc_train_avg\n",
    "        if self.loss_train_avg is not None:\n",
    "            del self.loss_train_avg\n",
    "        self.acc_train_avg = tf.keras.metrics.Accuracy()\n",
    "        self.loss_train_avg = tf.keras.metrics.Mean()\n",
    "        \n",
    "        x_batches, y_batches = dataset\n",
    "        pbar = tqdm_notebook(total=len(x_batches))\n",
    "        \n",
    "        batch_idxs = list(range(len(x_batches)))\n",
    "        if self.shuffle_clients:\n",
    "            # shuffle the batches each time\n",
    "            random.shuffle(batch_idxs)\n",
    "            \n",
    "        for i, batch_idx in enumerate(batch_idxs):\n",
    "            x_batch = x_batches[batch_idx][1]\n",
    "            y_batch = y_batches[batch_idx][1]\n",
    "            \n",
    "            self.train_step(i, x_batch, y_batch, len(batch_idxs) - 1)\n",
    "            pbar.update(1)\n",
    "            pbar.set_description('train_acc={:.2f}%'.format(self.acc_train_avg.result()*100))\n",
    "        pbar.close()\n",
    "        \n",
    "        # save checkpoints\n",
    "        self.checkpoint()\n",
    "        \n",
    "    def train_step(self, i, x_batch, y_batch, limit):\n",
    "        # Iterate over the client's batch in minibatches:\n",
    "        j = 0\n",
    "        while(j < len(x_batch)):\n",
    "            if self.minibatch_size is None:\n",
    "                # use whole batch (no minibatch)\n",
    "                x_minibatch = x_batch\n",
    "                y_minibatch = y_batch\n",
    "            else:\n",
    "                x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                y_minibatch = y_batch[j:(j+self.minibatch_size)]\n",
    "\n",
    "            # run the gradients\n",
    "            loss_value, grads = self.grad(x_minibatch, y_minibatch)\n",
    "\n",
    "            # accumulate them\n",
    "            self.accumulate_grads(grads)\n",
    "\n",
    "            if self.minibatch_size is None:\n",
    "                break\n",
    "            else:\n",
    "                j += self.minibatch_size\n",
    "\n",
    "        # perform a train step every batches_per_train_step number of batches:\n",
    "        if (i > 0 and i % self.batches_per_train_step == 0) or i == limit:\n",
    "            # Run the train_step ops to update the weights based on our accumulated gradients\n",
    "            self.optimize()\n",
    "            self.zero_out()\n",
    "    \n",
    "    def grad(self, inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(inputs, training=True)\n",
    "            loss_value = self.model_loss(targets, logits)\n",
    "            \n",
    "        # evaluate accuracy and append acc and loss to arrays\n",
    "        self.acc_train_avg(tf.argmax(targets, 1), tf.argmax(logits, 1))\n",
    "        self.loss_train_avg(loss_value)\n",
    "        \n",
    "        return loss_value, tape.gradient(loss_value, self.model.trainable_variables)\n",
    "    \n",
    "    def accumulate_grads(self, grads):\n",
    "        # add to accum_vars the new gradients\n",
    "        self.accum_vars = [self.accum_vars[i].assign_add(grad) for i, grad in enumerate(grads)]\n",
    "        # increment the counter by 1\n",
    "        self.accum_counter.assign_add(1.0)\n",
    "        \n",
    "    def optimize(self):\n",
    "        # apply the gradients in accum_vars, dividing by the number in accum_counter\n",
    "        self.optimizer.apply_gradients(\n",
    "            [(accum_var / self.accum_counter, tv) \\\n",
    "                for (accum_var, tv) in zip(self.accum_vars, self.model.trainable_variables)]\n",
    "        )\n",
    "    \n",
    "    def zero_out(self):\n",
    "        # reset accum_vars and accum_counter back to 0\n",
    "        self.accum_vars = [tv.assign(tf.zeros_like(tv)) for tv in self.accum_vars]\n",
    "        self.accum_counter = tf.Variable(0.0, trainable=False)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = None\n",
    "        self.internal_iteration = None\n",
    "        self.iteration_offset = 0\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        # setup fresh checkpointer every new iteration\n",
    "        if self.internal_iteration is None or iteration != self.internal_iteration - self.iteration_offset:\n",
    "            ckpt_save_folder = os.path.join('checkpoints', 'it_{}'.format(iteration + self.iteration_offset), blackbox_checkpoint_folder)\n",
    "            os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "        \n",
    "            if self.ckpt is not None:\n",
    "                del self.ckpt\n",
    "            if self.manager is not None:\n",
    "                del self.manager\n",
    "\n",
    "            self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "            self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "            self.internal_iteration = iteration + self.iteration_offset\n",
    "    \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved checkpoint: {}\".format(save_path))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        parent_folder = os.path.join('checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, blackbox_checkpoint_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), blackbox_checkpoint_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                self.iteration_offset = largest_it\n",
    "                print('Restored latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found, starting with a fresh network')\n",
    "        else:\n",
    "            if load_default:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'default', blackbox_checkpoint_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), blackbox_checkpoint_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    self.iteration_offset = it_restore\n",
    "                print('Restored latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "        \n",
    "    def evaluate(self, dataset):\n",
    "        \n",
    "        x, y = dataset\n",
    "        \n",
    "        acc_test_avg = tf.keras.metrics.Accuracy()\n",
    "        loss_test_avg = tf.keras.metrics.Mean()\n",
    "        for i in range(0, len(x), self.eval_batch_size):\n",
    "            # get batch\n",
    "            x_batch = x[i:i+self.eval_batch_size]\n",
    "            y_batch = y[i:i+self.eval_batch_size]\n",
    "            \n",
    "            # evaluate\n",
    "            logits = self.model(x_batch, training=False)\n",
    "            acc_test_avg(tf.argmax(y_batch, 1), tf.argmax(logits, 1))\n",
    "            loss_test_avg(self.model_loss(y_batch, logits))\n",
    "        \n",
    "        if self.acc_train_avg is not None and self.loss_train_avg is not None:\n",
    "            print('Train Accuracy: {:.3f} | Loss: {:.3f}'.format(self.acc_train_avg.result(), self.loss_train_avg.result()))\n",
    "        print('Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test_avg.result(), loss_test_avg.result()))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D:\n",
    "    \n",
    "    def __init__(self, discriminator=None):\n",
    "        \n",
    "        # make FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "        if discriminator is not None:\n",
    "            self.model = discriminator\n",
    "        else:\n",
    "            self.model = self.discriminator_model()\n",
    "            \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define entropies\n",
    "        self.cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        self.bin_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            \n",
    "        # setup checkpointing\n",
    "        self.ckpt = None\n",
    "        self.manager = None\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Discriminator model\n",
    "    \n",
    "    def discriminator_model(self):\n",
    "        model = start_piece_(input_shape, filters)\n",
    "        model = approximator_piece_(model, depth, filters)\n",
    "        model = end_piece_(model, dense, num_classes)\n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Loss\n",
    "    \n",
    "    def loss(self, fake_discrimination, labels):\n",
    "        matches = self.matches_labels(fake_discrimination, labels, loop_times=0)\n",
    "        # we want the discriminator to NOT be fooled by these fake images\n",
    "        cross_entropy = self.bin_cross_entropy(tf.zeros_like(matches), matches)\n",
    "        return cross_entropy\n",
    "    \n",
    "    def entropy(self, y_true, y_pred):\n",
    "        return self.cat_cross_entropy(y_true, y_pred)\n",
    "        \n",
    "    def matches_labels(self, fake_output, labels, loop_times=0):\n",
    "        '''\n",
    "        Only works if the Discriminator is already trained on real images!!\n",
    "        1. Performs a softmax -> onehot conversion (differentiable approx.)\n",
    "        2. Multiplies this by the onehot version of the onehot attack label\n",
    "        3. Sums to reduce dimension\n",
    "        \n",
    "        - if the sum is close to 1, the nn thinks that the image is a part of the attack class\n",
    "        - if the sum is close to 0, the nn thinks that the image is not of the attack class\n",
    "        - the sum should not be in between, due to the onehot conversion we perform in step 1\n",
    "        '''\n",
    "        # 1.\n",
    "        my_power = 8\n",
    "        for i in range(loop_times):\n",
    "            fake_output = self.soft_onehot(fake_output)\n",
    "        \n",
    "        # 2.\n",
    "        matches = tf.math.multiply(fake_output, labels)\n",
    "        \n",
    "        # 3.\n",
    "        reduced = tf.math.reduce_sum(matches, axis=-1)\n",
    "        \n",
    "        return reduced\n",
    "        \n",
    "    def soft_onehot(self, softmax, my_power=8):\n",
    "        '''\n",
    "        Shown to not really work... vanishing gradients problem\n",
    "        '''\n",
    "        soft_extreme = softmax ** my_power\n",
    "        norm = tf.reduce_sum(soft_extreme, axis=-1)\n",
    "        almost_onehot = tf.math.divide(soft_extreme, tf.reshape(norm, (-1, 1)))\n",
    "        return almost_onehot\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        ckpt_save_folder = os.path.join('checkpoints', 'it_{}'.format(iteration), discriminator_checkpoint_folder)\n",
    "        os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "        if self.ckpt is not None:\n",
    "            del self.ckpt\n",
    "        if self.manager is not None:\n",
    "            del self.manager\n",
    "\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "        \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved D checkpoint: {}\".format(save_path))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        iteration_offset = 0\n",
    "        parent_folder = os.path.join('checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, discriminator_checkpoint_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), discriminator_checkpoint_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                iteration_offset = largest_it\n",
    "                print('Restored D to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found for D, starting with a fresh network')\n",
    "        else:\n",
    "            if load_default:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'default', discriminator_checkpoint_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), discriminator_checkpoint_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    iteration_offset = it_restore\n",
    "                print('Restored D to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        return iteration_offset\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluation\n",
    "\n",
    "    def discriminate(self, generated_images, training=True):\n",
    "        return self.model(generated_images, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G:\n",
    "    \n",
    "    def __init__(self, noise_dim):\n",
    "        self.noise_dim = noise_dim\n",
    "        \n",
    "        # make FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "        self.model = self.generator_model()\n",
    "            \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define entropies\n",
    "        self.cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        self.bin_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            \n",
    "        # setup checkpointing\n",
    "        self.ckpt = None\n",
    "        self.manager = None\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Discriminator model\n",
    "    \n",
    "    def generator_model(self):\n",
    "        ACTIVATION = keras.layers.Activation(\"tanh\")\n",
    "        \n",
    "        # Prepare noise input\n",
    "        input_z = keras.layers.Input((self.noise_dim,))\n",
    "        dense_z_1 = keras.layers.Dense(1024)(input_z)\n",
    "        act_z_1 = ACTIVATION(dense_z_1)\n",
    "        dense_z_2 = keras.layers.Dense(128 * 7 * 7)(act_z_1)\n",
    "        bn_z_1 = keras.layers.BatchNormalization()(dense_z_2)\n",
    "        reshape_z = keras.layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,))(bn_z_1)\n",
    "\n",
    "        # Prepare Conditional (label) input\n",
    "        input_c = keras.layers.Input((num_classes,))\n",
    "        dense_c_1 = keras.layers.Dense(1024)(input_c)\n",
    "        act_c_1 = ACTIVATION(dense_c_1)\n",
    "        dense_c_2 = keras.layers.Dense(128 * 7 * 7)(act_c_1)\n",
    "        bn_c_1 = keras.layers.BatchNormalization()(dense_c_2)\n",
    "        reshape_c = keras.layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,))(bn_c_1)\n",
    "\n",
    "        # Combine input source\n",
    "        concat_z_c = keras.layers.Concatenate()([reshape_z, reshape_c])\n",
    "\n",
    "        # Image generation with the concatenated inputs\n",
    "        up_1 = keras.layers.UpSampling2D(size=(2, 2))(concat_z_c)\n",
    "        conv_1 = keras.layers.Conv2D(64, (5, 5), padding='same')(up_1)\n",
    "        act_1 = ACTIVATION(conv_1)\n",
    "        up_2 = keras.layers.UpSampling2D(size=(2, 2))(act_1)\n",
    "        conv_2 = keras.layers.Conv2D(1, (5, 5), padding='same')(up_2)\n",
    "        act_2 = keras.layers.Activation(\"tanh\")(conv_2)\n",
    "        model = keras.models.Model(inputs=[input_z, input_c], outputs=act_2)\n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Loss\n",
    "    \n",
    "    def loss(self, fake_discrimination, labels):\n",
    "        # we want the discriminator to be fooled by these fake images\n",
    "        cross_entropy = self.cat_cross_entropy(fake_discrimination, labels)\n",
    "        return cross_entropy\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        ckpt_save_folder = os.path.join('checkpoints', 'it_{}'.format(iteration), discriminator_checkpoint_folder)\n",
    "        os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "        if self.ckpt is not None:\n",
    "            del self.ckpt\n",
    "        if self.manager is not None:\n",
    "            del self.manager\n",
    "\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "        \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved D checkpoint: {}\".format(save_path))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        iteration_offset = 0\n",
    "        parent_folder = os.path.join('checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, discriminator_checkpoint_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), discriminator_checkpoint_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                iteration_offset = largest_it\n",
    "                print('Restored D to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found for D, starting with a fresh network')\n",
    "        else:\n",
    "            if load_default:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'default', discriminator_checkpoint_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), discriminator_checkpoint_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    iteration_offset = it_restore\n",
    "                print('Restored D to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        return iteration_offset\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluation\n",
    "        \n",
    "    def generate(self, inputs, training=True):\n",
    "        generated_images = self.model(inputs, training=training)\n",
    "        return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    \n",
    "    def __init__(self, gan_training_params, discriminator=None):\n",
    "        \n",
    "        self.noise_dim = gan_training_params['noise_dim']\n",
    "        self.batch_size = gan_training_params['batch_size']\n",
    "        self.save_ckpts = True\n",
    "        \n",
    "#         # make FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "#         if discriminator is not None:\n",
    "#             self.discriminator = discriminator\n",
    "#         else:\n",
    "#             self.discriminator = self.discriminator_model()\n",
    "#         self.generator = self.generator_model()\n",
    "        \n",
    "#         self.cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "#         self.bin_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        \n",
    "        # define optimizers\n",
    "#         self.generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "#         self.discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "        # define the D and G models\n",
    "        self.d = D(discriminator)\n",
    "        self.g = G(self.noise_dim)\n",
    "        \n",
    "        # define metrics\n",
    "        self.gen_loss_train_avg = None\n",
    "        self.gen_acc_train_avg = None\n",
    "        self.disc_loss_train_avg = None\n",
    "        \n",
    "        # seed for image generation\n",
    "        num_examples_to_generate = 16\n",
    "        self.seed = tf.random.normal([num_examples_to_generate, self.noise_dim])\n",
    "        \n",
    "        # labels for image generation\n",
    "        label_pattern = [i % (num_classes) for i in range(num_examples_to_generate)]\n",
    "        self.eval_labels = tf.one_hot(label_pattern, num_classes, dtype=tf.dtypes.float32)\n",
    "        \n",
    "        # setup checkpointing\n",
    "#         self.discriminator_ckpt = None\n",
    "#         self.discriminator_manager = None\n",
    "#         self.generator_ckpt = None\n",
    "#         self.generator_manager = None\n",
    "        self.internal_iteration = None\n",
    "        self.iteration_offset = 0\n",
    "        \n",
    "        # initialize d and g\n",
    "        self.d.init_ckpt()\n",
    "        self.g.init_ckpt()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Label matching\n",
    "        \n",
    "#     def soft_onehot(self, softmax, my_power=8):\n",
    "#         '''\n",
    "#         Shown to not really work... vanishing gradients\n",
    "#         '''\n",
    "#         soft_extreme = softmax ** my_power\n",
    "#         norm = tf.reduce_sum(soft_extreme, axis=-1)\n",
    "#         almost_onehot = tf.math.divide(soft_extreme, tf.reshape(norm, (-1, 1)))\n",
    "#         return almost_onehot\n",
    "        \n",
    "#     def matches_labels(self, fake_output, labels, loop_times=3):\n",
    "#         '''\n",
    "#         Only works if the Discriminator is already trained on real images!!\n",
    "#         1. Performs a softmax -> onehot conversion (differentiable approx.)\n",
    "#         2. Multiplies this by the onehot version of the onehot attack label\n",
    "#         3. Sums to reduce dimension\n",
    "        \n",
    "#         - if the sum is close to 1, the nn thinks that the image is a part of the attack class\n",
    "#         - if the sum is close to 0, the nn thinks that the image is not of the attack class\n",
    "#         - the sum should not be in between, due to the onehot conversion we perform in step 1\n",
    "#         '''\n",
    "#         # 1.\n",
    "#         my_power = 8\n",
    "#         for i in range(loop_times):\n",
    "#             fake_output = self.soft_onehot(fake_output)\n",
    "        \n",
    "#         # 2.\n",
    "#         matches = tf.math.multiply(fake_output, labels)\n",
    "        \n",
    "#         # 3.\n",
    "#         reduced = tf.math.reduce_sum(matches, axis=-1)\n",
    "        \n",
    "#         return reduced\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Discriminator\n",
    "    # - since we know the label\n",
    "    \n",
    "#     def discriminator_model(self):\n",
    "#         model = start_piece_(input_shape, filters)\n",
    "#         model = approximator_piece_(model, depth, filters)\n",
    "#         model = end_piece_(model, dense, num_classes)\n",
    "#         return model\n",
    "    \n",
    "#     def discriminator_loss(self, fake_discrimination, labels):\n",
    "#         matches = self.matches_labels(fake_discrimination, labels, loop_times=0)\n",
    "#         # we want the discriminator to NOT be fooled by these fake images\n",
    "#         cross_entropy = self.bin_cross_entropy(tf.zeros_like(matches), matches)\n",
    "#         return cross_entropy\n",
    "    \n",
    "#     def discriminator_entropy(self, y_true, y_pred):\n",
    "#         return self.cat_cross_entropy(y_true, y_pred)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Generator\n",
    "\n",
    "#     def generator_model(self):\n",
    "#         ACTIVATION = keras.layers.Activation(\"tanh\")\n",
    "        \n",
    "#         # Prepare noise input\n",
    "#         input_z = keras.layers.Input((self.noise_dim,))\n",
    "#         dense_z_1 = keras.layers.Dense(1024)(input_z)\n",
    "#         act_z_1 = ACTIVATION(dense_z_1)\n",
    "#         dense_z_2 = keras.layers.Dense(128 * 7 * 7)(act_z_1)\n",
    "#         bn_z_1 = keras.layers.BatchNormalization()(dense_z_2)\n",
    "#         reshape_z = keras.layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,))(bn_z_1)\n",
    "\n",
    "#         # Prepare Conditional (label) input\n",
    "#         input_c = keras.layers.Input((num_classes,))\n",
    "#         dense_c_1 = keras.layers.Dense(1024)(input_c)\n",
    "#         act_c_1 = ACTIVATION(dense_c_1)\n",
    "#         dense_c_2 = keras.layers.Dense(128 * 7 * 7)(act_c_1)\n",
    "#         bn_c_1 = keras.layers.BatchNormalization()(dense_c_2)\n",
    "#         reshape_c = keras.layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,))(bn_c_1)\n",
    "\n",
    "#         # Combine input source\n",
    "#         concat_z_c = keras.layers.Concatenate()([reshape_z, reshape_c])\n",
    "\n",
    "#         # Image generation with the concatenated inputs\n",
    "#         up_1 = keras.layers.UpSampling2D(size=(2, 2))(concat_z_c)\n",
    "#         conv_1 = keras.layers.Conv2D(64, (5, 5), padding='same')(up_1)\n",
    "#         act_1 = ACTIVATION(conv_1)\n",
    "#         up_2 = keras.layers.UpSampling2D(size=(2, 2))(act_1)\n",
    "#         conv_2 = keras.layers.Conv2D(1, (5, 5), padding='same')(up_2)\n",
    "#         act_2 = keras.layers.Activation(\"tanh\")(conv_2)\n",
    "#         model = keras.models.Model(inputs=[input_z, input_c], outputs=act_2)\n",
    "#         return model\n",
    "\n",
    "#     def generator_loss(self, fake_discrimination, labels):\n",
    "#         # we want the discriminator to be fooled by these fake images\n",
    "#         cross_entropy = self.cat_cross_entropy(fake_discrimination, labels)\n",
    "#         return cross_entropy\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Trainer\n",
    "        \n",
    "    def train(self, iteration):\n",
    "        # setup checkpointing\n",
    "        self.setup_ckpts(iteration)\n",
    "        \n",
    "        # initialize the metrics each new epoch\n",
    "        if self.gen_acc_train_avg is not None:\n",
    "            del self.gen_acc_train_avg\n",
    "        if self.gen_loss_train_avg is not None:\n",
    "            del self.gen_loss_train_avg\n",
    "        if self.disc_loss_train_avg is not None:\n",
    "            del self.disc_loss_train_avg\n",
    "        \n",
    "        self.gen_loss_train_avg = tf.keras.metrics.Mean()\n",
    "        self.gen_acc_train_avg = tf.keras.metrics.Accuracy()\n",
    "        self.disc_loss_train_avg = tf.keras.metrics.Mean()\n",
    "        \n",
    "        pbar = tqdm_notebook(total=200) # why is this governed by dataset still?\n",
    "        \n",
    "        for i in range(200):\n",
    "            self.train_step(train_discriminator=(self.gen_acc_train_avg.result() >= 0.95),\n",
    "                            train_generator=(self.gen_acc_train_avg.result() < 0.95))\n",
    "            pbar.update(1)\n",
    "            pbar.set_description('g_acc={:.2f}, g_loss={:.2f}, d_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                                     self.gen_loss_train_avg.result(),\n",
    "                                                                                     self.disc_loss_train_avg.result()))\n",
    "        \n",
    "        # save checkpoints\n",
    "        self.checkpoint()\n",
    "    \n",
    "    def train_step(self, train_discriminator, train_generator):\n",
    "        noise = tf.random.normal([self.batch_size, self.noise_dim])\n",
    "        random_classes = tf.random.uniform(shape=(self.batch_size, ), maxval=num_classes, dtype=tf.dtypes.int32)\n",
    "        labels = tf.one_hot(random_classes, num_classes, dtype=tf.dtypes.float32)\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_images = self.g.generate([noise, labels], training=True)\n",
    "            \n",
    "            # convert the [-1 1] image into [0 1] (due to tanh activation)\n",
    "            generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "            # we don't evaluate any real images in our case\n",
    "            #real_output = self.discriminator(images, training=True)\n",
    "            fake_discrimination = self.d.discriminate(generated_images, training=True)\n",
    "\n",
    "            gen_loss = self.g.loss(fake_discrimination, labels)\n",
    "            disc_loss = self.d.loss(fake_discrimination, labels)\n",
    "            \n",
    "            # evaluate accuracy and append acc and loss to arrays\n",
    "            self.gen_loss_train_avg(gen_loss)\n",
    "            self.gen_acc_train_avg(tf.argmax(labels, 1), tf.argmax(fake_discrimination, 1))\n",
    "            self.disc_loss_train_avg(disc_loss)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.g.model.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.d.model.trainable_variables)\n",
    "\n",
    "        if train_generator:\n",
    "            self.g.optimizer.apply_gradients(zip(gradients_of_generator, self.g.model.trainable_variables))\n",
    "        if train_discriminator:\n",
    "            self.d.optimizer.apply_gradients(zip(gradients_of_discriminator, self.d.model.trainable_variables))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "#     def init_ckpts(self):\n",
    "#         self.discriminator_ckpt = tf.train.Checkpoint(optimizer=self.discriminator_optimizer, model=self.discriminator)\n",
    "#         self.generator_ckpt = tf.train.Checkpoint(optimizer=self.generator_optimizer, model=self.generator)\n",
    "    \n",
    "    def setup_ckpts(self, iteration):\n",
    "        if self.save_ckpts:\n",
    "            # setup fresh checkpointer every new iteration\n",
    "            if self.internal_iteration is None or (self.internal_iteration != (iteration + self.iteration_offset)):\n",
    "                self.internal_iteration = iteration + self.iteration_offset\n",
    "                self.d.setup_ckpt(self.internal_iteration)\n",
    "                self.g.setup_ckpt(self.internal_iteration)\n",
    "        \n",
    "#     def setup_discriminator_ckpt(self, iteration):\n",
    "#         ckpt_save_folder = os.path.join('checkpoints', 'it_{}'.format(iteration), discriminator_checkpoint_folder)\n",
    "#         os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "#         if self.discriminator_ckpt is not None:\n",
    "#             del self.discriminator_ckpt\n",
    "#         if self.discriminator_manager is not None:\n",
    "#             del self.discriminator_manager\n",
    "\n",
    "#         self.discriminator_ckpt = tf.train.Checkpoint(optimizer=self.discriminator_optimizer, model=self.discriminator)\n",
    "#         self.discriminator_manager = tf.train.CheckpointManager(self.discriminator_ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "        \n",
    "#     def setup_generator_ckpt(self, iteration):\n",
    "#         ckpt_save_folder = os.path.join('checkpoints', 'it_{}'.format(iteration), generator_checkpoint_folder)\n",
    "#         os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "#         if self.generator_ckpt is not None:\n",
    "#             del self.generator_ckpt\n",
    "#         if self.generator_manager is not None:\n",
    "#             del self.generator_manager\n",
    "\n",
    "#         self.generator_ckpt = tf.train.Checkpoint(optimizer=self.generator_optimizer, model=self.generator)\n",
    "#         self.generator_manager = tf.train.CheckpointManager(self.generator_ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "    \n",
    "    def checkpoint(self):\n",
    "        if self.save_ckpts:\n",
    "            self.d.checkpoint()\n",
    "            self.g.checkpoint()\n",
    "        \n",
    "#     def checkpoint_discriminator(self):\n",
    "#         save_path = self.discriminator_manager.save()\n",
    "#         print(\"Saved D checkpoint: {}\".format(save_path))\n",
    "        \n",
    "#     def checkpoint_generator(self):\n",
    "#         save_path = self.generator_manager.save()\n",
    "#         print(\"Saved G checkpoint: {}\".format(save_path))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        tmp_offset = self.d.restore(it_restore, load_default)\n",
    "        self.iteration_offset = self.g.restore(it_restore, load_default)\n",
    "        assert tmp_offset == self.iteration_offset\n",
    "        \n",
    "#     def restore_discriminator(self, it_restore=None, load_default=False):\n",
    "#         parent_folder = os.path.join('checkpoints')\n",
    "#         if it_restore is None and not load_default:\n",
    "#             # find the most recent iteration and checkpoint\n",
    "#             largest_it = None\n",
    "#             for d in glob(os.path.join(parent_folder, '*')):\n",
    "#                 if os.path.isfile(os.path.join(d, discriminator_checkpoint_folder, 'checkpoint')):\n",
    "#                     # passed, valid checkpoint\n",
    "#                     if '_' in d:\n",
    "#                         # passed, valid iteration folder\n",
    "#                         it = int(d.split('_')[1])\n",
    "#                         if largest_it is None or it > largest_it:\n",
    "#                             largest_it = it\n",
    "#             if largest_it is not None:\n",
    "#                 checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), discriminator_checkpoint_folder)\n",
    "#                 self.discriminator_ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "#                 self.iteration_offset = largest_it\n",
    "#                 print('Restored D to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "#             else:\n",
    "#                 print('No weights found for D, starting with a fresh network')\n",
    "#         else:\n",
    "#             if load_default:\n",
    "#                 checkpoint_directory = os.path.join(parent_folder, 'default', discriminator_checkpoint_folder)\n",
    "#             else:\n",
    "#                 checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), discriminator_checkpoint_folder)\n",
    "#             if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "#                 self.discriminator_ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "#                 if it_restore is not None:\n",
    "#                     self.iteration_offset = it_restore\n",
    "#                 print('Restored D to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "#             else:\n",
    "#                 print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        \n",
    "#     def restore_generator(self, it_restore=None, load_default=False):\n",
    "#         parent_folder = os.path.join('checkpoints')\n",
    "#         if it_restore is None and not load_default:\n",
    "#             # find the most recent iteration and checkpoint\n",
    "#             largest_it = None\n",
    "#             for d in glob(os.path.join(parent_folder, '*')):\n",
    "#                 if os.path.isfile(os.path.join(d, generator_checkpoint_folder, 'checkpoint')):\n",
    "#                     # passed, valid checkpoint\n",
    "#                     if '_' in d:\n",
    "#                         # passed, valid iteration folder\n",
    "#                         it = int(d.split('_')[1])\n",
    "#                         if largest_it is None or it > largest_it:\n",
    "#                             largest_it = it\n",
    "#             if largest_it is not None:\n",
    "#                 checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), generator_checkpoint_folder)\n",
    "#                 self.generator_ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "#                 self.iteration_offset = largest_it\n",
    "#                 print('Restored G to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "#             else:\n",
    "#                 print('No weights found for G, starting with a fresh network')\n",
    "#         else:\n",
    "#             if load_default:\n",
    "#                 checkpoint_directory = os.path.join(parent_folder, 'default', generator_checkpoint_folder)\n",
    "#             else:\n",
    "#                 checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), generator_checkpoint_folder)\n",
    "#             if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "#                 self.generator_ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "#                 if it_restore is not None:\n",
    "#                     self.iteration_offset = it_restore\n",
    "#                 print('Restored G to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "#             else:\n",
    "#                 print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "            \n",
    "    def generate_images(self):\n",
    "        # Notice `training` is set to False.\n",
    "        # This is so all layers run in inference mode (batchnorm).\n",
    "        \n",
    "        # make the number of \n",
    "        \n",
    "        predictions = self.g.generate([self.seed, self.eval_labels], training=False)\n",
    "        predictions = 0.5 * predictions + 0.5\n",
    "\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "        for i in range(predictions.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            plt.imshow(predictions[i, :, :, 0] * 255.0, cmap='gray')\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    def evaluate_gan(self, dataset):\n",
    "        \n",
    "        if self.gen_acc_train_avg is not None:\n",
    "            print('G Train Acc:     {:.3f} | Loss: {:.3f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                self.gen_loss_train_avg.result()))\n",
    "            print('D Train Acc:     NaN   | Loss: {:.3f}'.format(self.disc_loss_train_avg.result()))\n",
    "        disc_acc_test = self.evaluate_discriminator(dataset)\n",
    "        return disc_acc_test\n",
    "        \n",
    "    def evaluate_discriminator(self, dataset):\n",
    "        \n",
    "        x, y = dataset\n",
    "        \n",
    "        acc_test_avg = tf.keras.metrics.Accuracy()\n",
    "        loss_test_avg = tf.keras.metrics.Mean()\n",
    "        for i in range(0, len(x), self.batch_size):\n",
    "            # get batch\n",
    "            x_batch = x[i:i+self.batch_size]\n",
    "            y_batch = y[i:i+self.batch_size]\n",
    "            \n",
    "            # evaluate\n",
    "            logits = self.d.discriminate(x_batch, training=False)\n",
    "            acc_test_avg(tf.argmax(y_batch, 1), tf.argmax(logits, 1))\n",
    "            loss_test_avg(self.d.entropy(y_batch, logits))\n",
    "            \n",
    "        print('D Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test_avg.result(), loss_test_avg.result()))\n",
    "        print()\n",
    "        \n",
    "        return acc_test_avg.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemTrainer:\n",
    "    \n",
    "    def __init__(self, split_training_params, gan_training_params):\n",
    "        # Split Learning params:\n",
    "        self.split_epochs = split_training_params['epochs']\n",
    "        self.split_train_dataset = split_training_params['train_dataset']\n",
    "        assert self.split_train_dataset is not None\n",
    "        self.split_test_dataset = split_training_params['test_dataset']\n",
    "        assert self.split_test_dataset is not None\n",
    "        \n",
    "        # GAN params:\n",
    "        self.gan_epochs = gan_training_params['epochs']\n",
    "        self.use_blackbox= gan_training_params['use_blackbox']\n",
    "        \n",
    "        # create the Split Learning Trainer\n",
    "        self.split = SplitLearning(split_training_params)\n",
    "        \n",
    "        # create the GAN Trainer\n",
    "        if self.use_blackbox:\n",
    "            # treat the Split Learning NN as a Black-box\n",
    "            self.gan = GAN(gan_training_params)\n",
    "        else:\n",
    "            # use the Split Learning NN as the GAN's Discriminator as an easy check:\n",
    "            self.gan = GAN(gan_training_params, discriminator=self.split.model)\n",
    "        \n",
    "    def query_blackbox(self):\n",
    "        '''\n",
    "        Send images generated by the GAN into the Split Learning model (TODO)\n",
    "        '''\n",
    "        pass\n",
    "        \n",
    "    def train_system(self):\n",
    "        \n",
    "        iteration = 1\n",
    "        \n",
    "        # Train the Split Learning model for 25 epochs:\n",
    "        print('~'*40)\n",
    "        print('Training Split Learning')\n",
    "        for e in tqdm_notebook(range(self.split_epochs)):\n",
    "            if e == 0:\n",
    "                print('~'*40)\n",
    "            self.split.train(self.split_train_dataset, iteration)\n",
    "            self.split.evaluate(self.split_test_dataset)\n",
    "            \n",
    "        if not EASY_MODE:\n",
    "            # Refine the Discriminator in the GAN, since Split Learning is a Black-box:\n",
    "            print('~'*40)\n",
    "            print('Refining Discriminator')\n",
    "            print('~'*40)\n",
    "            # TODO\n",
    "        \n",
    "        # Train the GAN for X epochs, and see if the generator can produce anything:\n",
    "        print('~'*40)\n",
    "        print('Training GAN')\n",
    "        for e in tqdm_notebook(range(self.gan_epochs)):\n",
    "            if e == 0:\n",
    "                print('~'*40)\n",
    "            self.gan.train(iteration)\n",
    "            self.gan.generate_images()\n",
    "            \n",
    "    def train_sl(self):\n",
    "        iteration = 1\n",
    "        \n",
    "        # Train the Split Learning model for 25 epochs:\n",
    "        print('~'*40)\n",
    "        print('Training Split Learning')\n",
    "        for e in tqdm_notebook(range(self.split_epochs)):\n",
    "            if e == 0:\n",
    "                print('~'*40)\n",
    "            self.split.train(self.split_train_dataset, iteration)\n",
    "            self.split.evaluate(self.split_test_dataset)\n",
    "            \n",
    "    def train_gan(self, original_disc_acc, reset_d_every_epoch=False):\n",
    "        \n",
    "        iteration = 1\n",
    "        \n",
    "        # Train the GAN for X epochs, and see if the generator can produce anything:\n",
    "        print('~'*40)\n",
    "        print('Training GAN')\n",
    "        for e in tqdm_notebook(range(self.gan_epochs)):\n",
    "            if e == 0:\n",
    "                print('~'*40)\n",
    "            self.gan.train(iteration)\n",
    "            self.gan.generate_images()\n",
    "            \n",
    "            disc_acc_test = self.gan.evaluate_gan(self.split_test_dataset)\n",
    "            \n",
    "            if reset_d_every_epoch or disc_acc_test < original_disc_acc * 0.8:\n",
    "                # reset D back to the original weights, so as not to diverge D too much over training time\n",
    "                self.gan.restore_discriminator(load_default=True)\n",
    "                self.gan.evaluate_discriminator(self.split_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over all attack classes to see if we can estimate all classes from D!\n",
    "\n",
    "def test_GAN():\n",
    "    print('='*40)\n",
    "    print('Training GAN for attacking ANY class:')\n",
    "    print('='*40)\n",
    "\n",
    "    slg = SystemTrainer(split_training_params, gan_training_params)\n",
    "\n",
    "    # load pretrained weights if they exist:\n",
    "    slg.split.restore()# (load_default=True, it_restore=1)\n",
    "    slg.gan.restore()# (load_default=True, it_restore=1)\n",
    "    # slg.gan.save_ckpts = False # don't save the training ckpts for this test\n",
    "\n",
    "    # This SHOULD have the restored weights from split\n",
    "    print()\n",
    "    print('Double checking that the D in the GAN has been trained:')\n",
    "    original_disc_acc = slg.gan.evaluate_discriminator(slg.split_test_dataset)\n",
    "    print()\n",
    "\n",
    "    slg.train_gan(original_disc_acc=original_disc_acc, reset_d_every_epoch=False)\n",
    "    \n",
    "    del slg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Training GAN for attacking ANY class:\n",
      "========================================\n",
      "Restored latest checkpoint from checkpoints\\it_1\\blackbox_checkpoint\n",
      "No weights found for D, starting with a fresh network\n",
      "No weights found for G, starting with a fresh network\n",
      "\n",
      "Double checking that the D in the GAN has been trained:\n",
      "D Test Accuracy: 0.152 | Loss: 2.303\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Training GAN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4585ca26d3b340b89d447ee72a4cf0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c2419f5eef4bd9915ca8f8a9a1060c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved D checkpoint: checkpoints\\it_1\\discriminator_checkpoint\\ckpt-1\n",
      "Saved G checkpoint: checkpoints\\it_1\\generator_checkpoint\\ckpt-1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G Train Acc:     0.817 | Loss: 2.359\n",
      "D Train Acc:     NaN   | Loss: 0.746\n",
      "D Test Accuracy: 0.152 | Loss: 2.303\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fa06df4ed84055abd2d18368d05284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-8e06b600e7a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_GAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-39-c770ccd0d32f>\u001b[0m in \u001b[0;36mtest_GAN\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mslg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_gan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_disc_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moriginal_disc_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset_d_every_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mslg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-da118c051ba7>\u001b[0m in \u001b[0;36mtrain_gan\u001b[1;34m(self, original_disc_acc, reset_d_every_epoch)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'~'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-681ba542ff31>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, iteration)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             self.train_step(train_discriminator=(self.gen_acc_train_avg.result() >= 0.95),\n\u001b[1;32m--> 163\u001b[1;33m                             train_generator=(self.gen_acc_train_avg.result() < 0.95))\n\u001b[0m\u001b[0;32m    164\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             pbar.set_description('g_acc={:.2f}, g_loss={:.2f}, d_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
      "\u001b[1;32m<ipython-input-37-681ba542ff31>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, train_discriminator, train_generator)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise_dim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mrandom_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[1;34m(indices, depth, on_value, off_value, axis, dtype, name)\u001b[0m\n\u001b[0;32m   3643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3644\u001b[0m     return gen_array_ops.one_hot(indices, depth, on_value, off_value, axis,\n\u001b[1;32m-> 3645\u001b[1;33m                                  name)\n\u001b[0m\u001b[0;32m   3646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[1;34m(indices, depth, on_value, off_value, axis, name)\u001b[0m\n\u001b[0;32m   5537\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   5538\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"OneHot\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5539\u001b[1;33m         tld.op_callbacks, indices, depth, on_value, off_value, \"axis\", axis)\n\u001b[0m\u001b[0;32m   5540\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5541\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slg = SystemTrainer(split_training_params, noise_dim, gan_batch_size, gan_epochs, use_blackbox=False)\n",
    "# slg.train_sl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
