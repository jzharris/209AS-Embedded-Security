{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison - Descriminator Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a network to mimic the Blackbox version, using all clients in the training set to perform the task. We use the test set to evaluate how close the Descriminator model is from the Blackbox version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Input\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import os.path\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility \n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "num_classes = 10\n",
    "max_epochs = 25\n",
    "save_every = 1\n",
    "descriminator_epochs = 25\n",
    "\n",
    "# client params\n",
    "clients_per_class = 100                         # number of clients per label. Each client only has access to one label\n",
    "                                                # - each unique class is divided into X number of subsets\n",
    "    \n",
    "minibatch_size = None                           # number of samples to operate on at one time\n",
    "                                                # - can vary to optimize computing requirements\n",
    "                                                # - if None, will evaluate the client's whole batch regardless of its size\n",
    "    \n",
    "batches_per_train_step = 20                     # after averaging the gradients from X clients, we will apply them to the model\n",
    "\n",
    "shuffle_clients = True\n",
    "\n",
    "# dataset params\n",
    "separated_folder = \"./separated_dataset\"\n",
    "os.makedirs(separated_folder, exist_ok=True)\n",
    "separated_train_path = os.path.join(separated_folder, \"train_separated.pkl\")\n",
    "separated_test_path = os.path.join(separated_folder, \"test_separated.pkl\")\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "target_rows, target_cols = 28, 28    # governed by the chosen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if target_rows != img_rows or target_cols != img_cols:\n",
    "    # resize x_train\n",
    "    x_train_resized = []\n",
    "    for x_ in x_train:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_train_resized.append(x_)\n",
    "    x_train = np.asarray(x_train_resized)\n",
    "\n",
    "    # resize x_test\n",
    "    x_test_resized = []\n",
    "    for x_ in x_test:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_test_resized.append(x_)\n",
    "    x_test = np.asarray(x_test_resized)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "y: (60000, 10) (10000, 10)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "print('X:', x_train.shape, x_test.shape)\n",
    "print('y:', y_train.shape, y_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training seperation\n",
      "loaded testing seperation\n"
     ]
    }
   ],
   "source": [
    "# Separating the data by class\n",
    "if os.path.isfile(separated_train_path):\n",
    "    with open(separated_train_path, 'rb') as f:\n",
    "        x_train_dict, y_train_dict = pickle.load(f)\n",
    "        print('loaded training seperation')\n",
    "else:\n",
    "    x_train_dict = {}\n",
    "    y_train_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_train_dict[target_label] = []\n",
    "        y_train_dict[target_label] = []\n",
    "        for i, label in enumerate(y_train):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_train_dict[target_label].append(x_train[i])\n",
    "                y_train_dict[target_label].append(y_train[i])\n",
    "    \n",
    "    with open(separated_train_path, 'wb') as f:\n",
    "        pickle.dump([x_train_dict, y_train_dict], f)\n",
    "        print('saved training seperation')\n",
    "\n",
    "if os.path.isfile(separated_test_path):\n",
    "    with open(separated_test_path, 'rb') as f:\n",
    "        x_test_dict, y_test_dict = pickle.load(f)\n",
    "        print('loaded testing seperation')\n",
    "else:\n",
    "    x_test_dict = {}\n",
    "    y_test_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_test_dict[target_label] = []\n",
    "        y_test_dict[target_label] = []\n",
    "        for i, label in enumerate(y_test):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_test_dict[target_label].append(x_test[i])\n",
    "                y_test_dict[target_label].append(y_test[i])\n",
    "\n",
    "    with open(separated_test_path, 'wb') as f:\n",
    "        pickle.dump([x_test_dict, y_test_dict], f)\n",
    "        print('saved testing seperation')\n",
    "    \n",
    "# convert dicts to lists\n",
    "x_train_seperated = [np.array(x_train_dict[i]) for i in range(10)]\n",
    "y_train_seperated = [np.array(y_train_dict[i]) for i in range(10)]\n",
    "\n",
    "x_test_seperated = [np.array(x_test_dict[i]) for i in range(10)]\n",
    "y_test_seperated = [np.array(y_test_dict[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "plt.figure()\n",
    "plt.title('Data separation per class')\n",
    "plt.bar(x_train_dict.keys(), [len(v) for v in x_train_dict.values()], color='tab:blue')\n",
    "plt.bar(x_test_dict.keys(), [len(v) for v in x_test_dict.values()], color='orange', width=0.6)\n",
    "plt.legend(['x_train', 'x_test'], loc='center right', framealpha=1.0)\n",
    "plt.xlabel('class label')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data into batches for clients to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients per class:  99.6 ~= 100\n",
      "Total number of clients: 996\n",
      "Average batch size: 60.6\n"
     ]
    }
   ],
   "source": [
    "# Separate the data into a long list of batches, each batch representing a client training with that batch of images.\n",
    "# After each batch, a new client will have the opportunity to train their batch of images.\n",
    "# Batches are shuffled to simulate many clients training the model at once.\n",
    "\n",
    "client_counts = {}\n",
    "batch_sizes = {}\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "def ceil(a,b):\n",
    "    return -(-a//b)\n",
    "\n",
    "for class_idx in range(len(x_train_seperated)):\n",
    "    # Get batches from class data:\n",
    "    n_samples_per_class = len(x_train_seperated[class_idx])\n",
    "    samples_per_client = n_samples_per_class / clients_per_class\n",
    "    better_batch_size = int(math.ceil(samples_per_client))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(ceil(n_samples_per_class, better_batch_size)):\n",
    "        x_batches.append((class_idx, x_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        y_batches.append((class_idx, y_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        count += 1\n",
    "    client_counts[class_idx] = count\n",
    "    batch_sizes[class_idx] = better_batch_size\n",
    "        \n",
    "# double check that the clients_per_class is upheld per class\n",
    "# (blue bars should be uniform, orange should change according to class):\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('class label')\n",
    "ax1.set_ylabel('client count', color=color)\n",
    "plt.bar(client_counts.keys(), [v for v in client_counts.values()], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'orange'\n",
    "ax2.set_ylabel('batch size', color=color)  # we already handled the x-label with ax1\n",
    "plt.bar(batch_sizes.keys(), [v for v in batch_sizes.values()], color=color, width=0.6)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylim(0, np.mean([v for v in batch_sizes.values()])*2)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()\n",
    "\n",
    "print('Clients per class:  {} ~= {}'.format(np.mean([v for v in client_counts.values()]), clients_per_class))\n",
    "print('Total number of clients: {}'.format(np.sum([v for v in client_counts.values()])))\n",
    "print('Average batch size: {}'.format(np.mean([v for v in batch_sizes.values()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackbox_model(input_layer, training=True):\n",
    "    h = Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape)(input_layer)\n",
    "    h = Conv2D(64, (3, 3), activation='relu')(h)\n",
    "    h = MaxPooling2D(pool_size=(2, 2))(h)\n",
    "    h = Dropout(0.25)(h, training=training)\n",
    "    h = Flatten()(h)\n",
    "    h = Dense(128, activation='relu')(h)\n",
    "    h = Dropout(0.5)(h, training=training)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(h)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove model complexity, the blackbox and descriminator models will be kept the same\n",
    "\n",
    "def descriminator_model(input_shape, training=True):\n",
    "    model = blackbox_model(input_shape, training)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (target_rows, target_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zharr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\zharr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add nodes for input and blackbox pred label\n",
    "x = Input(shape=input_shape)\n",
    "y_blackbox = blackbox_model(x, training=False)    # NOT training this model\n",
    "\n",
    "# add node for descriminator pred label\n",
    "y_descriminator = descriminator_model(x, training=True)\n",
    "\n",
    "# we don't care about the 'true' label\n",
    "# y_true = Input(shape=(num_classes, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function in terms of y_pred and y_true\n",
    "loss = tf.keras.losses.MSE(y_blackbox, y_descriminator)\n",
    "\n",
    "# Setup metrics to look at during training:\n",
    "_, acc_op = tf.metrics.accuracy(labels=tf.argmax(y_blackbox, 1),\n",
    "                                predictions=tf.argmax(y_descriminator,1))\n",
    "\n",
    "## Optimizer definition - nothing different from any classical example\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-3bc30d66b1bb>:11: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    }
   ],
   "source": [
    "# INSPIRED by https://stackoverflow.com/questions/42156957/how-to-update-model-parameters-with-accumulated-gradients\n",
    "\n",
    "# Fetch a list of our network's trainable parameters.\n",
    "trainable_vars = tf.trainable_variables()\n",
    "\n",
    "# Create variables to store accumulated gradients\n",
    "accumulators = [\n",
    "    tf.Variable(\n",
    "        tf.zeros_like(tv.initialized_value()),\n",
    "        trainable=False\n",
    "    ) for tv in trainable_vars\n",
    "]\n",
    "\n",
    "# Create a variable for counting the number of accumulations\n",
    "accumulation_counter = tf.Variable(0.0, trainable=False)\n",
    "\n",
    "# Compute gradients; grad_pairs contains (gradient, variable) pairs\n",
    "grad_pairs = optimizer.compute_gradients(loss, trainable_vars)\n",
    "\n",
    "# Create operations which add a variable's gradient to its accumulator.\n",
    "accumulate_ops = [\n",
    "    accumulator.assign_add(\n",
    "        grad\n",
    "    ) for (accumulator, (grad, var)) in zip(accumulators, grad_pairs)\n",
    "]\n",
    "\n",
    "# The final accumulation operation is to increment the counter\n",
    "accumulate_ops.append(accumulation_counter.assign_add(1.0))\n",
    "\n",
    "# Update trainable variables by applying the accumulated gradients\n",
    "# divided by the counter. Note: apply_gradients takes in a list of \n",
    "# (grad, var) pairs\n",
    "train_step = optimizer.apply_gradients(\n",
    "    [(accumulator / accumulation_counter, var) \\\n",
    "        for (accumulator, (grad, var)) in zip(accumulators, grad_pairs)]\n",
    ")\n",
    "\n",
    "# Accumulators must be zeroed once the accumulated gradient is applied.\n",
    "zero_ops = [\n",
    "    accumulator.assign(\n",
    "        tf.zeros_like(tv)\n",
    "    ) for (accumulator, tv) in zip(accumulators, trainable_vars)\n",
    "]\n",
    "\n",
    "# Add one last op for zeroing the counter\n",
    "zero_ops.append(accumulation_counter.assign(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the session\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.local_variables_initializer())\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "\n",
      "========================================\n",
      "Training on blackbox_e1\n",
      "..........\n",
      "Epoch 1:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c83c003ed3431eb8650a976fa62d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Accuracy: 0.135 | Loss: 0.000\n",
      "Test Accuracy: 0.059 | Loss: 0.000\n",
      "\n",
      "..........\n",
      "Epoch 2:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d131efba9b014716ad76b4589bb73c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e424364ba029>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     \u001b[1;31m# get the gradients and determine accuracy/loss of model on training dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccumulate_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_minibatch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                     \u001b[1;31m# add acc and loss metrics for batch:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "print('Training the model...\\n')\n",
    "\n",
    "# Loop through every trained blackbox model, and train a new descriminator on it:\n",
    "for blackbox_epoch in range(max_epochs):\n",
    "    if (blackbox_epoch+1) % save_every == 0 or blackbox_epoch+1 == max_epochs:\n",
    "        print('='*40)\n",
    "        print('Training on blackbox_e{}'.format(blackbox_epoch+1))\n",
    "        \n",
    "        for epoch in range(descriminator_epochs):\n",
    "            print('.'*10)\n",
    "            print('Epoch %s:' % str(epoch+1))\n",
    "\n",
    "            batch_idxs = list(range(len(x_batches)))\n",
    "            if shuffle_clients:\n",
    "                # shuffle the batches each time\n",
    "                random.shuffle(batch_idxs)\n",
    "\n",
    "            # Run the zero_ops to initialize the accumulators\n",
    "            sess.run(zero_ops)\n",
    "\n",
    "            # Fancy progress bar\n",
    "            samples = x_train.shape[0]\n",
    "            pbar = tqdm_notebook(total=samples)\n",
    "\n",
    "            # Keep track of average loss/acc per class:\n",
    "            accs_train = []\n",
    "            losses_train = []\n",
    "\n",
    "            # Iterate over clients:\n",
    "            grad_feed_dict = dict()\n",
    "            for i, batch_idx in enumerate(batch_idxs):\n",
    "                class_idx, x_batch = x_batches[batch_idx]\n",
    "                _, y_batch = y_batches[batch_idx]\n",
    "\n",
    "                # Iterate over the client's batch in minibatches:\n",
    "                j = 0\n",
    "                while(j < len(x_batch)):\n",
    "                    if minibatch_size is None:\n",
    "                        # use whole batch (no minibatch)\n",
    "                        x_minibatch = x_batch\n",
    "                        y_minibatch = y_batch\n",
    "                    else:\n",
    "                        x_minibatch = x_batch[j:(j+minibatch_size)]\n",
    "                        y_minibatch = y_batch[j:(j+minibatch_size)]\n",
    "\n",
    "                    # get the gradients and determine accuracy/loss of model on training dataset\n",
    "                    _, acc_train, loss_train = sess.run([accumulate_ops, acc_op, loss], feed_dict={x: x_minibatch})\n",
    "\n",
    "                    # add acc and loss metrics for batch:\n",
    "                    accs_train.append(acc_train)\n",
    "                    losses_train.append(np.mean(loss_train))\n",
    "\n",
    "                    if minibatch_size is None:\n",
    "                        break\n",
    "                    else:\n",
    "                        j += minibatch_size\n",
    "\n",
    "                # increment pbar\n",
    "                pbar.update(len(x_batch))\n",
    "                pbar.set_description('train_acc={:.3f} | train_loss={:.3f}'.format(np.mean(accs_train), np.mean(losses_train)))\n",
    "\n",
    "                # perform a train step every batches_per_train_step number of batches:\n",
    "                if (i > 0 and i % batches_per_train_step == 0) or i == len(batch_idxs) - 1:\n",
    "                    # Run the train_step ops to update the weights based on our accumulated gradients\n",
    "                    sess.run(train_step)\n",
    "\n",
    "                    # zero out the accumulators\n",
    "                    sess.run(zero_ops)\n",
    "\n",
    "            pbar.update(x_train.shape[0] - pbar.n)\n",
    "            pbar.close()\n",
    "\n",
    "            # Calculate test acc and loss\n",
    "            acc_test, loss_test = sess.run([acc_op, loss], feed_dict={x: x_test})\n",
    "\n",
    "            # Update progress bar\n",
    "            print('Train Accuracy: {:.3f} | Loss: {:.3f}'.format(np.mean(accs_train), np.mean(losses_train)))\n",
    "            print('Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test, np.mean(loss_test)))\n",
    "            print()\n",
    "\n",
    "            if epoch+1 == descriminator_epochs:\n",
    "                # checkpoint params\n",
    "                checkpoint_folder = \"./checkpoints/blackbox_e{}__descriminator_e{}\".format(blackbox_epoch+1, epoch+1)\n",
    "                os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "                blackbox_weights_path = os.path.join(checkpoint_folder, 'descriminator_checkpoint.ckpt')\n",
    "\n",
    "                # Save the weights\n",
    "                saver.save(sess, blackbox_weights_path)\n",
    "                #model.save_weights(blackbox_weights_path)\n",
    "                print('Saved the updated weights')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
