{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from tqdm import tqdm\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Input, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility \n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configuration\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "target_rows, target_cols = 28, 28    # governed by the chosen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if target_rows != img_rows or target_cols != img_cols:\n",
    "    # resize x_train\n",
    "    x_train_resized = []\n",
    "    for x_ in x_train:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_train_resized.append(x_)\n",
    "    x_train = np.asarray(x_train_resized)\n",
    "\n",
    "    # resize x_test\n",
    "    x_test_resized = []\n",
    "    for x_ in x_test:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_test_resized.append(x_)\n",
    "    x_test = np.asarray(x_test_resized)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "y: (60000, 10) (10000, 10)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "print('X:', x_train.shape, x_test.shape)\n",
    "print('y:', y_train.shape, y_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb813a6d47440149d6f845895811d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7ab13ce00c4e73abefe15b25b63e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Separating the data by class\n",
    "x_train_dict = {}\n",
    "y_train_dict = {}\n",
    "for target_label in tqdm_notebook(range(10)):\n",
    "    x_train_dict[target_label] = []\n",
    "    y_train_dict[target_label] = []\n",
    "    for i, label in enumerate(y_train):\n",
    "        if list(label).index(1) == target_label:\n",
    "            x_train_dict[target_label].append(x_train[i])\n",
    "            y_train_dict[target_label].append(y_train[i])\n",
    "            \n",
    "x_test_dict = {}\n",
    "y_test_dict = {}\n",
    "for target_label in tqdm_notebook(range(10)):\n",
    "    x_test_dict[target_label] = []\n",
    "    y_test_dict[target_label] = []\n",
    "    for i, label in enumerate(y_test):\n",
    "        if list(label).index(1) == target_label:\n",
    "            x_test_dict[target_label].append(x_test[i])\n",
    "            y_test_dict[target_label].append(y_test[i])\n",
    "            \n",
    "x_train_seperated = [np.array(x_train_dict[i]) for i in range(10)]\n",
    "y_train_seperated = [np.array(y_train_dict[i]) for i in range(10)]\n",
    "x_test_seperated = [np.array(x_test_dict[i]) for i in range(10)]\n",
    "y_test_seperated = [np.array(y_test_dict[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Data separation summary')\n",
    "plt.bar(x_train_dict.keys(), [len(v) for v in x_train_dict.values()], color='b')\n",
    "plt.bar(x_test_dict.keys(), [len(v) for v in x_test_dict.values()], color='g')\n",
    "plt.legend(['x_train', 'x_test'], loc='center right', framealpha=1.0)\n",
    "plt.xlabel('class label')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zharr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\zharr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "input_shape = (target_rows, target_cols, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add place for input and pred label\n",
    "x = Input(shape=input_shape)\n",
    "y_pred = model(x)\n",
    "\n",
    "# add place for truth label\n",
    "y_true = Input(shape=(num_classes, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function in terms of y_pred and y_true\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-c113009530ef>:11: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE from https://stackoverflow.com/questions/46772685/how-to-accumulate-gradients-in-tensorflow\n",
    "\n",
    "## Optimizer definition - nothing different from any classical example\n",
    "opt = tf.train.AdamOptimizer()\n",
    "\n",
    "## Retrieve all trainable variables you defined in your graph\n",
    "tvs = tf.trainable_variables()\n",
    "\n",
    "## Creation of a list of variables with the same shape as the trainable ones\n",
    "# initialized with 0s\n",
    "accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]\n",
    "zero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n",
    "\n",
    "## Calls the compute_gradients function of the optimizer to obtain... the list of gradients\n",
    "gvs = opt.compute_gradients(loss, tvs)\n",
    "\n",
    "## Adds to each element from the list you initialized earlier with zeros its gradient (works because accum_vars and gvs are in the same order)\n",
    "accum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n",
    "\n",
    "## Define the training step (part with variable value update)\n",
    "train_step = opt.apply_gradients([(accum_vars[i], gv[1]) for i, gv in enumerate(gvs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The while loop for training\n",
    "while ...:\n",
    "    # Run the zero_ops to initialize it\n",
    "    sess.run(zero_ops)\n",
    "    # Accumulate the gradients 'n_minibatches' times in accum_vars using accum_ops\n",
    "    for i in xrange(n_minibatches):\n",
    "        sess.run(accum_ops, feed_dict=dict(X: Xs[i], y: ys[i]))\n",
    "    # Run the train_step ops to update the weights based on your accumulated gradients\n",
    "    sess.run(train_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "def loss_fn(y_true, y_pred):\n",
    "    # You can get all the crazy and twisted you \n",
    "    # want here no Keras restrictions this time :)\n",
    "    loss_value = K.sum(K.pow((y_true - y_pred), 2))\n",
    "    return loss_value\n",
    "\n",
    "# Optimizer to run the gradients\n",
    "optimizer = Adam(lr=1e-4)\n",
    "\n",
    "# Graph creation\n",
    "# Creating training flow\n",
    "# Ground truth input, samples or X_t\n",
    "y_true = Input(shape=[0])\n",
    "\n",
    "# Prediction\n",
    "y_pred = model(x)\n",
    "\n",
    "# Loss \n",
    "loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "# Operation for getting \n",
    "# gradients and updating weights\n",
    "updates_op = optimizer.get_updates(\n",
    "    params=model.trainable_weights, \n",
    "    loss=loss)\n",
    "\n",
    "# The graph is created, now we need to call it\n",
    "# this would be similar to tf session.run()\n",
    "train = K.function(\n",
    "    inputs=[x, y_true], \n",
    "    outputs=[loss], \n",
    "    updates=updates_op)\n",
    "\n",
    "test = K.function(\n",
    "    inputs=[x, y_true], \n",
    "    outputs=[loss])\n",
    "\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch %s:' % epoch)\n",
    "\n",
    "    # Fancy progress bar\n",
    "    pbar = tqdm(range(len(samples)))\n",
    "\n",
    "    # Storing losses for computing mean\n",
    "    losses_train = []\n",
    "\n",
    "    # Batch loop: batch size=1\n",
    "    for idx in pbar:\n",
    "        sample = samples[idx]\n",
    "        target = targets[idx]\n",
    "\n",
    "        # Adding batch dim since batch=1\n",
    "        sample = np.expand_dims(sample, axis=0)\n",
    "        target = np.expand_dims(target, axis=0)\n",
    "\n",
    "        # To tensors, input of \n",
    "        # K.function must be tensors\n",
    "        sample = K.constant(sample)\n",
    "        target = K.constant(target)\n",
    "\n",
    "        # Running the train graph\n",
    "        loss_train = train([sample, target])\n",
    "        \n",
    "        # Compute loss mean\n",
    "        losses_train.append(loss_train[0])\n",
    "        loss_train_mean = np.mean(losses_train)\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_description('Train Loss: %.3f' % loss_train_mean)\n",
    "\n",
    "    # Testing\n",
    "    losses_test = []\n",
    "    for idx in range(len(samples_test)):\n",
    "        sample_test = samples_test[idx]\n",
    "        target_test = targets_test[idx]\n",
    "\n",
    "        # Adding batch dim since batch=1\n",
    "        sample_test = np.expand_dims(sample_test, axis=0)\n",
    "        target_test = np.expand_dims(target_test, axis=0)\n",
    "\n",
    "        # To tensors\n",
    "        sample_test = K.constant(sample_test)\n",
    "        target_test = K.constant(target_test)\n",
    "        \n",
    "        # Evaluation test graph\n",
    "        loss_test = test([sample_test, target_test])\n",
    "        \n",
    "        # Compute test loss mean\n",
    "        losses_test.append(loss_test[0])\n",
    "    \n",
    "    loss_test_mean = np.mean(losses_test)\n",
    "    print('Test Loss: %.3f' % loss_test_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
