{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from tqdm import tqdm\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Input, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import os.path\n",
    "import pickle\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility \n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "train_model = False           # if False, evaluate the model instead of training it\n",
    "\n",
    "# client params\n",
    "clients_per_class = 10        # number of clients per label. Each client only has access to one label\n",
    "                              # - each unique class is divided into X number of subsets\n",
    "    \n",
    "minibatch_size = None         # number of samples to operate on at one time\n",
    "                              # - can vary to optimize computing requirements\n",
    "                              # - if None, will evaluate the whole batch regardless of its size\n",
    "    \n",
    "batches_per_train_step = 20   # after averaging the gradients from X clients, we will apply them to the model\n",
    "\n",
    "shuffle_clients = True\n",
    "\n",
    "# checkpoint params\n",
    "checkpoint_folder = \"./checkpoints/blackbox\"\n",
    "os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "blackbox_weights_path = os.path.join(checkpoint_folder, 'blackbox_checkpoint.ckpt')\n",
    "blackbox_weights_check = os.path.join(checkpoint_folder, 'checkpoint')\n",
    "\n",
    "# dataset params\n",
    "separated_folder = \"./separated_dataset\"\n",
    "os.makedirs(separated_folder, exist_ok=True)\n",
    "separated_train_path = os.path.join(separated_folder, \"train_separated.pkl\")\n",
    "separated_test_path = os.path.join(separated_folder, \"test_separated.pkl\")\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "target_rows, target_cols = 28, 28    # governed by the chosen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if target_rows != img_rows or target_cols != img_cols:\n",
    "    # resize x_train\n",
    "    x_train_resized = []\n",
    "    for x_ in x_train:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_train_resized.append(x_)\n",
    "    x_train = np.asarray(x_train_resized)\n",
    "\n",
    "    # resize x_test\n",
    "    x_test_resized = []\n",
    "    for x_ in x_test:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_test_resized.append(x_)\n",
    "    x_test = np.asarray(x_test_resized)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "y: (60000, 10) (10000, 10)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "print('X:', x_train.shape, x_test.shape)\n",
    "print('y:', y_train.shape, y_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training seperation\n",
      "loaded testing seperation\n"
     ]
    }
   ],
   "source": [
    "# Separating the data by class\n",
    "if os.path.isfile(separated_train_path):\n",
    "    with open(separated_train_path, 'rb') as f:\n",
    "        x_train_dict, y_train_dict = pickle.load(f)\n",
    "        print('loaded training seperation')\n",
    "else:\n",
    "    x_train_dict = {}\n",
    "    y_train_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_train_dict[target_label] = []\n",
    "        y_train_dict[target_label] = []\n",
    "        for i, label in enumerate(y_train):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_train_dict[target_label].append(x_train[i])\n",
    "                y_train_dict[target_label].append(y_train[i])\n",
    "    \n",
    "    with open(separated_train_path, 'wb') as f:\n",
    "        pickle.dump([x_train_dict, y_train_dict], f)\n",
    "        print('saved training seperation')\n",
    "\n",
    "if os.path.isfile(separated_test_path):\n",
    "    with open(separated_test_path, 'rb') as f:\n",
    "        x_test_dict, y_test_dict = pickle.load(f)\n",
    "        print('loaded testing seperation')\n",
    "else:\n",
    "    x_test_dict = {}\n",
    "    y_test_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_test_dict[target_label] = []\n",
    "        y_test_dict[target_label] = []\n",
    "        for i, label in enumerate(y_test):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_test_dict[target_label].append(x_test[i])\n",
    "                y_test_dict[target_label].append(y_test[i])\n",
    "\n",
    "    with open(separated_test_path, 'wb') as f:\n",
    "        pickle.dump([x_test_dict, y_test_dict], f)\n",
    "        print('saved testing seperation')\n",
    "    \n",
    "# convert dicts to lists\n",
    "x_train_seperated = [np.array(x_train_dict[i]) for i in range(10)]\n",
    "y_train_seperated = [np.array(y_train_dict[i]) for i in range(10)]\n",
    "\n",
    "x_test_seperated = [np.array(x_test_dict[i]) for i in range(10)]\n",
    "y_test_seperated = [np.array(y_test_dict[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "plt.figure()\n",
    "plt.title('Data separation per class')\n",
    "plt.bar(x_train_dict.keys(), [len(v) for v in x_train_dict.values()], color='tab:blue')\n",
    "plt.bar(x_test_dict.keys(), [len(v) for v in x_test_dict.values()], color='orange', width=0.6)\n",
    "plt.legend(['x_train', 'x_test'], loc='center right', framealpha=1.0)\n",
    "plt.xlabel('class label')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data into batches for clients to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients per class:  10.0 ~= 10\n",
      "Average batch size: 6000.0\n"
     ]
    }
   ],
   "source": [
    "# Separate the data into a long list of batches, each batch representing a client training with that batch of images.\n",
    "# After each batch, a new client will have the opportunity to train their batch of images.\n",
    "# Batches are shuffled to simulate many clients training the model at once.\n",
    "\n",
    "client_counts = {}\n",
    "batch_sizes = {}\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "def ceil(a,b):\n",
    "    return -(-a//b)\n",
    "\n",
    "for class_idx in range(len(x_train_seperated)):\n",
    "    # Get batches from class data:\n",
    "    n_samples_per_class = len(x_train_seperated[class_idx])\n",
    "    samples_per_client = n_samples_per_class / clients_per_class\n",
    "    better_batch_size = int(math.ceil(samples_per_client))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(ceil(n_samples_per_class, better_batch_size)):\n",
    "        x_batches.append((class_idx, x_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        y_batches.append((class_idx, y_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        count += 1\n",
    "    client_counts[class_idx] = count\n",
    "    batch_sizes[class_idx] = n_samples_per_class\n",
    "        \n",
    "# double check that the clients_per_class is upheld per class\n",
    "# (blue bars should be uniform, red should change according to class):\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('class label')\n",
    "ax1.set_ylabel('client count', color=color)\n",
    "plt.bar(client_counts.keys(), [v for v in client_counts.values()], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'orange'\n",
    "ax2.set_ylabel('batch size', color=color)  # we already handled the x-label with ax1\n",
    "plt.bar(batch_sizes.keys(), [v for v in batch_sizes.values()], color=color, width=0.6)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylim(0, np.mean([v for v in batch_sizes.values()])*2)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()\n",
    "\n",
    "print('Clients per class:  {} ~= {}'.format(np.mean([v for v in client_counts.values()]), clients_per_class))\n",
    "print('Average batch size: {}'.format(np.mean([v for v in batch_sizes.values()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zharr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\zharr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (target_rows, target_cols, 1)\n",
    "\n",
    "model = create_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add place for input and pred label\n",
    "x = Input(shape=input_shape)\n",
    "y_pred = model(x)\n",
    "\n",
    "# add place for truth label\n",
    "y_true = Input(shape=(num_classes, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function in terms of y_pred and y_true\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "# Setup metrics to look at during training:\n",
    "_, acc_op = tf.metrics.accuracy(labels=tf.argmax(y_true, 1),\n",
    "                                predictions=tf.argmax(y_pred,1))\n",
    "\n",
    "## Optimizer definition - nothing different from any classical example\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-3bc30d66b1bb>:11: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    }
   ],
   "source": [
    "# INSPIRED by https://stackoverflow.com/questions/42156957/how-to-update-model-parameters-with-accumulated-gradients\n",
    "\n",
    "# Fetch a list of our network's trainable parameters.\n",
    "trainable_vars = tf.trainable_variables()\n",
    "\n",
    "# Create variables to store accumulated gradients\n",
    "accumulators = [\n",
    "    tf.Variable(\n",
    "        tf.zeros_like(tv.initialized_value()),\n",
    "        trainable=False\n",
    "    ) for tv in trainable_vars\n",
    "]\n",
    "\n",
    "# Create a variable for counting the number of accumulations\n",
    "accumulation_counter = tf.Variable(0.0, trainable=False)\n",
    "\n",
    "# Compute gradients; grad_pairs contains (gradient, variable) pairs\n",
    "grad_pairs = optimizer.compute_gradients(loss, trainable_vars)\n",
    "\n",
    "# Create operations which add a variable's gradient to its accumulator.\n",
    "accumulate_ops = [\n",
    "    accumulator.assign_add(\n",
    "        grad\n",
    "    ) for (accumulator, (grad, var)) in zip(accumulators, grad_pairs)\n",
    "]\n",
    "\n",
    "# The final accumulation operation is to increment the counter\n",
    "accumulate_ops.append(accumulation_counter.assign_add(1.0))\n",
    "\n",
    "# Update trainable variables by applying the accumulated gradients\n",
    "# divided by the counter. Note: apply_gradients takes in a list of \n",
    "# (grad, var) pairs\n",
    "train_step = optimizer.apply_gradients(\n",
    "    [(accumulator / accumulation_counter, var) \\\n",
    "        for (accumulator, (grad, var)) in zip(accumulators, grad_pairs)]\n",
    ")\n",
    "\n",
    "# Accumulators must be zeroed once the accumulated gradient is applied.\n",
    "zero_ops = [\n",
    "    accumulator.assign(\n",
    "        tf.zeros_like(tv)\n",
    "    ) for (accumulator, tv) in zip(accumulators, trainable_vars)\n",
    "]\n",
    "\n",
    "# Add one last op for zeroing the counter\n",
    "zero_ops.append(accumulation_counter.assign(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the session\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.local_variables_initializer())\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/blackbox\\blackbox_checkpoint.ckpt\n",
      "Weights found! Loaded previous weights\n"
     ]
    }
   ],
   "source": [
    "# Load weights if they are found\n",
    "\n",
    "if os.path.isfile(blackbox_weights_check):\n",
    "    saver.restore(sess, blackbox_weights_path)\n",
    "    #model.load_weights(blackbox_weights_path)\n",
    "    print('Weights found! Loaded previous weights')\n",
    "else:\n",
    "    print('NO weights found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "\n",
      "Test Accuracy: 0.989 | Loss: 0.035\n"
     ]
    }
   ],
   "source": [
    "# Train or Evaluate\n",
    "\n",
    "if train_model:\n",
    "    print('Training the model...\\n')\n",
    "    \n",
    "    # Loop through every class, and apply gradients after that:\n",
    "    for epoch in range(epochs):\n",
    "        print('.'*10)\n",
    "        print('Epoch %s:' % str(epoch+1))\n",
    "\n",
    "        batch_idxs = list(range(len(x_batches)))\n",
    "        if shuffle_clients:\n",
    "            # shuffle the batches each time\n",
    "            random.shuffle(batch_idxs)\n",
    "\n",
    "        # Run the zero_ops to initialize the accumulators\n",
    "        sess.run(zero_ops)\n",
    "\n",
    "        # Fancy progress bar\n",
    "        samples = x_train.shape[0]\n",
    "        pbar = tqdm_notebook(total=samples)\n",
    "\n",
    "        # Keep track of average loss/acc per class:\n",
    "        accs_train = []\n",
    "        losses_train = []\n",
    "\n",
    "        # Iterate over clients:\n",
    "        grad_feed_dict = dict()\n",
    "        for i, batch_idx in enumerate(batch_idxs):\n",
    "            class_idx, x_batch = x_batches[batch_idx]\n",
    "            _, y_batch = y_batches[batch_idx]\n",
    "            \n",
    "            # Iterate over the client's batch in minibatches:\n",
    "            j = 0\n",
    "            while(j < len(x_batch)):\n",
    "                if minibatch_size is None:\n",
    "                    # use whole batch (no minibatch)\n",
    "                    x_minibatch = x_batch\n",
    "                    y_minibatch = y_batch\n",
    "                else:\n",
    "                    x_minibatch = x_batch[j:(j+minibatch_size)]\n",
    "                    y_minibatch = y_batch[j:(j+minibatch_size)]\n",
    "                \n",
    "                # get the gradients and determine accuracy/loss of model on training dataset\n",
    "                _, acc_train, loss_train = sess.run([accumulate_ops, acc_op, loss], feed_dict={x: x_minibatch, \n",
    "                                                                                               y_true: y_minibatch})\n",
    "\n",
    "                # add acc and loss metrics for batch:\n",
    "                accs_train.append(acc_train)\n",
    "                losses_train.append(np.mean(loss_train))\n",
    "                \n",
    "                if minibatch_size is None:\n",
    "                    break\n",
    "                else:\n",
    "                    j += minibatch_size\n",
    "\n",
    "            # increment pbar\n",
    "            pbar.update(len(x_batch))\n",
    "            pbar.set_description('train_acc={:.3f} | train_loss={:.3f}'.format(np.mean(accs_train), np.mean(losses_train)))\n",
    "\n",
    "            # perform a train step every batches_per_train_step number of batches:\n",
    "            if (i > 0 and i % batches_per_train_step == 0) or i == len(batch_idxs) - 1:\n",
    "                # Run the train_step ops to update the weights based on our accumulated gradients\n",
    "                sess.run(train_step)\n",
    "\n",
    "                # zero out the accumulators\n",
    "                sess.run(zero_ops)\n",
    "\n",
    "        pbar.update(x_train.shape[0] - pbar.n)\n",
    "        pbar.close()\n",
    "\n",
    "        # Calculate test acc and loss\n",
    "        acc_test, loss_test = sess.run([acc_op, loss], feed_dict={x: x_test, y_true: y_test})\n",
    "\n",
    "        # Update progress bar\n",
    "        print('Train Accuracy: {:.3f} | Loss: {:.3f}'.format(np.mean(accs_train), np.mean(losses_train)))\n",
    "        print('Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test, np.mean(loss_test)))\n",
    "        print()\n",
    "        \n",
    "    # Save the weights\n",
    "    saver.save(sess, blackbox_weights_path)\n",
    "    #model.save_weights(blackbox_weights_path)\n",
    "    print('Saved the updated weights')\n",
    "    \n",
    "else:\n",
    "    print('Evaluating model...\\n')\n",
    "    # Calculate test acc and loss\n",
    "    acc_test, loss_test = sess.run([acc_op, loss], feed_dict={x: x_test, y_true: y_test})\n",
    "\n",
    "    # Update progress bar\n",
    "    print('Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test, np.mean(loss_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
