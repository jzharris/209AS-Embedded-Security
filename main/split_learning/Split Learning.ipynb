{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from tqdm import tqdm\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Input, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import os.path\n",
    "import pickle\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility \n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "batch_size = 64               # the number of samples each client trains with per timestep\n",
    "                              # smaller --> more variety between classes --> better training\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "train_from_scratch = False    # if True, will train a model from scratch if no weights are found\n",
    "\n",
    "# client params\n",
    "clients_per_class = 10        # number of clients per label. Each client only has access to one label\n",
    "batches_per_train_step = 20   # after averaging the gradients from X clients, we will apply them to the model\n",
    "shuffle_clients = True\n",
    "\n",
    "# checkpoint params\n",
    "checkpoint_folder = \"./checkpoints/blackbox\"\n",
    "os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "blackbox_weights_path = os.path.join(checkpoint_folder, 'blackbox_checkpoint.ckpt')\n",
    "\n",
    "# dataset params\n",
    "separated_train_path = \"./train_separated.pkl\"\n",
    "separated_test_path = \"./test_separated.pkl\"\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "target_rows, target_cols = 28, 28    # governed by the chosen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if target_rows != img_rows or target_cols != img_cols:\n",
    "    # resize x_train\n",
    "    x_train_resized = []\n",
    "    for x_ in x_train:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_train_resized.append(x_)\n",
    "    x_train = np.asarray(x_train_resized)\n",
    "\n",
    "    # resize x_test\n",
    "    x_test_resized = []\n",
    "    for x_ in x_test:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_test_resized.append(x_)\n",
    "    x_test = np.asarray(x_test_resized)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "y: (60000, 10) (10000, 10)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "print('X:', x_train.shape, x_test.shape)\n",
    "print('y:', y_train.shape, y_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training seperation\n",
      "loaded testing seperation\n"
     ]
    }
   ],
   "source": [
    "# Separating the data by class\n",
    "if os.path.isfile(separated_train_path):\n",
    "    with open(separated_train_path, 'rb') as f:\n",
    "        x_train_dict, y_train_dict = pickle.load(f)\n",
    "        print('loaded training seperation')\n",
    "else:\n",
    "    x_train_dict = {}\n",
    "    y_train_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_train_dict[target_label] = []\n",
    "        y_train_dict[target_label] = []\n",
    "        for i, label in enumerate(y_train):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_train_dict[target_label].append(x_train[i])\n",
    "                y_train_dict[target_label].append(y_train[i])\n",
    "    \n",
    "    with open(separated_train_path, 'wb') as f:\n",
    "        pickle.dump([x_train_dict, y_train_dict], f)\n",
    "        print('saved training seperation')\n",
    "\n",
    "if os.path.isfile(separated_test_path):\n",
    "    with open(separated_test_path, 'rb') as f:\n",
    "        x_test_dict, y_test_dict = pickle.load(f)\n",
    "        print('loaded testing seperation')\n",
    "else:\n",
    "    x_test_dict = {}\n",
    "    y_test_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_test_dict[target_label] = []\n",
    "        y_test_dict[target_label] = []\n",
    "        for i, label in enumerate(y_test):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_test_dict[target_label].append(x_test[i])\n",
    "                y_test_dict[target_label].append(y_test[i])\n",
    "\n",
    "    with open(separated_test_path, 'wb') as f:\n",
    "        pickle.dump([x_test_dict, y_test_dict], f)\n",
    "        print('saved testing seperation')\n",
    "    \n",
    "# convert dicts to lists\n",
    "x_train_seperated = [np.array(x_train_dict[i]) for i in range(10)]\n",
    "y_train_seperated = [np.array(y_train_dict[i]) for i in range(10)]\n",
    "\n",
    "x_test_seperated = [np.array(x_test_dict[i]) for i in range(10)]\n",
    "y_test_seperated = [np.array(y_test_dict[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "plt.figure()\n",
    "plt.title('Data separation per class')\n",
    "plt.bar(x_train_dict.keys(), [len(v) for v in x_train_dict.values()], color='b')\n",
    "plt.bar(x_test_dict.keys(), [len(v) for v in x_test_dict.values()], color='gold', width=0.6)\n",
    "plt.legend(['x_train', 'x_test'], loc='center right', framealpha=1.0)\n",
    "plt.xlabel('class label')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data into batches for clients to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60288 ~= 60000\n",
      "batch shape: (64, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Separate the data into a long list of batches, each batch representing a client training with that batch of images.\n",
    "# After each batch, a new client will have the opportunity to train their batch of images.\n",
    "# Batches are shuffled to simulate many clients training the model at once.\n",
    "\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "def ceil(a,b):\n",
    "    return -(-a//b)\n",
    "\n",
    "for class_idx in range(len(x_train_seperated)):\n",
    "    # Get batches from class data:\n",
    "    n_samples = len(x_train_seperated[class_idx])\n",
    "    better_batch_size = ceil(n_samples, ceil(n_samples, batch_size))\n",
    "\n",
    "    for i in range(ceil(n_samples, better_batch_size)):\n",
    "        x_batches.append((class_idx, x_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        y_batches.append((class_idx, y_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        \n",
    "# checks\n",
    "assert len(x_batches) == len(y_batches)\n",
    "print(len(x_batches) * batch_size, '~=', x_train.shape[0])\n",
    "print('batch shape:', x_batches[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zharr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\zharr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (target_rows, target_cols, 1)\n",
    "\n",
    "model = create_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add place for input and pred label\n",
    "x = Input(shape=input_shape)\n",
    "y_pred = model(x)\n",
    "\n",
    "# add place for truth label\n",
    "y_true = Input(shape=(num_classes, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function in terms of y_pred and y_true\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "# Setup metrics to look at during training:\n",
    "_, acc_op = tf.metrics.accuracy(labels=tf.argmax(y_true, 1),\n",
    "                                predictions=tf.argmax(y_pred,1))\n",
    "\n",
    "## Optimizer definition - nothing different from any classical example\n",
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-3bc30d66b1bb>:11: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    }
   ],
   "source": [
    "# INSPIRED by https://stackoverflow.com/questions/42156957/how-to-update-model-parameters-with-accumulated-gradients\n",
    "\n",
    "# Fetch a list of our network's trainable parameters.\n",
    "trainable_vars = tf.trainable_variables()\n",
    "\n",
    "# Create variables to store accumulated gradients\n",
    "accumulators = [\n",
    "    tf.Variable(\n",
    "        tf.zeros_like(tv.initialized_value()),\n",
    "        trainable=False\n",
    "    ) for tv in trainable_vars\n",
    "]\n",
    "\n",
    "# Create a variable for counting the number of accumulations\n",
    "accumulation_counter = tf.Variable(0.0, trainable=False)\n",
    "\n",
    "# Compute gradients; grad_pairs contains (gradient, variable) pairs\n",
    "grad_pairs = optimizer.compute_gradients(loss, trainable_vars)\n",
    "\n",
    "# Create operations which add a variable's gradient to its accumulator.\n",
    "accumulate_ops = [\n",
    "    accumulator.assign_add(\n",
    "        grad\n",
    "    ) for (accumulator, (grad, var)) in zip(accumulators, grad_pairs)\n",
    "]\n",
    "\n",
    "# The final accumulation operation is to increment the counter\n",
    "accumulate_ops.append(accumulation_counter.assign_add(1.0))\n",
    "\n",
    "# Update trainable variables by applying the accumulated gradients\n",
    "# divided by the counter. Note: apply_gradients takes in a list of \n",
    "# (grad, var) pairs\n",
    "train_step = optimizer.apply_gradients(\n",
    "    [(accumulator / accumulation_counter, var) \\\n",
    "        for (accumulator, (grad, var)) in zip(accumulators, grad_pairs)]\n",
    ")\n",
    "\n",
    "# Accumulators must be zeroed once the accumulated gradient is applied.\n",
    "zero_ops = [\n",
    "    accumulator.assign(\n",
    "        tf.zeros_like(tv)\n",
    "    ) for (accumulator, tv) in zip(accumulators, trainable_vars)\n",
    "]\n",
    "\n",
    "# Add one last op for zeroing the counter\n",
    "zero_ops.append(accumulation_counter.assign(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the session\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.local_variables_initializer())\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights found! Loaded previous weights\n",
      "\n",
      "Test Accuracy: 0.103 | Loss: 2.304\n"
     ]
    }
   ],
   "source": [
    "# Train the model IF we want to, otherwise just use previous\n",
    "if train_from_scratch and not os.path.isfile(blackbox_weights_path):\n",
    "    print('Training from scratch...')\n",
    "    \n",
    "    # Loop through every class, and apply gradients after that:\n",
    "    for epoch in range(epochs):\n",
    "        print('.'*10)\n",
    "        print('Epoch %s:' % epoch+1)\n",
    "\n",
    "        batch_idxs = list(range(len(x_batches)))\n",
    "        if shuffle_clients:\n",
    "            # shuffle the batches each time\n",
    "            random.shuffle(batch_idxs)\n",
    "\n",
    "        # Run the zero_ops to initialize the accumulators\n",
    "        sess.run(zero_ops)\n",
    "\n",
    "        # Fancy progress bar\n",
    "        samples = x_train.shape[0]\n",
    "        pbar = tqdm_notebook(total=samples)\n",
    "\n",
    "        # Keep track of average loss/acc per class:\n",
    "        accs_train = []\n",
    "        losses_train = []\n",
    "\n",
    "        # Iterate over every minibatch (client batch):\n",
    "        grad_feed_dict = dict()\n",
    "        for i, batch_idx in enumerate(batch_idxs):\n",
    "            class_idx, x_batch = x_batches[batch_idx]\n",
    "            _, y_batch = y_batches[batch_idx]\n",
    "\n",
    "            # get the gradients and determine accuracy/loss of model on training dataset\n",
    "            _, acc_train, loss_train = sess.run([accumulate_ops, acc_op, loss], feed_dict={x: x_batch, y_true: y_batch})\n",
    "\n",
    "            # increment pbar\n",
    "            pbar.update(len(x_batch))\n",
    "\n",
    "            # add acc and loss metrics for batch:\n",
    "            accs_train.append(acc_train)\n",
    "            losses_train.append(np.mean(loss_train))\n",
    "            pbar.set_description('train_acc={:.3f} | train_loss={:.3f}'.format(np.mean(accs_train), np.mean(losses_train)))\n",
    "\n",
    "            # perform a train step every batches_per_train_step number of batches:\n",
    "            if (i > 0 and i % batches_per_train_step == 0) or i == len(batch_idxs) - 1:\n",
    "                # Run the train_step ops to update the weights based on our accumulated gradients\n",
    "                sess.run(train_step)\n",
    "\n",
    "                # zero out the accumulators\n",
    "                sess.run(zero_ops)\n",
    "\n",
    "        pbar.update(x_train.shape[0] - pbar.n)\n",
    "        pbar.close()\n",
    "\n",
    "        # Calculate test acc and loss\n",
    "        acc_test, loss_test = sess.run([acc_op, loss], feed_dict={x: x_test, y_true: y_test})\n",
    "\n",
    "        # Update progress bar\n",
    "        print('Train Accuracy: {:.3f} | Loss: {:.3f}'.format(np.mean(accs_train), np.mean(losses_train)))\n",
    "        print('Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test, np.mean(loss_test)))\n",
    "        print()\n",
    "        \n",
    "    # Save the weights\n",
    "    model.save_weights(blackbox_weights_path)\n",
    "    print('Saved the updated weights')\n",
    "        \n",
    "elif os.path.isfile(blackbox_weights_path):\n",
    "    model.load_weights(blackbox_weights_path)\n",
    "    print('Weights found! Loaded previous weights')\n",
    "    print()\n",
    "    \n",
    "    # Calculate test acc and loss\n",
    "    acc_test, loss_test = sess.run([acc_op, loss], feed_dict={x: x_test, y_true: y_test})\n",
    "\n",
    "    # Update progress bar\n",
    "    print('Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test, np.mean(loss_test)))\n",
    "    \n",
    "else:\n",
    "    print('ERROR: either train from scratch, or give a valid weights ckpt file to load from.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
