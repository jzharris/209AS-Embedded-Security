{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack attempt, using a cGAN to train D and FGSM to refine D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF 2.2.0\n",
      "Keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution() # default for TF 2.0\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "from tensorflow import keras  # Import the tf version of keras.\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, \\\n",
    "                                    LeakyReLU, Conv2DTranspose, Reshape\n",
    "# import keras.backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "print('TF', tf.__version__)\n",
    "print('Keras', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import notebook, tqdm\n",
    "import pickle\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "\n",
    "import os.path\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility \n",
    "# np.random.seed(0)\n",
    "# tf.random.set_seed(0)\n",
    "\n",
    "# Enlargen plots\n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EASY_MODE: if True, Split Learning NN is used as the Discriminator in the GAN. This is good for testing, but\n",
    "# bypasses the black-box paradigm! Use with caution\n",
    "EASY_MODE = True\n",
    "\n",
    "# Black-box params (optimized for MNIST)\n",
    "depth = 9\n",
    "filters = 33\n",
    "dense = 110\n",
    "num_classes = 10\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "target_rows, target_cols = 28, 28    # governed by the chosen model\n",
    "input_shape = (target_rows, target_cols, 1)\n",
    "\n",
    "# Attack params:\n",
    "attack_params = {\n",
    "    'our_class': 0,                             # the label indices that we want to preserve (and the data we own)\n",
    "    'attacker_clients': 5,                      # attacker controls X number of clients and their data\n",
    "    'attack_classes': [1],                      # the label(s) we want to poison\n",
    "    'flip_to': [7],                             # must be len(attack_classes) - flips the target label ('1') to new class ('7')\n",
    "    'prime_trigger': 0.00, #0.11                # the D test accuracy that, after which, we will move on from priming\n",
    "    'prime_first_iteration': True,              # whether to always prime on the first iteration\n",
    "    'prime_by_ckpt': True,                      # whether to prime manually (False) or by loading a checkpoint file (True)\n",
    "    'prime_cgan_by_ckpt': False,                # whether to load a pretrained cGAN from default/ or start from scratch (False)\n",
    "    'attack_trigger': 0.8,                      # the D accuracy (wrt Black-box) that, after which, we will commence an attack\n",
    "    'd_refinement_batch_num': 3,                # number of batches to refine D with: G -> BB <-> D\n",
    "    'd_refinement_batch_size': 100,             # number of attack images in each refinement batch: G -> BB <-> D\n",
    "    'train_dataset': None,                      # attack dataset - fixed in the beginning by choosing the attacking clients\n",
    "                                                # - this is the only data we have access to throughout the training process\n",
    "    'attacks_per_epoch': 10,                    # how many times to attack per epoch\n",
    "    'prime_exit_trigger': 1.0,                  # how good D has to be on the current blackbox model to exit priming\n",
    "    'refine_exit_trigger': 1.0,                 # how good D has to be after refinement*\n",
    "    'train_bb_every_n_its': 2,                  # only train the BB model while querying if (it % train_bb_every_n_its == 0)\n",
    "    'cgan_query_every_n_its': 1,                # only query BB with cGAN every N iterations\n",
    "    'refine_using_fgsm': True,                 # use FGSM to generate images to refine D with via uG -> BB -> D\n",
    "    'refine_using_ugan': False,                  # use the uGAN to generate images to refine D with via uG -> BB -> D\n",
    "    'accumulate_g_queries': True,               # whether to keep uGAN imgs every iteration, or to just use most recent (False)\n",
    "    'flush_g_queries_every_bb_train': False,    # whether to keep uGAN imgs after new BB is trained, or preserved them (False)\n",
    "    'reset_g_every_bb_train': False,            # whether to reset G back to init every time we train the BB model\n",
    "}\n",
    "\n",
    "# Split Learning training params:\n",
    "split_training_params = {\n",
    "    'minibatch_size': None,                     # number of samples to operate on at one time\n",
    "                                                #  - can vary to optimize computing requirements\n",
    "                                                #  - if None, will evaluate the client's whole batch regardless of its size\n",
    "    'apply_gradients_after': 20,                # after averaging the gradients from X clients, we will apply them to the model\n",
    "    'epochs': 1, #8                               # number of epochs to train for\n",
    "    'shuffle_clients': True,                    # whether to shuffle the clients during training\n",
    "    'eval_batch_size': 5, #256                    # batch size when evaluating test set (not split by clients),\n",
    "    'train_dataset': None,                      # training set - indexed by client\n",
    "    'test_dataset': None,                       # testing set - not batched\n",
    "    'batch_limit': None,                        # how many batches to train on, maximum, per epoch\n",
    "    'ckpt_folder': \"blackbox_checkpoint\",       # folder where to store the checkpoints\n",
    "    'start_id': 'split_start_model',            # start piece\n",
    "    'middle_id': 'split_middle_model',          # middle piece\n",
    "    'end_id': 'split_end_model',                # end piece\n",
    "    'full_id': 'split_model',                   # full model name\n",
    "}\n",
    "\n",
    "# cGAN training params:\n",
    "cgan_training_params = {\n",
    "    'minibatch_size': split_training_params['minibatch_size'],\n",
    "    'extra_depth': 3,                           # number of extra middle layers to put in the D of cGAN\n",
    "    'start_id': 'd_start_model',                # start piece\n",
    "    'middle_id': 'd_middle_model',              # middle piece\n",
    "    'end_id': 'd_end_model',                    # end piece\n",
    "    'full_id': 'd_model',                       # full model name\n",
    "    'use_bb_ends': True,                        # whether to share the weights of the start and end piece from the BB model\n",
    "    'batch_size': 256,                          # number of images to generate from cG at once\n",
    "    'noise_dim': 100,                           # noise vector for cG\n",
    "    'epochs': 1,                                # number of epochs to train cGAN\n",
    "    'use_blackbox': False,                      # if True, copies the Blackbox model into D (easy check)\n",
    "    'd_ckpt_folder': \"discriminator_checkpoint\",# folder where to store the d checkpoints\n",
    "    'bb_ckpt_folder': \"blackbox_checkpoint\",    # folder where the blackbox default ckpt is kept\n",
    "    'g_ckpt_folder': \"generator_checkpoint\",    # folder where to store the g checkpoints\n",
    "    'batches_per_epoch': 100,                   # number of batches to train on per epoch\n",
    "    'd_trigger': 0.98,                          # train D if g_accuracy is >= X\n",
    "    'g_trigger': 1.01,                          # train G if g_accuracy is < X\n",
    "    'loop_times': 0,                            # number of times to apply softmax -> onehot encoding\n",
    "    'uncertain_loop_times': 1,                  # number to use in the uncertain_loss used by D\n",
    "    'softmax_power': 2,                         # number used in softmax -> onehot encoding operation\n",
    "    'd_reset_percentage': 1.0,                  # reset D if the test d_accuracy dips below X% of the original accuracy\n",
    "    'early_stop_trigger': 5,                    # stop training early, if g_accuracy has not improved for X epochs\n",
    "    'stop_sensitivity': 0.02,                   # \"no improvement\" is when the g_accuracy has not moved more than X% from prev\n",
    "    'g_nudge_trigger': 3,                       # if \"no improvement\" for X epochs, turn on D for one turn\n",
    "    'g_nudge_probability': 0.20,                # probability of nudging this sample, if enabled\n",
    "    'counter_nudge': True,                      # whether to train an extra epoch when coming out of training right after nudge\n",
    "    'd_priming_epoch_limit': 1000,              # number of epochs to stop at for priming\n",
    "    'd_refine_epoch_limit': 200,                # number of epochs to stop at for refining D\n",
    "    'save_best_g': False,                       # whether to save the best G during training, or to just use the last one\n",
    "    'd_restore_after_nudge': True,              # whether to restore D back to normal at the end of the epoch if it was nudged\n",
    "    'reset_g_every_it': False,                  # whether to restore cG back to init at the end of Step 5 if not -> Step 6\n",
    "}\n",
    "\n",
    "# uGAN training params:\n",
    "ugan_training_params = {\n",
    "    'minibatch_size': split_training_params['minibatch_size'],\n",
    "    'extra_depth': 3,                           # number of extra middle layers to put in the D of cGAN\n",
    "    'start_id': 'x_start_model',                # start piece\n",
    "    'middle_id': 'x_middle_model',              # middle piece\n",
    "    'end_id': 'x_end_model',                    # end piece\n",
    "    'full_id': 'x_model',                       # full model name\n",
    "    'use_bb_ends': True,                        # whether to share the weights of the start and end piece from the BB model\n",
    "    'is_conditional': True,                     # whether to use the cGAN or uGAN architecture\n",
    "    'batch_size': 256,                          # number of images to generate from uG at once\n",
    "    'noise_dim': 100,                           # noise vector for uG\n",
    "    'epochs': 15,                               # number of epochs to train uGAN\n",
    "    'd_ckpt_folder': \"discriminator_checkpoint\",# folder where to store the d checkpoints\n",
    "    'bb_ckpt_folder': \"blackbox_checkpoint\",    # folder where the blackbox default ckpt is kept\n",
    "    'g_ckpt_folder': \"generator_checkpoint\",    # folder where to store the g checkpoints\n",
    "    'batches_per_epoch': 100,                   # number of batches to train on per epoch\n",
    "    'loop_times': 0,                            # number of times to apply softmax -> onehot encoding\n",
    "    'uncertain_loop_times': 1,                  # number to use in the uncertain_loss used by D\n",
    "    'softmax_power': 2,                         # number used in softmax -> onehot encoding operation\n",
    "    'early_stop_trigger': 5,                    # stop training early, if g_accuracy has not improved for X epochs\n",
    "    'stop_sensitivity': 0.02,                   # \"no improvement\" is when the g_accuracy has not moved more than X% from prev\n",
    "    'save_best_g': False,                       # whether to save the best G during training, or to just use the last one\n",
    "    'reset_g_every_it': True,                   # whether to restore uG back to init at the end of Step 5 if not -> Step 6\n",
    "}\n",
    "\n",
    "# FGSM training params:\n",
    "fgsm_training_params = {\n",
    "    'epsilon': 0.9,\n",
    "    'norm': 'Inf',                                 # can be L1, Inf\n",
    "}\n",
    "\n",
    "# Mitigation params:\n",
    "mitigation_params = {\n",
    "    'percent_to_drop': 0.1                      # what percentage of images in the batch should be replaced with noise\n",
    "}\n",
    "\n",
    "# Data parsing params\n",
    "clients_per_class = 100                         # number of clients per label. Each client only has access to one label\n",
    "                                                # - each unique class is divided into X number of subsets\n",
    "\n",
    "# Dataset params\n",
    "separated_folder = \"./separated_dataset\"\n",
    "os.makedirs(separated_folder, exist_ok=True)\n",
    "separated_train_path = os.path.join(separated_folder, \"train_separated.pkl\")\n",
    "separated_test_path = os.path.join(separated_folder, \"test_separated.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255    # range is [0, 1]\n",
    "x_test /= 255     # range is [0, 1]\n",
    "\n",
    "if target_rows != img_rows or target_cols != img_cols:\n",
    "    # resize x_train\n",
    "    x_train_resized = []\n",
    "    for x_ in x_train:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_train_resized.append(x_)\n",
    "    x_train = np.asarray(x_train_resized)\n",
    "\n",
    "    # resize x_test\n",
    "    x_test_resized = []\n",
    "    for x_ in x_test:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_test_resized.append(x_)\n",
    "    x_test = np.asarray(x_test_resized)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "y: (60000, 10) (10000, 10)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "print('X:', x_train.shape, x_test.shape)\n",
    "print('y:', y_train.shape, y_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "BUFFER_SIZE = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training seperation\n",
      "loaded testing seperation\n"
     ]
    }
   ],
   "source": [
    "# Separating the data by class\n",
    "if os.path.isfile(separated_train_path):\n",
    "    with open(separated_train_path, 'rb') as f:\n",
    "        x_train_dict, y_train_dict = pickle.load(f)\n",
    "        print('loaded training seperation')\n",
    "else:\n",
    "    x_train_dict = {}\n",
    "    y_train_dict = {}\n",
    "    for target_label in notebook.tqdm(range(10)):\n",
    "        x_train_dict[target_label] = []\n",
    "        y_train_dict[target_label] = []\n",
    "        for i, label in enumerate(y_train):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_train_dict[target_label].append(x_train[i])\n",
    "                y_train_dict[target_label].append(y_train[i])\n",
    "    \n",
    "    with open(separated_train_path, 'wb') as f:\n",
    "        pickle.dump([x_train_dict, y_train_dict], f)\n",
    "        print('saved training seperation')\n",
    "\n",
    "if os.path.isfile(separated_test_path):\n",
    "    with open(separated_test_path, 'rb') as f:\n",
    "        x_test_dict, y_test_dict = pickle.load(f)\n",
    "        print('loaded testing seperation')\n",
    "else:\n",
    "    x_test_dict = {}\n",
    "    y_test_dict = {}\n",
    "    for target_label in notebook.tqdm(range(10)):\n",
    "        x_test_dict[target_label] = []\n",
    "        y_test_dict[target_label] = []\n",
    "        for i, label in enumerate(y_test):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_test_dict[target_label].append(x_test[i])\n",
    "                y_test_dict[target_label].append(y_test[i])\n",
    "\n",
    "    with open(separated_test_path, 'wb') as f:\n",
    "        pickle.dump([x_test_dict, y_test_dict], f)\n",
    "        print('saved testing seperation')\n",
    "    \n",
    "# convert dicts to lists\n",
    "x_train_seperated = [np.array(x_train_dict[i]) for i in range(10)]\n",
    "y_train_seperated = [np.array(y_train_dict[i]) for i in range(10)]\n",
    "\n",
    "x_test_seperated = [np.array(x_test_dict[i]) for i in range(10)]\n",
    "y_test_seperated = [np.array(y_test_dict[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "plt.figure()\n",
    "plt.title('Data separation per class')\n",
    "plt.bar(x_train_dict.keys(), [len(v) for v in x_train_dict.values()], color='tab:blue')\n",
    "plt.bar(x_test_dict.keys(), [len(v) for v in x_test_dict.values()], color='orange', width=0.6)\n",
    "plt.legend(['x_train', 'x_test'], loc='center right', framealpha=1.0)\n",
    "plt.xlabel('class label')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data into batches for clients to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients per class:  99.6 ~= 100\n",
      "Total number of clients: 996\n",
      "Average batch size: 60.6\n"
     ]
    }
   ],
   "source": [
    "# Separate the data into a long list of batches, each batch representing a client training with that batch of images.\n",
    "# After each batch, a new client will have the opportunity to train their batch of images.\n",
    "# Batches are shuffled to simulate many clients training the model at once.\n",
    "\n",
    "client_counts = {}\n",
    "batch_sizes = {}\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "def ceil(a,b):\n",
    "    return -(-a//b)\n",
    "\n",
    "for class_idx in range(len(x_train_seperated)):\n",
    "    # Get batches from class data:\n",
    "    n_samples_per_class = len(x_train_seperated[class_idx])\n",
    "    samples_per_client = n_samples_per_class / clients_per_class\n",
    "    better_batch_size = int(math.ceil(samples_per_client))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(ceil(n_samples_per_class, better_batch_size)):\n",
    "        x_batches.append((class_idx, x_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        y_batches.append((class_idx, y_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        count += 1\n",
    "    client_counts[class_idx] = count\n",
    "    batch_sizes[class_idx] = better_batch_size\n",
    "        \n",
    "# double check that the clients_per_class is upheld per class\n",
    "# (blue bars should be uniform, orange should change according to class):\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('class label')\n",
    "ax1.set_ylabel('client count', color=color)\n",
    "plt.bar(client_counts.keys(), [v for v in client_counts.values()], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'orange'\n",
    "ax2.set_ylabel('batch size', color=color)  # we already handled the x-label with ax1\n",
    "plt.bar(batch_sizes.keys(), [v for v in batch_sizes.values()], color=color, width=0.6)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylim(0, np.mean([v for v in batch_sizes.values()])*2)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()\n",
    "\n",
    "print('Clients per class:  {} ~= {}'.format(np.mean([v for v in client_counts.values()]), clients_per_class))\n",
    "print('Total number of clients: {}'.format(np.sum([v for v in client_counts.values()])))\n",
    "print('Average batch size: {}'.format(np.mean([v for v in batch_sizes.values()])))\n",
    "\n",
    "split_batch_size = np.floor(np.mean([v for v in batch_sizes.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the attacker's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 clients to choose from:\n",
      "Classes of attack clients: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Choosing the following clients as the attackers:\n",
      "[71 23 68 72 38]\n"
     ]
    }
   ],
   "source": [
    "x_batches_filtered_i = [i for i, batch in enumerate(x_batches) if batch[0] == attack_params['our_class']]\n",
    "y_batches_filtered_i = [i for i, batch in enumerate(y_batches) if batch[0] == attack_params['our_class']]\n",
    "assert x_batches_filtered_i == y_batches_filtered_i\n",
    "\n",
    "x_batches_filtered = list(map(x_batches.__getitem__, x_batches_filtered_i))\n",
    "y_batches_filtered = list(map(y_batches.__getitem__, y_batches_filtered_i))\n",
    "\n",
    "print('{} clients to choose from:'.format(len(x_batches_filtered)))\n",
    "print('Classes of attack clients:', [f[0] for f in x_batches_filtered])\n",
    "print()\n",
    "\n",
    "attack_clients = np.random.choice(len(x_batches_filtered), attack_params['attacker_clients'], replace=False)\n",
    "print('Choosing the following clients as the attackers:\\n{}'.format(attack_clients))\n",
    "x_attack_batches = list(map(x_batches_filtered.__getitem__, attack_clients))\n",
    "y_attack_batches = list(map(y_batches_filtered.__getitem__, attack_clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset length: 996 996\n",
      "New dataset length:      991 991\n"
     ]
    }
   ],
   "source": [
    "# remove the attackers from the original training dataset\n",
    "# BREAKS THE ORIGINAL X_BATCHES AND Y_BATCHES!\n",
    "print('Original dataset length:', len(x_batches), len(y_batches))\n",
    "\n",
    "x_attackers_i = list(map(x_batches_filtered_i.__getitem__, attack_clients))\n",
    "y_attackers_i = list(map(y_batches_filtered_i.__getitem__, attack_clients))\n",
    "\n",
    "x_batches = [batch for i, batch in enumerate(x_batches) if i not in x_attackers_i]\n",
    "y_batches = [batch for i, batch in enumerate(y_batches) if i not in y_attackers_i]\n",
    "\n",
    "print('New dataset length:     ', len(x_batches), len(y_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data for Split Learning\n",
    "split_train_dataset = (x_batches, y_batches)\n",
    "split_test_dataset = (x_test, y_test)\n",
    "\n",
    "# place into train params:\n",
    "split_training_params['train_dataset'] = split_train_dataset\n",
    "split_training_params['test_dataset'] = split_test_dataset\n",
    "\n",
    "# Build attack dataset\n",
    "attack_train_dataset = (x_attack_batches, y_attack_batches)\n",
    "attack_params['train_dataset'] = attack_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0; Max: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Show min and max of the dataset (ensure you are using the right normalization)\n",
    "min_ = np.inf\n",
    "max_ = -np.inf\n",
    "for batch in x_batches:\n",
    "    min__ = np.min(batch[1])\n",
    "    max__ = np.max(batch[1])\n",
    "    min_ = min(min_, min__)\n",
    "    max_ = max(max_, max__)\n",
    "print('Min: {}; Max: {}'.format(min_, max_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "\n",
    "def start_piece(identifier, input_shape, filters=4):\n",
    "    assert filters >= 1\n",
    "    \n",
    "    input_1 = keras.layers.Input(input_shape)\n",
    "    conv1 = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(input_1)\n",
    "    model = keras.models.Model(inputs=[input_1], outputs=conv1)\n",
    "    model._name = identifier\n",
    "    \n",
    "    return model\n",
    "\n",
    "def blackbox_piece(identifier, input_shape, depth=1, filters=4):\n",
    "    assert depth >= 1\n",
    "    assert filters >= 1\n",
    "    \n",
    "    input_2 = keras.layers.Input(input_shape)\n",
    "    \n",
    "    # for now, we will just give the black-box all the CNN layers\n",
    "    for i in range(depth-1):\n",
    "        if i == 0:\n",
    "            convs = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(input_2)\n",
    "        else:\n",
    "            convs = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(convs)\n",
    "            \n",
    "    model = keras.models.Model(inputs=[input_2], outputs=convs)\n",
    "    model._name = identifier\n",
    "    \n",
    "    return model\n",
    "\n",
    "def approximator_piece(identifier, input_shape, depth=1, filters=4):\n",
    "    assert depth >= 1\n",
    "    assert filters >= 1\n",
    "    \n",
    "    input_2 = keras.layers.Input(input_shape)\n",
    "    \n",
    "    # for now, we will just give the black-box all the CNN layers\n",
    "    for i in range(depth-1):\n",
    "        if i == 0:\n",
    "            convs = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(input_2)\n",
    "        else:\n",
    "            convs = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(convs)\n",
    "            \n",
    "    model = keras.models.Model(inputs=[input_2], outputs=convs)\n",
    "    model._name = identifier\n",
    "    \n",
    "    return model\n",
    "\n",
    "def end_piece(identifier, input_shape, dense_breadth=128, num_classes=10):\n",
    "    assert dense_breadth >= num_classes\n",
    "    \n",
    "    input_3 = keras.layers.Input(input_shape)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(input_3)\n",
    "    drop1 = Dropout(0.25)(pool1)\n",
    "    flat1 = Flatten()(drop1)\n",
    "    dense1 = Dense(dense_breadth, activation='relu')(flat1)\n",
    "    drop2 = Dropout(0.5)(dense1)\n",
    "    dense2 = Dense(num_classes, activation='softmax')(drop2)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_3], outputs=dense2)\n",
    "    model._name = identifier\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the params are acceptable:\n",
    "assert depth >= 1\n",
    "assert filters >= 1\n",
    "assert dense >= num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitLearning:\n",
    "    \n",
    "    def __init__(self, split_training_params):\n",
    "        self.minibatch_size = split_training_params['minibatch_size']\n",
    "        self.batches_per_train_step = split_training_params['apply_gradients_after']\n",
    "        self.eval_batch_size = split_training_params['eval_batch_size']\n",
    "        self.shuffle_clients = split_training_params['shuffle_clients']\n",
    "        \n",
    "        self.ckpt_folder = split_training_params['ckpt_folder']\n",
    "        self.start_id = split_training_params['start_id']\n",
    "        self.middle_id = split_training_params['middle_id']\n",
    "        self.end_id = split_training_params['end_id']\n",
    "        self.full_id = split_training_params['full_id']\n",
    "        \n",
    "        # define the NN model\n",
    "        self.start_piece = None\n",
    "        self.middle_piece = None\n",
    "        self.end_piece = None\n",
    "        self.server_pub, server_shape = self.server_publisher()\n",
    "        self.client_sub = self.client_subscriber(server_shape)\n",
    "        self.model = self.blackbox_model(self.server_pub, self.client_sub)\n",
    "        \n",
    "        # define loss function\n",
    "        self.cross_entropy = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define metrics\n",
    "        self.acc_train_avg = None\n",
    "        self.loss_train_avg = None\n",
    "        \n",
    "        # setup checkpointing\n",
    "        self.init_ckpt()\n",
    "        \n",
    "        # setup ops\n",
    "        self.setup_ops()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Black-box model\n",
    "        \n",
    "    def server_publisher(self):\n",
    "        # create the first two models (start and middle)\n",
    "        \n",
    "        #   start piece...\n",
    "        self.start_piece = start_piece(self.start_id, input_shape, filters)\n",
    "        output_shape = self.start_piece.layers[-1].output_shape[1:]\n",
    "        \n",
    "        #   middle...\n",
    "        self.middle_piece = blackbox_piece(self.middle_id, output_shape, depth, filters)\n",
    "        output_shape = self.middle_piece.layers[-1].output_shape[1:]\n",
    "        \n",
    "        # glue the three models together\n",
    "        input_ = keras.layers.Input(input_shape)\n",
    "        hidden1 = self.start_piece(input_)\n",
    "        output_ = self.middle_piece(hidden1)\n",
    "        \n",
    "        # create the full model\n",
    "        model = keras.models.Model(inputs=[input_], outputs=output_)\n",
    "        model._name = self.full_id+\"_pub\"\n",
    "        model.summary()\n",
    "        \n",
    "        return model, output_shape\n",
    "        \n",
    "    def client_subscriber(self, input_shape):\n",
    "        # create the last model (end piece)\n",
    "        \n",
    "        #   end piece...\n",
    "        self.end_piece = end_piece(self.end_id, input_shape, dense, num_classes)\n",
    "        \n",
    "        # glue the three models together\n",
    "        input_ = keras.layers.Input(input_shape)\n",
    "        output_ = self.end_piece(input_)\n",
    "        \n",
    "        # create the full model\n",
    "        model = keras.models.Model(inputs=[input_], outputs=output_)\n",
    "        model._name = self.full_id+\"_sub\"\n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def blackbox_model(self, pub, sub):\n",
    "        # glue both models together\n",
    "        \n",
    "        input_ = pub.input\n",
    "        output_ = sub(pub.output)\n",
    "        \n",
    "        full_model = keras.models.Model(inputs=[input_], outputs=output_)\n",
    "        full_model._name = self.full_id+\"_combined\"\n",
    "        full_model.summary()\n",
    "        \n",
    "        return full_model\n",
    "    \n",
    "    def model_loss(self, y_true, y_pred):\n",
    "        return self.cross_entropy(y_true, y_pred)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Train\n",
    "    \n",
    "    def setup_ops(self):\n",
    "        # INSPIRED BY: https://stackoverflow.com/questions/42156957/how-to-update-model-parameters-with-accumulated-gradients\n",
    "        # https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\n",
    "        \n",
    "        self.tvs = self.model.trainable_variables\n",
    "        self.accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in self.tvs]\n",
    "        self.accum_counter = tf.Variable(0.0, trainable=False)\n",
    "    \n",
    "    def train(self, datasets, iteration, g_dataset=None, batch_limit=None, mask=None):\n",
    "        # setup checkpointing\n",
    "        self.setup_ckpt(iteration)\n",
    "        \n",
    "        # setup bb_dataset (stores labels if g_dataset is passed in)\n",
    "        bb_dataset = []\n",
    "        \n",
    "        g_dataset_acc = tf.keras.metrics.Accuracy()\n",
    "        \n",
    "        # initialize the metrics each new epoch\n",
    "        if self.acc_train_avg is not None:\n",
    "            del self.acc_train_avg\n",
    "        if self.loss_train_avg is not None:\n",
    "            del self.loss_train_avg\n",
    "        self.acc_train_avg = tf.keras.metrics.Accuracy()\n",
    "        self.loss_train_avg = tf.keras.metrics.Mean()\n",
    "        \n",
    "        # append all datasets together for training:\n",
    "        x_batches = []\n",
    "        y_batches = []\n",
    "        for dataset in datasets:\n",
    "            x_batches_, y_batches_ = dataset\n",
    "            x_batches = x_batches + x_batches_\n",
    "            y_batches = y_batches + y_batches_\n",
    "        # if g_dataset is not None, add those batches to the end:\n",
    "        if g_dataset is not None:\n",
    "            g_x_batches, g_y_batches = g_dataset\n",
    "            g_batch_idxs = list(range(len(x_batches), len(x_batches)+len(g_x_batches)))\n",
    "            x_batches = x_batches + g_x_batches\n",
    "            y_batches = y_batches + g_y_batches\n",
    "        else:\n",
    "            g_batch_idxs = []\n",
    "            \n",
    "        # setup progress bar\n",
    "        total_batches = batch_limit if batch_limit is not None and batch_limit < len(x_batches) else len(x_batches)\n",
    "        pbar = notebook.tqdm(total=total_batches)\n",
    "        \n",
    "        batch_idxs = list(range(len(x_batches)))\n",
    "        if self.shuffle_clients:\n",
    "            # shuffle the batches each time\n",
    "            random.shuffle(batch_idxs)\n",
    "            \n",
    "        for i, batch_idx in enumerate(batch_idxs):\n",
    "            x_batch = x_batches[batch_idx][1]\n",
    "            y_batch = y_batches[batch_idx][1]\n",
    "            \n",
    "            # if a mask is applied, replace the cases when the mask is 1\n",
    "            if mask is not None:\n",
    "                mask_idx = g_batch_idxs.index(batch_idx)\n",
    "                mask_batch = mask[:, mask_idx, 0] # (100, 28, 28, 1)\n",
    "            else:\n",
    "                mask_batch = None\n",
    "            \n",
    "            if batch_idx in g_batch_idxs:\n",
    "                # this is a g_x_batch! don't apply gradients, but store the prediction\n",
    "                client_logits, server_logits = self.pred_step(x_batch, mask_batch)\n",
    "                g_dataset_acc(tf.argmax(y_batch, 1), tf.argmax(client_logits, 1))\n",
    "                \n",
    "                bb_dataset.append((x_batch, y_batch, client_logits))\n",
    "            else:\n",
    "                # TODO: also mask these\n",
    "                self.train_step(i, x_batch, y_batch, len(batch_idxs) - 1)\n",
    "            pbar.update(1)\n",
    "            pbar.set_description('train_acc={:.2f}%'.format(self.acc_train_avg.result()*100))\n",
    "            \n",
    "            if batch_limit is not None and i-1 >= batch_limit:\n",
    "                break\n",
    "        pbar.close()\n",
    "        print('train_acc={:.4f}%'.format(self.acc_train_avg.result()*100))\n",
    "        print('accuracy of blackbox on G dataset: {:.4f}%'.format(g_dataset_acc.result()*100))\n",
    "        \n",
    "        # save checkpoints\n",
    "        self.checkpoint()\n",
    "        \n",
    "        return bb_dataset\n",
    "        \n",
    "    def pred_step(self, x_batch, mask_batch):\n",
    "        \n",
    "        # Generate the output from the server:\n",
    "        server_logits = []\n",
    "        j = 0\n",
    "        while(j < len(x_batch)):\n",
    "            if self.minibatch_size is None:\n",
    "                # use whole batch (no minibatch)\n",
    "                x_minibatch = x_batch\n",
    "            else:\n",
    "                x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "\n",
    "            logits = self.server_pub(x_minibatch, training=True)\n",
    "            server_logits = server_logits + [logits]\n",
    "\n",
    "            if self.minibatch_size is None:\n",
    "                break\n",
    "            else:\n",
    "                j += self.minibatch_size\n",
    "        server_logits = tf.concat(server_logits, 0)\n",
    "                \n",
    "        # Apply masking\n",
    "        \n",
    "        # replacing with just zeros for now:\n",
    "        if mask_batch is not None:\n",
    "            \n",
    "            # convert the mask batch (1, 100) into (100, 28, 28, 33)\n",
    "            mask = np.ones(shape=server_logits.shape)\n",
    "            mask[mask_batch[0] == 1, ...] = 0\n",
    "            assert mask[mask == 0].size > 0\n",
    "            \n",
    "            print('server logits:', server_logits.shape)\n",
    "            print('mask:', mask.shape)\n",
    "            server_logits = tf.math.multiply(server_logits, mask)\n",
    "                \n",
    "        # Generate the output from the client, accepting the server's response as input:\n",
    "        client_logits = []\n",
    "        j = 0\n",
    "        while(j < len(server_logits)):\n",
    "            if self.minibatch_size is None:\n",
    "                # use whole batch (no minibatch)\n",
    "                x_minibatch = server_logits\n",
    "            else:\n",
    "                x_minibatch = server_logits[j:(j+self.minibatch_size)]\n",
    "\n",
    "            print(x_minibatch.shape)\n",
    "            logits = self.client_sub(x_minibatch, training=True)\n",
    "#             logits = self.model(x_minibatch, training=True)\n",
    "            client_logits = client_logits + list(logits.numpy())\n",
    "\n",
    "            if self.minibatch_size is None:\n",
    "                break\n",
    "            else:\n",
    "                j += self.minibatch_size\n",
    "                \n",
    "        return client_logits, server_logits\n",
    "        \n",
    "    def train_step(self, i, x_batch, y_batch, limit):\n",
    "        # Iterate over the client's batch in minibatches:\n",
    "        j = 0\n",
    "        while(j < len(x_batch)):\n",
    "            if self.minibatch_size is None:\n",
    "                # use whole batch (no minibatch)\n",
    "                x_minibatch = x_batch\n",
    "                y_minibatch = y_batch\n",
    "            else:\n",
    "                x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                y_minibatch = y_batch[j:(j+self.minibatch_size)]\n",
    "\n",
    "            # run the gradients\n",
    "            loss_value, grads = self.grad(x_minibatch, y_minibatch)\n",
    "\n",
    "            # accumulate them\n",
    "            self.accumulate_grads(grads)\n",
    "\n",
    "            if self.minibatch_size is None:\n",
    "                break\n",
    "            else:\n",
    "                j += self.minibatch_size\n",
    "\n",
    "        # perform a train step every batches_per_train_step number of batches:\n",
    "        if (i > 0 and i % self.batches_per_train_step == 0) or i == limit:\n",
    "            # Run the train_step ops to update the weights based on our accumulated gradients\n",
    "            self.optimize()\n",
    "            self.zero_out()\n",
    "    \n",
    "    def grad(self, inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(inputs, training=True)\n",
    "            loss_value = self.model_loss(targets, logits)\n",
    "            \n",
    "        # evaluate accuracy and append acc and loss to arrays\n",
    "        self.acc_train_avg(tf.argmax(targets, 1), tf.argmax(logits, 1))\n",
    "        self.loss_train_avg(loss_value)\n",
    "        \n",
    "        return loss_value, tape.gradient(loss_value, self.model.trainable_variables)\n",
    "    \n",
    "    def accumulate_grads(self, grads):\n",
    "        # add to accum_vars the new gradients\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.accum_vars[i].assign_add(grad)\n",
    "        # increment the counter by 1\n",
    "        self.accum_counter.assign_add(1.0)\n",
    "        \n",
    "    def optimize(self):\n",
    "        # apply the gradients in accum_vars, dividing by the number in accum_counter\n",
    "        self.optimizer.apply_gradients(\n",
    "            [(accum_var / self.accum_counter, tv) \\\n",
    "                for (accum_var, tv) in zip(self.accum_vars, self.model.trainable_variables)]\n",
    "        )\n",
    "    \n",
    "    def zero_out(self):\n",
    "        # reset accum_vars and accum_counter back to 0\n",
    "        for i, tv in enumerate(self.accum_vars):\n",
    "            self.accum_vars[i].assign(tf.zeros_like(tv))\n",
    "        self.accum_counter = tf.Variable(0.0, trainable=False)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = None\n",
    "        self.internal_iteration = None\n",
    "        self.iteration_offset = 0\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        # setup fresh checkpointer every new iteration\n",
    "        if self.internal_iteration is None or iteration != self.internal_iteration - self.iteration_offset:\n",
    "            ckpt_save_folder = os.path.join('../gan_attack/checkpoints', 'it_{}'.format(iteration + self.iteration_offset), self.ckpt_folder)\n",
    "            os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "        \n",
    "            if self.ckpt is not None:\n",
    "                del self.ckpt\n",
    "            if self.manager is not None:\n",
    "                del self.manager\n",
    "\n",
    "            self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "            self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "            self.internal_iteration = iteration + self.iteration_offset\n",
    "    \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved checkpoint: {}\".format(save_path))\n",
    "        self.save_all_models(save_path)\n",
    "        \n",
    "    def save_all_models(self, save_path):\n",
    "        # in addition to checkpointing, save all of the models into their own ckpt files\n",
    "        it_folder = \"\"\n",
    "        for folder in self.splitall(save_path):\n",
    "            if \"it\" not in folder:\n",
    "                it_folder = os.path.join(it_folder, folder)\n",
    "            else:\n",
    "                it_folder = os.path.join(it_folder, folder)\n",
    "                break\n",
    "        \n",
    "        # save all three models\n",
    "        start_piece_folder = os.path.join(it_folder, self.start_id + \"_checkpoint\")\n",
    "        os.makedirs(start_piece_folder, exist_ok=True)\n",
    "        self.start_piece.save_weights(os.path.join(start_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved checkpoint: {}\".format(os.path.join(start_piece_folder, 'checkpoint')))\n",
    "        \n",
    "        middle_piece_folder = os.path.join(it_folder, self.middle_id + \"_checkpoint\")\n",
    "        os.makedirs(middle_piece_folder, exist_ok=True)\n",
    "        self.middle_piece.save_weights(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved checkpoint: {}\".format(os.path.join(middle_piece_folder, 'checkpoint')))\n",
    "        \n",
    "        end_piece_folder = os.path.join(it_folder, self.end_id + \"_checkpoint\")\n",
    "        os.makedirs(end_piece_folder, exist_ok=True)\n",
    "        self.end_piece.save_weights(os.path.join(end_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved checkpoint: {}\".format(os.path.join(end_piece_folder, 'checkpoint')))\n",
    "        \n",
    "    @staticmethod\n",
    "    def splitall(path):\n",
    "        allparts = []\n",
    "        while 1:\n",
    "            parts = os.path.split(path)\n",
    "            if parts[0] == path:  # sentinel for absolute paths\n",
    "                allparts.insert(0, parts[0])\n",
    "                break\n",
    "            elif parts[1] == path: # sentinel for relative paths\n",
    "                allparts.insert(0, parts[1])\n",
    "                break\n",
    "            else:\n",
    "                path = parts[0]\n",
    "                allparts.insert(0, parts[1])\n",
    "        return allparts\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        parent_folder = os.path.join('../gan_attack/checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                self.iteration_offset = largest_it\n",
    "                print('Restored latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found, starting with a fresh network')\n",
    "        else:\n",
    "            if load_default:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    self.iteration_offset = it_restore\n",
    "                print('Restored latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "        \n",
    "    def evaluate(self, dataset):\n",
    "        '''\n",
    "        NOTE: dataset here is tailored for standard 'test' dataset provided by Keras\n",
    "        '''\n",
    "        \n",
    "        x, y = dataset\n",
    "        \n",
    "        acc_test_avg = tf.keras.metrics.Accuracy()\n",
    "        loss_test_avg = tf.keras.metrics.Mean()\n",
    "        for i in range(0, len(x), self.eval_batch_size):\n",
    "            # get batch\n",
    "            x_batch = x[i:i+self.eval_batch_size]\n",
    "            y_batch = y[i:i+self.eval_batch_size]\n",
    "            \n",
    "            # evaluate\n",
    "            logits = self.model(x_batch, training=False)\n",
    "            acc_test_avg(tf.argmax(y_batch, 1), tf.argmax(logits, 1))\n",
    "            loss_test_avg(self.model_loss(y_batch, logits))\n",
    "        \n",
    "        if self.acc_train_avg is not None and self.loss_train_avg is not None:\n",
    "            print('Train Accuracy: {:.3f} | Loss: {:.3f}'.format(self.acc_train_avg.result(), self.loss_train_avg.result()))\n",
    "        print('Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test_avg.result(), loss_test_avg.result()))\n",
    "        print()\n",
    "        return acc_test_avg.result()\n",
    "        \n",
    "    def predict(self, dataset, return_tensors=True):\n",
    "        '''\n",
    "        Returns a list of label batches of each client that was in the dataset\n",
    "        '''\n",
    "        \n",
    "        x, _ = dataset\n",
    "        labels = []\n",
    "        \n",
    "        for i, client_x in enumerate(x):\n",
    "            x_batch = client_x[1]\n",
    "            label_batch = []\n",
    "            \n",
    "            # run through every minibatch:\n",
    "            j = 0\n",
    "            while(j < len(x_batch)):\n",
    "                if self.minibatch_size is None:\n",
    "                    # use whole batch (no minibatch)\n",
    "                    x_minibatch = x_batch\n",
    "                else:\n",
    "                    x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                    \n",
    "                # evaluate\n",
    "                preds = self.model(x_batch, training=False)\n",
    "                if not return_tensors:\n",
    "                    preds = tf.nn.softmax(preds)\n",
    "                    preds = tf.argmax(preds, axis=1)\n",
    "                    \n",
    "                label_batch = label_batch + list(preds.numpy())\n",
    "                \n",
    "                if self.minibatch_size is None:\n",
    "                    break\n",
    "                else:\n",
    "                    j += self.minibatch_size\n",
    "            \n",
    "            # add to list\n",
    "            labels.append(label_batch)\n",
    "            \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D:\n",
    "    '''\n",
    "    The Discriminator portion of the GAN. Accepts a network, otherwise creates a new model.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, start_piece=None, middle_piece=None, end_piece=None, d_model=None):\n",
    "        \n",
    "#         self.ckpt_folder = gan_training_params['d_ckpt_folder']\n",
    "        self.ckpt_folder = gan_training_params['middle_id']\n",
    "        self.bb_ckpt_folder = gan_training_params['bb_ckpt_folder']\n",
    "        self.loop_times = gan_training_params['loop_times']\n",
    "        self.softmax_power = gan_training_params['softmax_power']\n",
    "        self.minibatch_size = gan_training_params['minibatch_size']\n",
    "        \n",
    "        self.use_bb_ends = gan_training_params['use_bb_ends']\n",
    "        self.start_id = gan_training_params['start_id']\n",
    "        self.middle_id = gan_training_params['middle_id']\n",
    "        self.end_id = gan_training_params['end_id']\n",
    "        self.full_id = gan_training_params['full_id']\n",
    "        \n",
    "        # make FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "        \n",
    "        # define the NN model\n",
    "        if d_model is not None:\n",
    "            assert start_piece is None and middle_piece is None and end_piece is None\n",
    "            self.model = d_model\n",
    "        else:\n",
    "            self.start_piece = start_piece\n",
    "            self.middle_piece = middle_piece\n",
    "            self.end_piece = end_piece\n",
    "            self.model = self.discriminator_model()\n",
    "            \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define entropies\n",
    "        self.cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        self.bin_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            \n",
    "        # setup checkpointing\n",
    "        self.ckpt = None\n",
    "        self.manager = None\n",
    "        \n",
    "        # save the initial weights\n",
    "        if middle_piece is None:\n",
    "            self.save_initial_weights()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Discriminator model\n",
    "    \n",
    "    def discriminator_model(self):\n",
    "        # create all three models\n",
    "        \n",
    "        #   start piece...\n",
    "        if self.use_bb_ends:\n",
    "            assert self.start_piece is not None\n",
    "        else:\n",
    "            self.start_piece = start_piece(self.start_id, input_shape, filters)\n",
    "        output_shape = self.start_piece.layers[-1].output_shape[1:]\n",
    "        \n",
    "        #   middle...\n",
    "        if self.middle_piece is None:\n",
    "            self.middle_piece = approximator_piece(self.middle_id, output_shape, depth, filters)\n",
    "        else:\n",
    "            print('WARNING: using the middle piece in D')\n",
    "        output_shape = self.middle_piece.layers[-1].output_shape[1:]\n",
    "        \n",
    "        #   end piece...\n",
    "        if self.use_bb_ends:\n",
    "            assert self.end_piece is not None\n",
    "        else:\n",
    "            self.end_piece = end_piece(self.end_id, output_shape, dense, num_classes)\n",
    "        \n",
    "        # glue the three models together\n",
    "        input_ = keras.layers.Input(input_shape)\n",
    "        hidden1 = self.start_piece(input_)\n",
    "        hidden2 = self.middle_piece(hidden1)\n",
    "        output_ = self.end_piece(hidden2)\n",
    "        \n",
    "        # create the full model\n",
    "        model = keras.models.Model(inputs=[input_], outputs=output_)\n",
    "        model._name = self.full_id\n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Loss\n",
    "    \n",
    "    def loss(self, fake_discrimination, labels):\n",
    "        matches = self.matches_labels(fake_discrimination, labels, loop_times=self.loop_times)\n",
    "        # we want the discriminator to NOT be fooled by these fake images\n",
    "        cross_entropy = self.bin_cross_entropy(tf.zeros_like(matches), matches)\n",
    "        return cross_entropy\n",
    "    \n",
    "    def entropy(self, y_true, y_pred):\n",
    "        return self.cat_cross_entropy(y_true, y_pred)\n",
    "        \n",
    "    def matches_labels(self, fake_output, labels, loop_times=0):\n",
    "        '''\n",
    "        Only works if the Discriminator is already trained on real images!!\n",
    "        1. Performs a softmax -> onehot conversion (differentiable approx.)\n",
    "        2. Multiplies this by the onehot version of the onehot attack label\n",
    "        3. Sums to reduce dimension\n",
    "        \n",
    "        - if the sum is close to 1, the nn thinks that the image is a part of the attack class\n",
    "        - if the sum is close to 0, the nn thinks that the image is not of the attack class\n",
    "        - the sum should not be in between, due to the onehot conversion we perform in step 1\n",
    "        '''\n",
    "        # 1.\n",
    "        my_power = self.softmax_power\n",
    "        for i in range(loop_times):\n",
    "            fake_output = self.soft_onehot(fake_output)\n",
    "        \n",
    "        # 2.\n",
    "        matches = tf.math.multiply(fake_output, labels)\n",
    "        \n",
    "        # 3.\n",
    "        reduced = tf.math.reduce_sum(matches, axis=-1)\n",
    "        \n",
    "        return reduced\n",
    "        \n",
    "    def soft_onehot(self, softmax, my_power=8):\n",
    "        '''\n",
    "        Shown to not really work... vanishing gradients problem\n",
    "        '''\n",
    "        soft_extreme = softmax ** my_power\n",
    "        norm = tf.reduce_sum(soft_extreme, axis=-1)\n",
    "        almost_onehot = tf.math.divide(soft_extreme, tf.reshape(norm, (-1, 1)))\n",
    "        return almost_onehot\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        ckpt_save_folder = os.path.join('../gan_attack/checkpoints', 'it_{}'.format(iteration), self.ckpt_folder)\n",
    "        os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "        if self.ckpt is not None:\n",
    "            del self.ckpt\n",
    "        if self.manager is not None:\n",
    "            del self.manager\n",
    "\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.middle_piece)\n",
    "        self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "        \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved D checkpoint: {}\".format(save_path))\n",
    "        self.save_all_models(save_path)\n",
    "        \n",
    "    def save_all_models(self, save_path):\n",
    "        # in addition to checkpointing, save all of the models into their own ckpt files\n",
    "        it_folder = \"\"\n",
    "        for folder in self.splitall(save_path):\n",
    "            if \"it\" not in folder:\n",
    "                it_folder = os.path.join(it_folder, folder)\n",
    "            else:\n",
    "                it_folder = os.path.join(it_folder, folder)\n",
    "                break\n",
    "        \n",
    "        # save all three models\n",
    "        start_piece_folder = os.path.join(it_folder, self.start_id + \"_checkpoint\")\n",
    "        os.makedirs(start_piece_folder, exist_ok=True)\n",
    "        self.start_piece.save_weights(os.path.join(start_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved D checkpoint: {}\".format(os.path.join(start_piece_folder, 'checkpoint')))\n",
    "        \n",
    "        middle_piece_folder = os.path.join(it_folder, self.middle_id + \"_checkpoint\")\n",
    "        os.makedirs(middle_piece_folder, exist_ok=True)\n",
    "        self.middle_piece.save_weights(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved D checkpoint: {}\".format(os.path.join(middle_piece_folder, 'checkpoint')))\n",
    "        \n",
    "        end_piece_folder = os.path.join(it_folder, self.end_id + \"_checkpoint\")\n",
    "        os.makedirs(end_piece_folder, exist_ok=True)\n",
    "        self.end_piece.save_weights(os.path.join(end_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved D checkpoint: {}\".format(os.path.join(end_piece_folder, 'checkpoint')))\n",
    "        \n",
    "    @staticmethod\n",
    "    def splitall(path):\n",
    "        allparts = []\n",
    "        while 1:\n",
    "            parts = os.path.split(path)\n",
    "            if parts[0] == path:  # sentinel for absolute paths\n",
    "                allparts.insert(0, parts[0])\n",
    "                break\n",
    "            elif parts[1] == path: # sentinel for relative paths\n",
    "                allparts.insert(0, parts[1])\n",
    "                break\n",
    "            else:\n",
    "                path = parts[0]\n",
    "                allparts.insert(0, parts[1])\n",
    "        return allparts\n",
    "    \n",
    "    def freeze_ends(self, yes):\n",
    "        self.start_piece.is_training = not yes\n",
    "        self.end_piece.is_training = not yes\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Load/save weights\n",
    "    \n",
    "    def save_initial_weights(self):\n",
    "        print('saving initial weights for D')\n",
    "        init_folder = os.path.join('../gan_attack/checkpoints', 'init', self.ckpt_folder)\n",
    "        os.makedirs(init_folder, exist_ok=True)\n",
    "        self.model.save_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def load_initial_weights(self):\n",
    "        print('loading initial weights for D')\n",
    "        init_folder = os.path.join('../gan_attack/checkpoints', 'init', self.ckpt_folder)\n",
    "        self.model.load_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False, use_blackbox=False):\n",
    "        iteration_offset = 0\n",
    "        parent_folder = os.path.join('../gan_attack/checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "#                 checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "#                 self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                self.restore_pieces(it_restore_ends=largest_it, it_restore_middle=largest_it)\n",
    "                iteration_offset = largest_it\n",
    "#                 print('Restored D to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found for D, starting with a fresh network')\n",
    "        else:\n",
    "            if load_default:\n",
    "                if use_blackbox:\n",
    "                    checkpoint_directory = os.path.join(parent_folder, 'default', self.bb_ckpt_folder)\n",
    "                else:\n",
    "                    checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    iteration_offset = it_restore\n",
    "                print('Restored D to checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        return iteration_offset\n",
    "    \n",
    "    def restore_middle(self, it_restore_middle):\n",
    "        parent_folder = os.path.join('../gan_attack/checkpoints')\n",
    "        it_folder_middle = os.path.join(parent_folder, 'it_{}'.format(it_restore_middle))\n",
    "        middle_piece_folder = os.path.join(it_folder_middle, self.middle_id + \"_checkpoint\")\n",
    "        print('Restoring D piece: {}'.format(middle_piece_folder))\n",
    "        \n",
    "        assert os.path.isfile(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        self.middle_piece.load_weights(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "    \n",
    "    def restore_pieces(self, it_restore_ends=None, it_restore_middle=None, start_id=None, middle_id=None, \n",
    "                       end_id=None, load_default=False):\n",
    "        \n",
    "        if it_restore_ends is None:\n",
    "            it_restore_ends = 1\n",
    "        if it_restore_middle is None:\n",
    "            it_restore_middle = 1\n",
    "        \n",
    "        if start_id is None:\n",
    "            start_id = self.start_id\n",
    "        if middle_id is None:\n",
    "            middle_id = self.middle_id\n",
    "        if end_id is None:\n",
    "            end_id = self.end_id\n",
    "        \n",
    "        parent_folder = os.path.join('../gan_attack/checkpoints')\n",
    "        it_folder_ends = os.path.join(parent_folder, 'default' if load_default else 'it_{}'.format(it_restore_ends))\n",
    "        it_folder_middle = os.path.join(parent_folder, 'default' if load_default else 'it_{}'.format(it_restore_middle))\n",
    "        \n",
    "        start_piece_folder = os.path.join(it_folder_ends, start_id + \"_checkpoint\")\n",
    "        print('Restoring D piece: {}'.format(start_piece_folder))\n",
    "        middle_piece_folder = os.path.join(it_folder_middle, middle_id + \"_checkpoint\")\n",
    "        print('Restoring D piece: {}'.format(middle_piece_folder))\n",
    "        end_piece_folder = os.path.join(it_folder_ends, end_id + \"_checkpoint\")\n",
    "        print('Restoring D piece: {}'.format(end_piece_folder))\n",
    "        \n",
    "        assert os.path.isfile(os.path.join(start_piece_folder, 'checkpoint'))\n",
    "        assert os.path.isfile(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        assert os.path.isfile(os.path.join(end_piece_folder, 'checkpoint'))\n",
    "        \n",
    "        self.start_piece.load_weights(os.path.join(start_piece_folder, 'checkpoint'))\n",
    "        self.middle_piece.load_weights(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        self.end_piece.load_weights(os.path.join(end_piece_folder, 'checkpoint'))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluation\n",
    "\n",
    "    def discriminate(self, generated_images, training=True):\n",
    "        return self.model(generated_images, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G:\n",
    "    '''\n",
    "    The Generator portion of the GAN. Generates images given a conditional label.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, is_conditional=True, identifier=None, extra_depth=0):\n",
    "        self.is_conditional = is_conditional\n",
    "        self.identifier = identifier\n",
    "        \n",
    "        self.ckpt_folder = self.g_identifier() + gan_training_params['g_ckpt_folder']\n",
    "        self.noise_dim = gan_training_params['noise_dim']\n",
    "        self.uncertain_loop_times = gan_training_params['uncertain_loop_times']\n",
    "        self.softmax_power = gan_training_params['softmax_power']\n",
    "        \n",
    "        # make FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "        self.input_shapes = []\n",
    "        if is_conditional:\n",
    "            self.model = self.c_generator_model(extra_depth)\n",
    "        else:\n",
    "            self.model = self.u_generator_model()\n",
    "            \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define entropies\n",
    "        self.cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        self.bin_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            \n",
    "        # setup checkpointing\n",
    "        self.ckpt = None\n",
    "        self.manager = None\n",
    "        \n",
    "        # save initial weights\n",
    "        self.save_initial_weights()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Generator model\n",
    "    \n",
    "    def g_identifier(self):\n",
    "        return self.identifier if self.identifier is not None else ''\n",
    "    \n",
    "    def c_generator_model(self, extra_depth=0):\n",
    "        '''\n",
    "        CONDITIONAL version of G\n",
    "        '''\n",
    "        ACTIVATION = keras.layers.Activation(\"tanh\")\n",
    "        \n",
    "        # Prepare noise input\n",
    "        self.input_shapes.append((self.noise_dim,))\n",
    "        input_z = keras.layers.Input((self.noise_dim,))\n",
    "        dense_z_1 = keras.layers.Dense(1024)(input_z)\n",
    "        act_z_1 = ACTIVATION(dense_z_1)\n",
    "        dense_z_2 = keras.layers.Dense(128 * 7 * 7)(act_z_1)\n",
    "        bn_z_1 = keras.layers.BatchNormalization()(dense_z_2)\n",
    "        reshape_z = keras.layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,))(bn_z_1)\n",
    "\n",
    "        # Prepare Conditional (label) input\n",
    "        self.input_shapes.append((num_classes,))\n",
    "        input_c = keras.layers.Input((num_classes,))\n",
    "        dense_c_1 = keras.layers.Dense(1024)(input_c)\n",
    "        act_c_1 = ACTIVATION(dense_c_1)\n",
    "        dense_c_2 = keras.layers.Dense(128 * 7 * 7)(act_c_1)\n",
    "        bn_c_1 = keras.layers.BatchNormalization()(dense_c_2)\n",
    "        reshape_c = keras.layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,))(bn_c_1)\n",
    "\n",
    "        # Combine input source\n",
    "        concat_z_c = keras.layers.Concatenate()([reshape_z, reshape_c])\n",
    "\n",
    "        # Image generation with the concatenated inputs\n",
    "        up_1 = keras.layers.UpSampling2D(size=(2, 2))(concat_z_c)\n",
    "        conv_1 = keras.layers.Conv2D(64, (5, 5), padding='same')(up_1)\n",
    "        for i in range(extra_depth):\n",
    "            conv_1 = keras.layers.Conv2D(64, (5, 5), padding='same')(conv_1)\n",
    "        act_1 = ACTIVATION(conv_1)\n",
    "        up_2 = keras.layers.UpSampling2D(size=(2, 2))(act_1)\n",
    "        #\n",
    "        drop_1 = keras.layers.Dropout(0.1)(up_2)\n",
    "        #\n",
    "        conv_2 = keras.layers.Conv2D(1, (5, 5), padding='same')(drop_1)\n",
    "        act_2 = keras.layers.Activation(\"tanh\")(conv_2)\n",
    "        model = keras.models.Model(inputs=[input_z, input_c], outputs=act_2)\n",
    "        model._name = \"{}g_model\".format(self.g_identifier())\n",
    "        return model\n",
    "    \n",
    "    def u_generator_model(self):\n",
    "        '''\n",
    "        NORMAL version of G\n",
    "        '''\n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        self.input_shapes.append((self.noise_dim,))\n",
    "        model.add(Dense(7*7*256, use_bias=False, input_shape=(self.noise_dim,)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Reshape((7, 7, 256)))\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "        model._name = \"{}g_model\".format(self.g_identifier())\n",
    "\n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Loss\n",
    "    \n",
    "    def loss(self, fake_discrimination, labels):\n",
    "        # we want the discriminator to be fooled by these fake images\n",
    "        cross_entropy = self.cat_cross_entropy(fake_discrimination, labels)\n",
    "        return cross_entropy\n",
    "    \n",
    "    def u_loss(self, fake_discrimination):\n",
    "        '''\n",
    "        Loss that measures how close the output is to having a single peak.\n",
    "        In other words we are measuring how certain the model thinks it is\n",
    "        correct, regardless of the answer\n",
    "        1. Performs a softmax -> onehot conversion (differentiable approx.)\n",
    "        2. Compare to the original output -- return this cat crossentropy\n",
    "        '''\n",
    "        fake_output = tf.identity(fake_discrimination)\n",
    "        \n",
    "        # 1.\n",
    "        my_power = self.softmax_power\n",
    "        for i in range(self.uncertain_loop_times):\n",
    "            fake_output = self.soft_onehot(fake_output)\n",
    "            \n",
    "        # 2.\n",
    "        return self.cat_cross_entropy(fake_output, fake_discrimination)\n",
    "        \n",
    "    def soft_onehot(self, softmax, my_power=8):\n",
    "        '''\n",
    "        Shown to not really work... vanishing gradients problem\n",
    "        '''\n",
    "        soft_extreme = softmax ** my_power\n",
    "        norm = tf.reduce_sum(soft_extreme, axis=-1)\n",
    "        almost_onehot = tf.math.divide(soft_extreme, tf.reshape(norm, (-1, 1)))\n",
    "        return almost_onehot\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        ckpt_save_folder = os.path.join('../gan_attack/checkpoints', 'it_{}'.format(iteration), self.ckpt_folder)\n",
    "        os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "        if self.ckpt is not None:\n",
    "            del self.ckpt\n",
    "        if self.manager is not None:\n",
    "            del self.manager\n",
    "\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "        \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved {}G checkpoint: {}\".format(self.g_identifier(), save_path))\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Load/save weights\n",
    "    \n",
    "    def save_initial_weights(self):\n",
    "        print('saving initial weights for {}G'.format(self.g_identifier()))\n",
    "        init_folder = os.path.join('../gan_attack/checkpoints', 'init', self.ckpt_folder)\n",
    "        os.makedirs(init_folder, exist_ok=True)\n",
    "        self.model.save_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def load_initial_weights(self):\n",
    "        print('loading initial weights for {}G'.format(self.g_identifier()))\n",
    "        init_folder = os.path.join('../gan_attack/checkpoints', 'init', self.ckpt_folder)\n",
    "        self.model.load_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        iteration_offset = 0\n",
    "        parent_folder = os.path.join('../gan_attack/checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                iteration_offset = largest_it\n",
    "                print('Restored {}G to latest checkpoint from {}'.format(self.g_identifier(), checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found for {}G, starting with a fresh network'.format(self.g_identifier()))\n",
    "        else:\n",
    "            if load_default:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    iteration_offset = it_restore\n",
    "                print('Restored {}G to checkpoint from {}'.format(self.g_identifier(), checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        return iteration_offset\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluation\n",
    "        \n",
    "    def generate(self, inputs, training=True):\n",
    "        generated_images = self.model(inputs, training=training)\n",
    "        return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cGAN:\n",
    "    '''\n",
    "    The cGAN. Trains the G and D.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, start_piece=None, middle_piece=None, end_piece=None):\n",
    "        self.is_conditional = True\n",
    "        self.extra_depth = gan_training_params['extra_depth']\n",
    "        self.noise_dim = gan_training_params['noise_dim']\n",
    "        self.batch_size = gan_training_params['batch_size']\n",
    "        self.batches_per_epoch = gan_training_params['batches_per_epoch']\n",
    "        self.d_trigger = gan_training_params['d_trigger']\n",
    "        self.g_trigger = gan_training_params['g_trigger']\n",
    "        self.early_stop_trigger = gan_training_params['early_stop_trigger']\n",
    "        self.stop_sensitivity = gan_training_params['stop_sensitivity']\n",
    "        self.g_nudge_trigger = gan_training_params['g_nudge_trigger']\n",
    "        self.g_nudge_probability = gan_training_params['g_nudge_probability']\n",
    "        self.minibatch_size = gan_training_params['minibatch_size']\n",
    "        self.d_restore_after_nudge = gan_training_params['d_restore_after_nudge']\n",
    "\n",
    "        # define the D and G models\n",
    "        self.g = G(gan_training_params, is_conditional=self.is_conditional, identifier='c_', extra_depth=self.extra_depth)\n",
    "        self.d = D(gan_training_params, start_piece, middle_piece, end_piece)\n",
    "            \n",
    "        # stack G on top of D\n",
    "        self.gd = self.stack_models()\n",
    "        print(self.gd.summary())\n",
    "        \n",
    "        # define losses\n",
    "        self.mse = tf.keras.losses.MeanSquaredError()\n",
    "        \n",
    "        # define metrics\n",
    "        self.gen_loss_train_avg = None\n",
    "        self.gen_acc_train_avg = None\n",
    "        self.disc_loss_train_avg = None\n",
    "        self.disc_loss_refine_avg = None\n",
    "        \n",
    "        # define plotting metrics\n",
    "        self.gen_loss_train_arr = []\n",
    "        self.gen_acc_train_arr = []\n",
    "        self.disc_loss_train_arr = []\n",
    "        self.disc_acc_test_arr = []\n",
    "        \n",
    "        # seed for image generation\n",
    "        num_examples_to_generate = 16\n",
    "        self.seed = tf.random.normal([num_examples_to_generate, self.noise_dim])\n",
    "        \n",
    "        # labels for image generation\n",
    "        label_pattern = [i % (num_classes) for i in range(num_examples_to_generate)]\n",
    "        self.eval_labels = tf.one_hot(label_pattern, num_classes, dtype=tf.dtypes.float32)\n",
    "        \n",
    "        # setup checkpointing\n",
    "        self.internal_iteration = None\n",
    "        self.iteration_offset = 0\n",
    "        self.save_ckpts = True\n",
    "        \n",
    "        # initialize d and g checkpoints\n",
    "        self.d.init_ckpt()\n",
    "        self.g.init_ckpt()\n",
    "        \n",
    "        # setup early stop metrics\n",
    "        self.early_stop = False\n",
    "        self.no_change_inc = 0\n",
    "        self.prev_g_acc = None\n",
    "        self.best_g_acc = None\n",
    "        self.nudge_flag = False\n",
    "        \n",
    "    def stack_models(self):\n",
    "        inputs = []\n",
    "        for input_shape in self.g.input_shapes:\n",
    "            inputs.append(keras.layers.Input(input_shape))\n",
    "        \n",
    "        outputG = self.g.model(inputs)\n",
    "        \n",
    "        # output of G needs to be converted from [-1, 1] to [0, 1] spectrum\n",
    "        outputG_converted = 0.5 * outputG + 0.5\n",
    "        \n",
    "        outputD = self.d.model(outputG_converted)\n",
    "        \n",
    "        model = keras.models.Model(inputs=inputs, outputs=outputD)\n",
    "        model._name = \"cgan_model\"\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Trainer\n",
    "        \n",
    "    def train(self, iteration, save_best=False):\n",
    "        # setup checkpointing\n",
    "        self.setup_ckpts(iteration)\n",
    "        \n",
    "        # freeze the ends of D\n",
    "        self.d.freeze_ends(True)\n",
    "        \n",
    "        # initialize the metrics each new epoch\n",
    "        if self.gen_acc_train_avg is not None:\n",
    "            del self.gen_acc_train_avg\n",
    "        if self.gen_loss_train_avg is not None:\n",
    "            del self.gen_loss_train_avg\n",
    "        if self.disc_loss_train_avg is not None:\n",
    "            del self.disc_loss_train_avg\n",
    "        \n",
    "        self.gen_loss_train_avg = tf.keras.metrics.Mean()\n",
    "        self.gen_acc_train_avg = tf.keras.metrics.Accuracy()\n",
    "        self.disc_loss_train_avg = tf.keras.metrics.Mean()\n",
    "        \n",
    "        pbar = notebook.tqdm(total=self.batches_per_epoch)\n",
    "        \n",
    "        for i in range(self.batches_per_epoch):\n",
    "            # nudge generator if nothing is happening:\n",
    "            if self.nudge():\n",
    "                if not self.nudge_flag:\n",
    "                    self.nudge_flag = True\n",
    "                    print(\"*** nudging ***\")\n",
    "                train_discriminator = True\n",
    "            else:\n",
    "                train_discriminator = (self.gen_acc_train_avg.result() >= self.d_trigger)\n",
    "            \n",
    "            # logic for training the generator\n",
    "            train_generator = (self.gen_acc_train_avg.result() < self.g_trigger)\n",
    "            \n",
    "            self.c_train_step(train_discriminator=train_discriminator, train_generator=train_generator)\n",
    "            pbar.update(1)\n",
    "            pbar.set_description('g_acc={:.2f}, g_loss={:.2f}, d_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                                     self.gen_loss_train_avg.result(),\n",
    "                                                                                     self.disc_loss_train_avg.result()))\n",
    "        \n",
    "        print('g_acc={:.2f}, g_loss={:.2f}, d_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                  self.gen_loss_train_avg.result(),\n",
    "                                                                  self.disc_loss_train_avg.result()))\n",
    "        \n",
    "        # reload from pre-nudge state\n",
    "        just_nudged = False\n",
    "        if self.nudge_flag:\n",
    "            just_nudged = True\n",
    "            if self.d_restore_after_nudge:\n",
    "                self.d.restore_middle(iteration)\n",
    "            self.nudge_flag = False\n",
    "        \n",
    "        # save checkpoints\n",
    "        # only checkpoint d if we are the cGAN\n",
    "        self.checkpoint_d()\n",
    "        if save_best:\n",
    "            if self.best_g_acc is None or self.gen_acc_train_avg.result() >= self.best_g_acc:\n",
    "                self.best_g_acc = self.gen_acc_train_avg.result()\n",
    "                self.checkpoint_g()\n",
    "        else:\n",
    "            self.checkpoint_g()\n",
    "            \n",
    "        # unfreeze the ends of D\n",
    "        self.d.freeze_ends(False)\n",
    "        \n",
    "        # check for early stop\n",
    "        self.early_stop_check()\n",
    "        \n",
    "        return just_nudged\n",
    "    \n",
    "    def c_train_step(self, train_discriminator, train_generator):\n",
    "        noise = tf.random.normal([self.batch_size, self.noise_dim])\n",
    "        random_classes = tf.random.uniform(shape=(self.batch_size, ), maxval=num_classes, dtype=tf.dtypes.int32)\n",
    "        labels = tf.one_hot(random_classes, num_classes, dtype=tf.dtypes.float32)\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            fake_discrimination = self.gd([noise, labels], training=train_generator)\n",
    "\n",
    "            gen_loss = self.g.loss(fake_discrimination, labels)\n",
    "            disc_loss = self.d.loss(fake_discrimination, labels)\n",
    "            \n",
    "            # evaluate accuracy and append acc and loss to arrays\n",
    "            self.gen_loss_train_avg(gen_loss)\n",
    "            self.gen_acc_train_avg(tf.argmax(labels, 1), tf.argmax(fake_discrimination, 1))\n",
    "            self.disc_loss_train_avg(disc_loss)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.g.model.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.d.middle_piece.trainable_variables)\n",
    "\n",
    "        if train_generator:\n",
    "            self.g.optimizer.apply_gradients(zip(gradients_of_generator, self.g.model.trainable_variables))\n",
    "        if train_discriminator:\n",
    "            self.d.optimizer.apply_gradients(zip(gradients_of_discriminator, self.d.middle_piece.trainable_variables))\n",
    "            \n",
    "    def nudge(self):\n",
    "        nudge = False\n",
    "        if self.no_change_inc >= self.g_nudge_trigger:\n",
    "            nudge = random.random() < self.g_nudge_probability\n",
    "        return nudge\n",
    "    \n",
    "    def refine_discriminator(self, input_datasets, blackbox_labelss, iteration):\n",
    "        assert len(input_datasets) == len(blackbox_labelss)\n",
    "        self.setup_ckpts(iteration)\n",
    "        \n",
    "        # freeze the ends of D\n",
    "        self.d.freeze_ends(True)\n",
    "        \n",
    "        disc_loss_refine_avg = tf.keras.metrics.Mean()\n",
    "        disc_acc_refine_avg = tf.keras.metrics.Accuracy()\n",
    "        optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        for k in range(len(input_datasets)):\n",
    "            # perform for every pair of data:\n",
    "            \n",
    "            input_dataset = input_datasets[k]        # (x, y) --> x: [[ client ... [(id, data) ...]]\n",
    "            blackbox_labels = blackbox_labelss[k]    #               [[ client ... [label_batch ...]]\n",
    "            \n",
    "            x, _ = input_dataset\n",
    "            \n",
    "            client_idxs = list(range(len(x)))\n",
    "            random.shuffle(client_idxs)\n",
    "\n",
    "            for client_idx in client_idxs:\n",
    "\n",
    "                # compare the two using MSE\n",
    "                client_x = x[client_idx]\n",
    "                x_batch = client_x[1]\n",
    "\n",
    "                # run through every minibatch:\n",
    "                j = 0\n",
    "                while(j < len(x_batch)):\n",
    "                    if self.minibatch_size is None:\n",
    "                        # use whole batch (no minibatch)\n",
    "                        x_minibatch = x_batch\n",
    "                        y_minibatch = blackbox_labels[client_idx]\n",
    "                    else:\n",
    "                        x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                        y_minibatch = blackbox_labels[client_idx][j:(j+self.minibatch_size)]\n",
    "                        \n",
    "                    with tf.GradientTape() as refine_tape:\n",
    "                        # predict each minibatch of the input_dataset and match it with its counterpart from the blackbox\n",
    "                        label_batch = self.d.discriminate(x_minibatch)\n",
    "                        refine_loss = self.mse(y_minibatch, label_batch)\n",
    "                        disc_loss_refine_avg(refine_loss)\n",
    "                        disc_acc_refine_avg(tf.argmax(y_minibatch, 1), tf.argmax(label_batch, 1))\n",
    "\n",
    "                    # train the discriminator, one client batch at a time\n",
    "                    gradients_of_discriminator = refine_tape.gradient(refine_loss, self.d.middle_piece.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients_of_discriminator, self.d.middle_piece.trainable_variables))\n",
    "\n",
    "                    if self.minibatch_size is None:\n",
    "                        break\n",
    "                    else:\n",
    "                        j += self.minibatch_size\n",
    "                        \n",
    "        # unfreeze the ends of D\n",
    "        self.d.freeze_ends(False)\n",
    "                    \n",
    "        return disc_loss_refine_avg.result(), disc_acc_refine_avg.result()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def setup_ckpts(self, iteration):\n",
    "        if self.save_ckpts:\n",
    "            # setup fresh checkpointer every new iteration\n",
    "            if self.internal_iteration is None or (self.internal_iteration != (iteration + self.iteration_offset)):\n",
    "                self.internal_iteration = iteration + self.iteration_offset\n",
    "                self.d.setup_ckpt(self.internal_iteration)\n",
    "                self.g.setup_ckpt(self.internal_iteration)\n",
    "    \n",
    "    def checkpoint_d(self):\n",
    "        if self.save_ckpts:\n",
    "            self.d.checkpoint()\n",
    "    \n",
    "    def checkpoint_g(self):\n",
    "        if self.save_ckpts:\n",
    "            self.g.checkpoint()\n",
    "            \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        self.d.restore_pieces(it_restore_ends=it_restore, it_restore_middle=it_restore, load_default=load_default)\n",
    "        self.iteration_offset = self.g.restore(it_restore, load_default)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Early stop\n",
    "        \n",
    "    def early_stop_check(self):\n",
    "        if self.prev_g_acc is not None:\n",
    "            perc_diff = abs(self.gen_acc_train_avg.result() - self.prev_g_acc) / self.prev_g_acc\n",
    "            #print(perc_diff, self.stop_sensitivity)\n",
    "            if perc_diff <= self.stop_sensitivity:\n",
    "                self.no_change_inc += 1\n",
    "                print('> no change inc: {}/{}'.format(self.no_change_inc, self.early_stop_trigger))\n",
    "                if self.no_change_inc >= self.early_stop_trigger:\n",
    "                    self.early_stop = True\n",
    "                    self.no_change_inc = 0\n",
    "            else:\n",
    "                self.no_change_inc = 0\n",
    "\n",
    "        self.prev_g_acc = self.gen_acc_train_avg.result()\n",
    "        \n",
    "    def reset_early_stop(self):\n",
    "        self.no_change_inc = 0\n",
    "        self.prev_g_acc = None\n",
    "        self.best_g_acc = None\n",
    "        self.nudge_flag = False\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "            \n",
    "    def generate_images(self, images=None, labels=None):\n",
    "        # Notice `training` is set to False.\n",
    "        # This is so all layers run in inference mode (batchnorm).\n",
    "        \n",
    "        if images is None:\n",
    "            images = self.g.generate([self.seed, self.eval_labels], training=False)\n",
    "            images = 0.5 * images + 0.5\n",
    "            labels = self.eval_labels\n",
    "        assert images.shape[0] >= 16\n",
    "        assert labels is not None\n",
    "        assert len(labels) == len(images)\n",
    "\n",
    "        categories = [self.g.g_identifier()+str(x) for x in list(range(10))]\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        for i in range(16):\n",
    "            ax = plt.subplot(4, 4, i+1)\n",
    "            if self.is_conditional:\n",
    "                ax.title.set_text(categories[np.argmax(labels[i])])\n",
    "            plt.imshow(images[i, :, :, 0] * 255.0, cmap='gray')\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def generate_dataset(self, batch_num, batch_size, verbose=False):\n",
    "        '''\n",
    "        Generates a list of batches (x_batch, y_batch) to pass into the black-box model\n",
    "        '''\n",
    "        x_batches = []\n",
    "        y_batches = []\n",
    "        for b in range(batch_num):\n",
    "            \n",
    "            # create a list of random ints\n",
    "            seed = tf.random.normal([batch_size, self.noise_dim])\n",
    "            gen_labels = np.random.randint(num_classes, size=batch_size)\n",
    "            y_batch = self.onehot_vals(gen_labels)\n",
    "            \n",
    "            predictions = self.g.generate([seed, y_batch], training=False)\n",
    "            x_batch = 0.5 * predictions + 0.5\n",
    "            \n",
    "            x_batches.append((None, x_batch)) # making into a tuple to match previous dataset scheme\n",
    "            y_batches.append((None, y_batch))\n",
    "            \n",
    "        if verbose:\n",
    "            self.generate_images(x_batches[0][1], y_batches[0][1])\n",
    "        return [x_batches, y_batches]\n",
    "    \n",
    "    def onehot_vals(self, a):\n",
    "        b = np.zeros((a.size, num_classes), dtype=np.float32)\n",
    "        b[np.arange(a.size), a] = 1\n",
    "        return b\n",
    "        \n",
    "    def evaluate_gan(self, dataset):\n",
    "        \n",
    "        if self.gen_acc_train_avg is not None:\n",
    "            print('G Train Acc:     {:.3f} | Loss: {:.3f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                self.gen_loss_train_avg.result()))\n",
    "            print('D Train Acc:     NaN   | Loss: {:.3f}'.format(self.disc_loss_train_avg.result()))\n",
    "        disc_acc_test = self.evaluate_discriminator(dataset)\n",
    "        \n",
    "        # define plotting metrics\n",
    "        self.gen_loss_train_arr.append(self.gen_loss_train_avg.result())\n",
    "        self.gen_acc_train_arr.append(self.gen_acc_train_avg.result())\n",
    "        self.disc_loss_train_arr.append(self.disc_loss_train_avg.result())\n",
    "        self.disc_acc_test_arr.append(disc_acc_test)\n",
    "        \n",
    "        return disc_acc_test\n",
    "        \n",
    "    def evaluate_discriminator(self, dataset, verbose=True):\n",
    "        \n",
    "        x, y = dataset\n",
    "        \n",
    "        acc_test_avg = tf.keras.metrics.Accuracy()\n",
    "        loss_test_avg = tf.keras.metrics.Mean()\n",
    "        for i in range(0, len(x), self.batch_size):\n",
    "            # get batch\n",
    "            x_batch = x[i:i+self.batch_size]\n",
    "            y_batch = y[i:i+self.batch_size]\n",
    "            \n",
    "            # evaluate\n",
    "            logits = self.d.discriminate(x_batch, training=False)\n",
    "            acc_test_avg(tf.argmax(y_batch, 1), tf.argmax(logits, 1))\n",
    "            loss_test_avg(self.d.entropy(y_batch, logits))\n",
    "            \n",
    "        if verbose:\n",
    "            print('D Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test_avg.result(), loss_test_avg.result()))\n",
    "            print()\n",
    "        \n",
    "        return acc_test_avg.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class uGAN:\n",
    "    '''\n",
    "    The uGAN. Trains the uG. uG can be either conditional or not conditional.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, is_conditional=True, start_piece=None, middle_piece=None, end_piece=None):\n",
    "        self.is_conditional = is_conditional\n",
    "        \n",
    "        self.extra_depth = gan_training_params['extra_depth']\n",
    "        self.noise_dim = gan_training_params['noise_dim']\n",
    "        self.batch_size = gan_training_params['batch_size']\n",
    "        self.batches_per_epoch = gan_training_params['batches_per_epoch']\n",
    "        self.early_stop_trigger = gan_training_params['early_stop_trigger']\n",
    "        self.stop_sensitivity = gan_training_params['stop_sensitivity']\n",
    "\n",
    "        # define the D and G models (D comes from cGAN)\n",
    "        self.g = G(gan_training_params, is_conditional=self.is_conditional, identifier='u_', extra_depth=self.extra_depth)\n",
    "        self.d = D(gan_training_params, start_piece, middle_piece, end_piece)\n",
    "            \n",
    "        # stack G on top of D\n",
    "        self.gd = self.stack_models()\n",
    "        print(self.gd.summary())\n",
    "        \n",
    "        # define metrics\n",
    "        self.gen_loss_train_avg = None\n",
    "        self.gen_acc_train_avg = None\n",
    "        \n",
    "        # define plotting metrics\n",
    "        self.gen_loss_train_arr = []\n",
    "        self.gen_acc_train_arr = []\n",
    "        \n",
    "        # seed for image generation\n",
    "        num_examples_to_generate = 16\n",
    "        self.seed = tf.random.normal([num_examples_to_generate, self.noise_dim])\n",
    "        \n",
    "        # labels for image generation\n",
    "        label_pattern = [i % (num_classes) for i in range(num_examples_to_generate)]\n",
    "        self.eval_labels = tf.one_hot(label_pattern, num_classes, dtype=tf.dtypes.float32)\n",
    "        \n",
    "        # setup checkpointing\n",
    "        self.internal_iteration = None\n",
    "        self.iteration_offset = 0\n",
    "        self.save_ckpts = True\n",
    "        \n",
    "        # initialize d and g checkpoints\n",
    "        self.g.init_ckpt()\n",
    "        \n",
    "        # setup early stop metrics\n",
    "        self.early_stop = False\n",
    "        self.no_change_inc = 0\n",
    "        self.prev_g_acc = None\n",
    "        self.best_g_acc = None\n",
    "        self.nudge_flag = False\n",
    "        \n",
    "    def stack_models(self):\n",
    "        inputs = []\n",
    "        for input_shape in self.g.input_shapes:\n",
    "            inputs.append(keras.layers.Input(input_shape))\n",
    "        \n",
    "        outputG = self.g.model(inputs)\n",
    "        \n",
    "        # output of G needs to be converted from [-1, 1] to [0, 1] spectrum\n",
    "        outputG_converted = 0.5 * outputG + 0.5\n",
    "        \n",
    "        outputD = self.d.model(outputG_converted)\n",
    "        \n",
    "        model = keras.models.Model(inputs=inputs, outputs=outputD)\n",
    "        model._name = \"ugan_model\"\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Trainer\n",
    "        \n",
    "    def train(self, iteration, save_best=False):\n",
    "        # setup checkpointing\n",
    "        self.setup_ckpts(iteration)\n",
    "        \n",
    "        # initialize the metrics each new epoch\n",
    "        if self.gen_acc_train_avg is not None:\n",
    "            del self.gen_acc_train_avg\n",
    "        if self.gen_loss_train_avg is not None:\n",
    "            del self.gen_loss_train_avg\n",
    "        \n",
    "        self.gen_loss_train_avg = tf.keras.metrics.Mean()\n",
    "        if self.is_conditional:\n",
    "            self.gen_acc_train_avg = tf.keras.metrics.Accuracy()\n",
    "        \n",
    "        pbar = notebook.tqdm(total=self.batches_per_epoch)\n",
    "        \n",
    "        for i in range(self.batches_per_epoch):\n",
    "            # logic for training the generator\n",
    "            train_generator = True\n",
    "            \n",
    "            if self.is_conditional:\n",
    "                self.c_train_step(train_generator=train_generator)\n",
    "                pbar.update(1)\n",
    "                pbar.set_description('g_acc={:.2f}, g_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                          self.gen_loss_train_avg.result()))\n",
    "            else:\n",
    "                self.u_train_step(train_generator=train_generator)\n",
    "                pbar.update(1)\n",
    "                pbar.set_description('g_loss={:.8f}'.format(self.gen_loss_train_avg.result()))\n",
    "        \n",
    "        if self.is_conditional:\n",
    "            print('g_acc={:.2f}, g_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                       self.gen_loss_train_avg.result()))\n",
    "        else:\n",
    "            print('g_loss={:.2f}'.format(self.gen_loss_train_avg.result()))\n",
    "        \n",
    "        # save checkpoints\n",
    "        if save_best:\n",
    "            if self.is_conditional:\n",
    "                if self.best_g_acc is None or self.gen_acc_train_avg.result() >= self.best_g_acc:\n",
    "                    self.best_g_acc = self.gen_acc_train_avg.result()\n",
    "                    self.checkpoint_g()\n",
    "            else:\n",
    "                # TODO: maybe make a best_ug_loss?\n",
    "                self.checkpoint_g()\n",
    "        else:\n",
    "            self.checkpoint_g()\n",
    "        \n",
    "        # check for early stop\n",
    "        self.early_stop_check()\n",
    "    \n",
    "    def c_train_step(self, train_generator):\n",
    "        noise = tf.random.normal([self.batch_size, self.noise_dim])\n",
    "        random_classes = tf.random.uniform(shape=(self.batch_size, ), maxval=num_classes, dtype=tf.dtypes.int32)\n",
    "        labels = tf.one_hot(random_classes, num_classes, dtype=tf.dtypes.float32)\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            fake_discrimination = self.gd([noise, labels], training=train_generator)\n",
    "\n",
    "            gen_loss = self.g.u_loss(fake_discrimination) + self.g.loss(fake_discrimination, labels)\n",
    "            \n",
    "            # evaluate accuracy and append acc and loss to arrays\n",
    "            self.gen_loss_train_avg(gen_loss)\n",
    "            self.gen_acc_train_avg(tf.argmax(labels, 1), tf.argmax(fake_discrimination, 1))\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.g.model.trainable_variables)\n",
    "\n",
    "        if train_generator:\n",
    "            self.g.optimizer.apply_gradients(zip(gradients_of_generator, self.g.model.trainable_variables))\n",
    "    \n",
    "    def u_train_step(self, train_generator):\n",
    "        '''\n",
    "        Train G, knowing we are trying to generate the most appropriate dataset to pass to BB\n",
    "        '''\n",
    "        noise = tf.random.normal([self.batch_size, self.noise_dim])\n",
    "        random_classes = tf.random.uniform(shape=(self.batch_size, ), maxval=num_classes, dtype=tf.dtypes.int32)\n",
    "\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            fake_discrimination = self.gd(noise, training=train_generator)\n",
    "\n",
    "            gen_loss = self.g.u_loss(fake_discrimination)\n",
    "            \n",
    "            # evaluate accuracy and append acc and loss to arrays\n",
    "            self.gen_loss_train_avg(gen_loss)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.g.model.trainable_variables)\n",
    "\n",
    "        if train_generator:\n",
    "            self.g.optimizer.apply_gradients(zip(gradients_of_generator, self.g.model.trainable_variables))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def setup_ckpts(self, iteration):\n",
    "        if self.save_ckpts:\n",
    "            # setup fresh checkpointer every new iteration\n",
    "            if self.internal_iteration is None or (self.internal_iteration != (iteration + self.iteration_offset)):\n",
    "                self.internal_iteration = iteration + self.iteration_offset\n",
    "                self.g.setup_ckpt(self.internal_iteration)\n",
    "    \n",
    "    def checkpoint_g(self):\n",
    "        if self.save_ckpts:\n",
    "            self.g.checkpoint()\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        self.iteration_offset = self.g.restore(it_restore, load_default)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Early stop\n",
    "        \n",
    "    def early_stop_check(self):\n",
    "        if self.is_conditional:\n",
    "            if self.prev_g_acc is not None:\n",
    "                perc_diff = abs(self.gen_acc_train_avg.result() - self.prev_g_acc) / self.prev_g_acc\n",
    "                #print(perc_diff, self.stop_sensitivity)\n",
    "                if perc_diff <= self.stop_sensitivity:\n",
    "                    self.no_change_inc += 1\n",
    "                    print('> no change inc: {}/{}'.format(self.no_change_inc, self.early_stop_trigger))\n",
    "                    if self.no_change_inc >= self.early_stop_trigger:\n",
    "                        self.early_stop = True\n",
    "                        self.no_change_inc = 0\n",
    "                else:\n",
    "                    self.no_change_inc = 0\n",
    "\n",
    "            self.prev_g_acc = self.gen_acc_train_avg.result()\n",
    "        else:\n",
    "            # TODO: maybe make a prev_ug_loss?\n",
    "            pass\n",
    "        \n",
    "    def reset_early_stop(self):\n",
    "        self.no_change_inc = 0\n",
    "        self.prev_g_acc = None\n",
    "        self.best_g_acc = None\n",
    "        self.nudge_flag = False\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "            \n",
    "    def generate_images(self, predictions=None, labels=None):\n",
    "        # Notice `training` is set to False.\n",
    "        # This is so all layers run in inference mode (batchnorm).\n",
    "        \n",
    "        if predictions is None:\n",
    "            predictions = self.g.generate([self.seed, self.eval_labels], training=False)\n",
    "            predictions = 0.5 * predictions + 0.5\n",
    "            labels = self.eval_labels\n",
    "        assert predictions.shape[0] >= 16\n",
    "        assert labels is not None\n",
    "        assert len(labels) == len(predictions)\n",
    "\n",
    "        if self.is_conditional:\n",
    "            categories = [self.g.g_identifier()+str(x) for x in list(range(10))]\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        for i in range(16):\n",
    "            ax = plt.subplot(4, 4, i+1)\n",
    "            if self.is_conditional:\n",
    "                ax.title.set_text(categories[np.argmax(labels[i])])\n",
    "            plt.imshow(predictions[i, :, :, 0] * 255.0, cmap='gray')\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def generate_dataset(self, batch_num, batch_size, verbose=False):\n",
    "        '''\n",
    "        Generates a list of batches (x_batch, y_batch) to pass into the black-box model\n",
    "        '''\n",
    "        x_batches = []\n",
    "        y_batches = []\n",
    "        for b in range(batch_num):\n",
    "            \n",
    "            # create a list of random ints\n",
    "            seed = tf.random.normal([batch_size, self.noise_dim])\n",
    "            gen_labels = np.random.randint(num_classes, size=batch_size)\n",
    "            y_batch = self.onehot_vals(gen_labels)\n",
    "            \n",
    "            if self.is_conditional:\n",
    "                predictions = self.g.generate([seed, y_batch], training=False)\n",
    "            else:\n",
    "                predictions = self.g.generate(seed, training=False)\n",
    "            x_batch = 0.5 * predictions + 0.5\n",
    "            \n",
    "            x_batches.append((None, x_batch)) # making into a tuple to match previous dataset scheme\n",
    "            y_batches.append((None, y_batch))\n",
    "            \n",
    "        if verbose:\n",
    "            self.generate_images(x_batches[0][1], y_batches[0][1])\n",
    "        return [x_batches, y_batches]\n",
    "    \n",
    "    def onehot_vals(self, a):\n",
    "        b = np.zeros((a.size, num_classes), dtype=np.float32)\n",
    "        b[np.arange(a.size), a] = 1\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGSM:\n",
    "    '''\n",
    "    The FGSM trainer. Generates better images to be used in the cGAN\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, fgsm_training_params, d):\n",
    "        \n",
    "        self.epsilon = fgsm_training_params['epsilon']\n",
    "        self.norm = fgsm_training_params['norm']\n",
    "        \n",
    "        # D must be the one we are using in the cGAN (because that's the D we are refining)\n",
    "        assert d is not None and type(d) is D\n",
    "        self.d = d\n",
    "        # self.d = D(fgsm_training_params, start_piece=d.start_piece, middle_piece=d.middle_piece, end_piece=d.end_piece)\n",
    "        \n",
    "        # define losses\n",
    "        self.cross_entropy = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Trainer\n",
    "    \n",
    "    def augment_dataset(self, input_datasets, blackbox_labelss, iteration):\n",
    "        assert len(input_datasets) == len(blackbox_labelss)\n",
    "        \n",
    "        # freeze the ends of D\n",
    "        self.d.freeze_ends(True)\n",
    "        \n",
    "        disc_loss_refine_avg = tf.keras.metrics.Mean()\n",
    "        disc_acc_refine_avg = tf.keras.metrics.Accuracy()\n",
    "        optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # Set the parameter epsilon = 0.5 for FGSM (Only alter the first 5 terms , X0~X4)\n",
    "        print (\"Fast Gradient Sign Method based on {} norm\".format(self.norm))\n",
    "        g_x_batches = []\n",
    "        g_y_batches = []\n",
    "        for k in notebook.tqdm(range(len(input_datasets))):\n",
    "            # perform for every pair of data:\n",
    "            \n",
    "            input_dataset = input_datasets[k]        # (x, y) --> x: [[ client ... [(id, data) ...]]\n",
    "            blackbox_labels = blackbox_labelss[k]    #               [[ client ... [label_batch ...]]\n",
    "            \n",
    "            x, y = input_dataset\n",
    "\n",
    "            # compare the two using MSE\n",
    "            for i, client_x in enumerate(x):\n",
    "                x_batch = x[i][1]\n",
    "                \n",
    "                g_x_batch = []\n",
    "                g_y_batch = []\n",
    "                # print(g_x_batch.shape, y[i][1].shape)\n",
    "                \n",
    "                for j in range(x_batch.shape[0]):\n",
    "                    \n",
    "                    x_ = tf.convert_to_tensor(np.expand_dims(x_batch[j], axis=0), np.float32)\n",
    "                    y_ = np.expand_dims(blackbox_labels[i][j], axis=0)\n",
    "                    \n",
    "                    with tf.GradientTape() as tape:\n",
    "                        tape.watch(x_)\n",
    "                        prediction = self.d.discriminate(x_)\n",
    "                        loss = self.cross_entropy(y_, prediction)\n",
    "                        \n",
    "                        disc_loss_refine_avg(loss)\n",
    "                        disc_acc_refine_avg(tf.argmax(y_, 1), tf.argmax(prediction, 1))\n",
    "                        \n",
    "                    # Get the gradients of the loss w.r.t to the input image.\n",
    "                    grad = tape.gradient(loss, x_)\n",
    "                    \n",
    "                    if self.norm == 'L1':\n",
    "                        grad = grad/(sum(abs(grad)))\n",
    "                    elif self.norm == 'Inf':\n",
    "                        grad = tf.sign(grad)\n",
    "                    else:\n",
    "                        raise Exception('L-norm not recognized')\n",
    "                        \n",
    "                    if not np.any(np.isnan(grad.numpy())):\n",
    "                        # Append the augmented image to the list (only if all elements in grad are not NaN)\n",
    "                        g_x_batch.append((np.expand_dims(x_batch[j], axis=0) + self.epsilon * grad.numpy())[0])\n",
    "                        g_y_batch.append(y[i][1][j])\n",
    "                    \n",
    "                if len(g_x_batch) > 0:\n",
    "                    g_x_batches.append((None, np.array(g_x_batch)))\n",
    "                    g_y_batches.append((None, np.array(g_y_batch)))\n",
    "            \n",
    "        # unfreeze the ends of D\n",
    "        self.d.freeze_ends(False)\n",
    "            \n",
    "        return (g_x_batches, g_y_batches)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        self.iteration_offset = self.d.restore(it_restore, load_default, use_blackbox=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemTrainer:\n",
    "    \n",
    "    def __init__(self, split_training_params, cgan_training_params, ugan_training_params, fgsm_training_params, attack_params):\n",
    "        # Datasets:\n",
    "        self.split_train_dataset = split_training_params['train_dataset']\n",
    "        assert self.split_train_dataset is not None\n",
    "        self.split_test_dataset = split_training_params['test_dataset']\n",
    "        assert self.split_test_dataset is not None\n",
    "        self.attack_train_dataset = attack_params['train_dataset']\n",
    "        assert self.attack_train_dataset is not None\n",
    "        \n",
    "        # Split Learning params:\n",
    "        self.split_epochs = split_training_params['epochs']\n",
    "        self.split_batch_limit = split_training_params['batch_limit']\n",
    "        \n",
    "        # GAN params:\n",
    "        self.cgan_training_params = cgan_training_params\n",
    "        self.fgsm_training_params = fgsm_training_params\n",
    "        \n",
    "        self.cgan_epochs = cgan_training_params['epochs']\n",
    "        self.use_blackbox= cgan_training_params['use_blackbox']\n",
    "        self.d_reset_percentage = cgan_training_params['d_reset_percentage']\n",
    "        self.d_priming_epoch_limit = cgan_training_params['d_priming_epoch_limit']\n",
    "        self.d_refine_epoch_limit = cgan_training_params['d_refine_epoch_limit']\n",
    "        self.save_best_cg = cgan_training_params['save_best_g']\n",
    "        self.reset_c_g_every_it = cgan_training_params['reset_g_every_it']\n",
    "        self.counter_nudge = cgan_training_params['counter_nudge']\n",
    "        \n",
    "        # Attack params:\n",
    "        self.prime_first_iteration = attack_params['prime_first_iteration']\n",
    "        self.prime_exit_trigger = attack_params['prime_exit_trigger']\n",
    "        self.prime_cgan_by_ckpt = attack_params['prime_cgan_by_ckpt']\n",
    "        self.refine_exit_trigger = attack_params['refine_exit_trigger']\n",
    "        self.prime_trigger = attack_params['prime_trigger']\n",
    "        self.prime_by_ckpt = attack_params['prime_by_ckpt']\n",
    "        self.attack_trigger = attack_params['attack_trigger']\n",
    "        self.attack_classes = attack_params['attack_classes']\n",
    "        self.d_refinement_batch_num = attack_params['d_refinement_batch_num']\n",
    "        self.d_refinement_batch_size = attack_params['d_refinement_batch_size']\n",
    "        self.train_bb_every_n_its = attack_params['train_bb_every_n_its']\n",
    "        self.cgan_query_every_n_its = attack_params['cgan_query_every_n_its']\n",
    "        self.accumulate_g_queries = attack_params['accumulate_g_queries']\n",
    "        self.flush_g_queries_every_bb_train = attack_params['flush_g_queries_every_bb_train']\n",
    "        self.refine_using_fgsm = attack_params['refine_using_fgsm']\n",
    "        self.reset_g_every_bb_train = attack_params['reset_g_every_bb_train']\n",
    "        \n",
    "        self.ugan_training_params = ugan_training_params\n",
    "        self.ugan_epochs = ugan_training_params['epochs']\n",
    "        self.ugan_is_conditional = ugan_training_params['is_conditional']\n",
    "        self.reset_u_g_every_it = ugan_training_params['reset_g_every_it']\n",
    "        self.refine_using_ugan = attack_params['refine_using_ugan']\n",
    "        \n",
    "        # create the Split Learning Trainer\n",
    "        self.split = SplitLearning(split_training_params)\n",
    "        \n",
    "        # create the cGAN Trainer\n",
    "        if not self.use_blackbox:\n",
    "            # treat the Split Learning NN as a Black-box\n",
    "            self.cgan = cGAN(cgan_training_params, start_piece=self.split.start_piece, end_piece=self.split.end_piece)\n",
    "        else:\n",
    "            # use the Split Learning NN as the GAN's Discriminator as an easy check:\n",
    "            self.cgan = cGAN(cgan_training_params, start_piece=self.split.start_piece, middle_piece=self.split.middle_piece,\n",
    "                             end_piece=self.split.end_piece)\n",
    "            \n",
    "        if self.refine_using_fgsm:\n",
    "            self.fgsm = FGSM(fgsm_training_params, self.cgan.d)\n",
    "        else:\n",
    "            self.fgsm = None\n",
    "            \n",
    "        # create uGAN Trainer, depend on cGAN's D\n",
    "        if self.refine_using_ugan:\n",
    "            # when trained, will use u_loss instead of loss\n",
    "            self.ugan = uGAN(ugan_training_params, is_conditional=self.ugan_is_conditional, start_piece=self.cgan.d.start_piece, \n",
    "                             middle_piece=self.cgan.d.middle_piece, end_piece=self.cgan.d.end_piece)\n",
    "            \n",
    "        # create metric accumulaters\n",
    "        self.g_acc = [None]\n",
    "        self.bb_acc = [None]\n",
    "        self.d_acc = []\n",
    "        self.bb_ong_acc = [None]\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Training\n",
    "    \n",
    "    def rand_bin_array(self, K, N):\n",
    "        arr = np.zeros(N)\n",
    "        arr[..., :K]  = 1\n",
    "        np.random.shuffle(arr)\n",
    "        return arr\n",
    "        \n",
    "    def train_system(self):\n",
    "        '''\n",
    "        Train the entire system, updating D while performing Split Learning, and train GAN until ready for attack\n",
    "        '''\n",
    "        \n",
    "        iteration = 0\n",
    "        previous_g_datasets = [] # [g_dataset ...] \n",
    "        while(True):\n",
    "            self.save_metrics()\n",
    "            \n",
    "            # Increment the iteration count:\n",
    "            iteration += 1\n",
    "            print('*'*40)\n",
    "            print('Iteration {}'.format(iteration))\n",
    "            print()\n",
    "        \n",
    "            # Prime the Black-box and D models (normal client, normal training):\n",
    "            d_acc = self.cgan.evaluate_discriminator(self.split_test_dataset, verbose=True)\n",
    "            if d_acc < self.prime_trigger or (self.prime_first_iteration and iteration == 1):\n",
    "                if self.prime_by_ckpt:\n",
    "                    # prime BB and D by loading in their default checkpoints\n",
    "                    self.split.restore(load_default=True)\n",
    "                    self.cgan.d.restore_pieces(load_default=True)\n",
    "                    \n",
    "                    print('o'*40)\n",
    "                    print('SKIPPED STEPS 1 & 2: Primed by checkpoint')\n",
    "                    print('o'*40)\n",
    "                    print()\n",
    "                else:\n",
    "                    ########################################################################\n",
    "                    # Step 1: \"Prime\" the Split Learning model if the model is not trained enough:\n",
    "                    print('~'*40)\n",
    "                    print('Step 1: Priming Split Learning')\n",
    "                    for e in notebook.tqdm(range(self.split_epochs)):\n",
    "                        print('-'*20)\n",
    "                        print('Epoch {}/{}'.format(e+1, self.split_epochs))\n",
    "                        # the attacker is pretending to be a normal client:\n",
    "                        self.split.train([self.split_train_dataset, self.attack_train_dataset], iteration, \n",
    "                                         batch_limit=self.split_batch_limit)\n",
    "                        self.split.evaluate(self.split_test_dataset)\n",
    "\n",
    "                    ########################################################################\n",
    "                    # Step 2: \"Prime\" D:\n",
    "                    print('~'*40)\n",
    "                    print('Step 2: Priming D')\n",
    "\n",
    "                    blackbox_labels = self.split.predict(self.attack_train_dataset)\n",
    "\n",
    "                    pbar = notebook.tqdm(total=self.d_priming_epoch_limit)\n",
    "                    d_prime_acc = None\n",
    "                    prime_inc = 0\n",
    "                    while (d_prime_acc is None or d_prime_acc < self.prime_exit_trigger) and prime_inc < self.d_priming_epoch_limit:\n",
    "                        d_refine_loss, d_prime_acc = self.cgan.refine_discriminator([self.attack_train_dataset], \n",
    "                                                                                    [blackbox_labels],\n",
    "                                                                                    iteration)\n",
    "                        pbar.set_description('d_prime_acc: {:.3f}'.format(d_prime_acc))\n",
    "                        pbar.update(1)\n",
    "                        prime_inc += 1\n",
    "                    pbar.close()\n",
    "                    \n",
    "                    # save checkpoints\n",
    "                    self.cgan.checkpoint_d()\n",
    "                    print('d_prime_acc: {:.3f}'.format(d_prime_acc))\n",
    "\n",
    "                # do not proceed if D is not close enough to the Split Learning model:\n",
    "                d_acc = self.cgan.evaluate_discriminator(self.split_test_dataset, verbose=True)\n",
    "                # Accumulate D Accuracy (starts at it 0)\n",
    "                self.d_acc.append(d_acc.numpy())\n",
    "                if d_acc < self.prime_trigger:\n",
    "                    # D is not trained enough, we will train the Black-box model more and then prime D again\n",
    "                    self.cgan.d.load_initial_weights()\n",
    "                    continue\n",
    "            else:\n",
    "                print('x'*40)\n",
    "                print('SKIPPED STEPS 1 & 2')\n",
    "                print('x'*40)\n",
    "                print()\n",
    "                \n",
    "                # Accumulate D Accuracy\n",
    "                self.d_acc.append(d_acc.numpy())\n",
    "\n",
    "            ################################################################################\n",
    "            # Step 3: Train GAN(s) on D:\n",
    "            if (iteration-1) % self.cgan_query_every_n_its == 0:\n",
    "                if (iteration-1 == 0) and self.prime_cgan_by_ckpt:\n",
    "                    self.cgan.restore(load_default=True)\n",
    "                    print('o'*40)\n",
    "                    print('SKIPPED STEP 3: Primed by checkpoint')\n",
    "                    print('o'*40)\n",
    "                    print()\n",
    "                else:\n",
    "                    if self.refine_using_ugan:\n",
    "                        print('~'*40)\n",
    "                        print('Step 3.1: Training uG')\n",
    "                        print(' - performed until uG converges with the current D')\n",
    "                        self.ugan.reset_early_stop()\n",
    "                        for e in notebook.tqdm(range(self.ugan_epochs)):\n",
    "                            print('-'*20)\n",
    "                            print('Epoch {}/{}'.format(e+1, self.ugan_epochs))\n",
    "                            self.ugan.train(iteration, save_best=False)\n",
    "                            self.ugan.generate_images()\n",
    "\n",
    "                            if self.get_early_stop_check(self.ugan):\n",
    "                                print('** Early stop! **')\n",
    "                                print()\n",
    "                                break\n",
    "                                \n",
    "                    print('~'*40)\n",
    "                    print('Step 3.2: Training cG')\n",
    "                    print(' - performed until cG converges with the current D')\n",
    "                    self.cgan.reset_early_stop()\n",
    "                    for e in notebook.tqdm(range(self.cgan_epochs)):\n",
    "                        print('-'*20)\n",
    "                        print('Epoch {}/{}'.format(e+1, self.cgan_epochs))\n",
    "                        just_nudged = self.cgan.train(iteration, save_best=self.save_best_cg)\n",
    "                        self.cgan.generate_images()\n",
    "                        \n",
    "                        stop_early = self.get_early_stop_check(self.cgan)\n",
    "                        if stop_early or e == self.cgan_epochs - 1:\n",
    "                            if just_nudged and self.counter_nudge:\n",
    "                                print('** Extra training to counter nudge **')\n",
    "                                self.cgan.train(iteration, save_best=self.save_best_cg)\n",
    "\n",
    "                        if stop_early:\n",
    "                            print('** Early stop! **')\n",
    "                            print()\n",
    "                            break\n",
    "                            \n",
    "                    # Accumulate G Accuracy\n",
    "                    self.g_acc.append(self.cgan.gen_acc_train_avg.result().numpy())\n",
    "\n",
    "                    # reload G with the best weights we found during training:\n",
    "                    if self.save_best_cg:\n",
    "                        self.cgan.g.restore(it_restore=iteration)\n",
    "                        self.cgan.generate_images()\n",
    "            else:\n",
    "                print('x'*40)\n",
    "                print('SKIPPED STEP 3')\n",
    "                print('x'*40)\n",
    "                print()\n",
    "                \n",
    "                # Accumulate G Accuracy\n",
    "                self.g_acc.append(None)\n",
    "                    \n",
    "            ################################################################################\n",
    "            # Step 4: Train Split Learning, but now add images from G\n",
    "            print('~'*40)\n",
    "            print('Step 4: Training Split Learning (and gathering Black-box labels)')\n",
    "            \n",
    "            if self.refine_using_ugan:\n",
    "                # the attacker weaves their images into the Black-box training step:\n",
    "                ug_dataset = self.ugan.generate_dataset(batch_num=self.d_refinement_batch_num,\n",
    "                                                        batch_size=self.d_refinement_batch_size, verbose=True)\n",
    "                g_dataset = ug_dataset\n",
    "\n",
    "                if (iteration-1) % self.cgan_query_every_n_its == 0:\n",
    "                    cg_dataset = self.cgan.generate_dataset(batch_num=self.d_refinement_batch_num,\n",
    "                                                            batch_size=self.d_refinement_batch_size, verbose=True)\n",
    "                    # append the two g_datasets together\n",
    "                    g_dataset[0] = g_dataset[0] + cg_dataset[0]\n",
    "                    g_dataset[1] = g_dataset[1] + cg_dataset[1]\n",
    "            else:\n",
    "                # the attacker weaves their images into the Black-box training step:\n",
    "                if (iteration-1) % self.cgan_query_every_n_its == 0:\n",
    "                    g_dataset = self.cgan.generate_dataset(batch_num=self.d_refinement_batch_num,\n",
    "                                                           batch_size=self.d_refinement_batch_size, verbose=True)\n",
    "                else:\n",
    "                    g_dataset = None\n",
    "                \n",
    "            # ** append all previous g_datasets into one\n",
    "            if self.accumulate_g_queries:\n",
    "                # append the previous g_dataset:\n",
    "                if g_dataset is not None:\n",
    "                    previous_g_datasets.append(g_dataset)\n",
    "                \n",
    "                for prev_d, prev_dataset in enumerate(previous_g_datasets):\n",
    "                    if prev_d == 0:\n",
    "                        g_dataset = deepcopy(prev_dataset)\n",
    "                    else:\n",
    "                        g_dataset[0] = g_dataset[0] + prev_dataset[0]\n",
    "                        g_dataset[1] = g_dataset[1] + prev_dataset[1]\n",
    "                \n",
    "            print('{} datasets gathered\\n'.format(len(previous_g_datasets)))\n",
    "            \n",
    "            # generate a mask, where '1' represents samples the server will interfere with, and '0' represents samples\n",
    "            # the server will leave alone\n",
    "            interfere_mask = self.rand_bin_array(K=int(mitigation_params['percent_to_drop']*self.d_refinement_batch_size),\n",
    "                                                 N=(1, self.d_refinement_batch_num, 1, self.d_refinement_batch_size))\n",
    "            print(np.sum(interfere_mask[interfere_mask == 1]) / interfere_mask.size)\n",
    "            \n",
    "            if iteration % self.train_bb_every_n_its == 0:\n",
    "                queried_dataset = self.split.train([self.split_train_dataset, self.attack_train_dataset], iteration, \n",
    "                                                   g_dataset=g_dataset, mask=interfere_mask)\n",
    "                \n",
    "                # Accumulate the BB Accuracy \n",
    "                bb_acc = self.split.acc_train_avg.result()\n",
    "                self.bb_acc.append(bb_acc.numpy())\n",
    "                \n",
    "                if self.flush_g_queries_every_bb_train:\n",
    "                    previous_g_datasets = []\n",
    "                if self.reset_g_every_bb_train:\n",
    "                    self.cgan.g.load_initial_weights()\n",
    "            else:\n",
    "                # do not train bb - only get the queried labels\n",
    "                print('only querying this iteration')\n",
    "                self.bb_acc.append(None)\n",
    "                queried_dataset = self.split.train(datasets=[], iteration=iteration, g_dataset=g_dataset, mask=interfere_mask)\n",
    "            raise Exception('!')\n",
    "            \n",
    "            # do not proceed if D is not close enough to the Split Learning model:\n",
    "            d_acc = self.cgan.evaluate_discriminator(self.split_test_dataset, verbose=False)\n",
    "            if d_acc < self.attack_trigger:\n",
    "                ###########################################################################\n",
    "                # Step 5: Refine D using the blackbox_labels we gathered and the dataset that we have available to us\n",
    "                print('~'*40)\n",
    "                print('Step 5.1: Gathering queries')\n",
    "                \n",
    "                # blackbox labels from our original dataset, \"stored\" when performing Step 4\n",
    "                blackbox_labels = self.split.predict(self.attack_train_dataset)\n",
    "                \n",
    "                # REDO g_dataset IN THE ORDER of what was queried\n",
    "                g_dataset = ([(None, x[0]) for x in queried_dataset], [(None, x[1]) for x in queried_dataset])\n",
    "                queried_labels = [x[2] for x in queried_dataset]\n",
    "\n",
    "                datasets = [self.attack_train_dataset] + [g_dataset]\n",
    "                labels = [blackbox_labels] + [queried_labels]\n",
    "                \n",
    "                ###########################\n",
    "                # FGSM\n",
    "                \n",
    "                if self.fgsm is not None:\n",
    "                    augmented_dataset = self.fgsm.augment_dataset(datasets, labels, iteration)\n",
    "                    \n",
    "                    # query using the augmented set:\n",
    "                    print('~'*40)\n",
    "                    print('Step 5.2: Gathering Blackbox labels for the augmented images')\n",
    "                    aug_sample_x = augmented_dataset[0][-1][1][0:16]\n",
    "                    aug_sample_y = augmented_dataset[1][-1][1][0:16]\n",
    "                    self.cgan.generate_images(aug_sample_x, aug_sample_y)\n",
    "\n",
    "                    queried_augmented_datasets = self.split.train(datasets=[], iteration=iteration, g_dataset=augmented_dataset)\n",
    "                    # REDO g_dataset IN THE ORDER of what was queried\n",
    "                    augmented_dataset = ([(None, x[0]) for x in queried_augmented_datasets], \n",
    "                                         [(None, x[1]) for x in queried_augmented_datasets])\n",
    "                    augmented_labels = [x[2] for x in queried_augmented_datasets]\n",
    "\n",
    "                    # add the original samples to the augmented dataset:\n",
    "                    datasets = [augmented_dataset] + datasets\n",
    "                    labels = [augmented_labels] + labels\n",
    "                else:\n",
    "                    assert self.refine_using_fgsm is False\n",
    "                \n",
    "                ###########################\n",
    "                \n",
    "                print('~'*40)\n",
    "                print('Step 5.3: Refining D')\n",
    "                pbar = notebook.tqdm(total=self.d_refine_epoch_limit)\n",
    "                d_refine_acc = None\n",
    "                refine_inc = 0\n",
    "                while (d_refine_acc is None or d_refine_acc < self.refine_exit_trigger) and refine_inc < self.d_refine_epoch_limit:\n",
    "                    d_refine_loss, d_refine_acc = self.cgan.refine_discriminator(datasets, labels, iteration)\n",
    "                    pbar.set_description('d_refine_acc: {:.3f}'.format(d_refine_acc))\n",
    "                    pbar.update(1)\n",
    "                    refine_inc += 1\n",
    "                pbar.close()\n",
    "                print('d_refine_acc: {:.3f}'.format(d_refine_acc))\n",
    "                \n",
    "                # gather statistics on how well G is able to trick BB:\n",
    "                print()\n",
    "                print('Split accuracy on G dataset:')\n",
    "                dset = self.cgan.generate_dataset(batch_num=self.d_refinement_batch_num,\n",
    "                                                  batch_size=self.d_refinement_batch_size, verbose=False)\n",
    "                bb_ong_acc = self.split.evaluate((dset[0][-1][1], dset[1][-1][1]))\n",
    "                self.bb_ong_acc.append(bb_ong_acc.numpy())\n",
    "                print()\n",
    "            \n",
    "                # do not proceed if D is not close enough to the Split Learning model:\n",
    "                d_acc = self.cgan.evaluate_discriminator(self.split_test_dataset, verbose=True)\n",
    "                if d_acc < self.attack_trigger:\n",
    "                    # D is not trained enough, we will train the Black-box model more and continue refining D\n",
    "                    if self.reset_c_g_every_it:\n",
    "                        self.cgan.g.load_initial_weights()\n",
    "                        \n",
    "                    if self.reset_u_g_every_it and self.refine_using_ugan:\n",
    "                        self.ugan.g.load_initial_weights()\n",
    "                    continue\n",
    "            else:\n",
    "                print('x'*40)\n",
    "                print('SKIPPED STEP 5')\n",
    "                print('x'*40)\n",
    "                print()\n",
    "            continue\n",
    "                \n",
    "            print('All done!')\n",
    "            break\n",
    "    \n",
    "    def get_early_stop_check(self, gan):\n",
    "        '''\n",
    "        Check if any models have triggered an early stop in their training\n",
    "        '''\n",
    "        early_stop = copy(gan.early_stop)\n",
    "        gan.early_stop = False\n",
    "        return early_stop\n",
    "    \n",
    "    def save_metrics(self):\n",
    "        '''\n",
    "        Save the accuracies to pickle files for later. Update new versions each iteration\n",
    "        '''\n",
    "        metric_save_folder = os.path.join('../gan_attack/checkpoints', 'metrics')\n",
    "        os.makedirs(metric_save_folder, exist_ok=True)\n",
    "        \n",
    "        g_acc_file = os.path.join(metric_save_folder, 'g_acc.pkl')\n",
    "        with open(g_acc_file, 'wb') as f:\n",
    "            pickle.dump(self.g_acc, f)\n",
    "            print('saved g_acc metric:', self.g_acc)\n",
    "        \n",
    "        bb_acc_file = os.path.join(metric_save_folder, 'bb_acc.pkl')\n",
    "        with open(bb_acc_file, 'wb') as f:\n",
    "            pickle.dump(self.bb_acc, f)\n",
    "            print('saved bb_acc metric:', self.bb_acc)\n",
    "        \n",
    "        d_acc_file = os.path.join(metric_save_folder, 'd_acc.pkl')\n",
    "        with open(d_acc_file, 'wb') as f:\n",
    "            pickle.dump(self.d_acc, f)\n",
    "            print('saved d_acc metric:', self.d_acc)\n",
    "        \n",
    "        bb_ong_acc_file = os.path.join(metric_save_folder, 'bb_ong_acc.pkl')\n",
    "        with open(bb_ong_acc_file, 'wb') as f:\n",
    "            pickle.dump(self.bb_ong_acc, f)\n",
    "            print('saved bb_ong_acc metric:', self.bb_ong_acc)\n",
    "        \n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "                \n",
    "    def plot_gan_training(self):\n",
    "        gen_loss_train_arr = self.cgan.gen_loss_train_arr\n",
    "        gen_acc_train_arr = self.cgan.gen_acc_train_arr\n",
    "        disc_loss_train_arr = self.cgan.disc_loss_train_arr\n",
    "        disc_acc_test_arr = self.cgan.disc_acc_test_arr\n",
    "        \n",
    "        epochs = list(range(max([len(gen_loss_train_arr), len(gen_acc_train_arr), \n",
    "                                 len(disc_loss_train_arr), len(disc_acc_test_arr)])))\n",
    "        epochs = [e + 1 for e in epochs]\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Generator Loss during Training')\n",
    "        plt.plot(epochs, gen_loss_train_arr)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Generator Accuracy during Training')\n",
    "        plt.plot(epochs, gen_acc_train_arr)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Discriminator Loss during Training')\n",
    "        plt.plot(epochs, disc_loss_train_arr)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Discriminator Accuracy (Test) during Training')\n",
    "        plt.plot(epochs, disc_acc_test_arr)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_training_params:\n",
      "{'apply_gradients_after': 20,\n",
      " 'batch_limit': None,\n",
      " 'ckpt_folder': 'blackbox_checkpoint',\n",
      " 'end_id': 'split_end_model',\n",
      " 'epochs': 1,\n",
      " 'eval_batch_size': 5,\n",
      " 'full_id': 'split_model',\n",
      " 'middle_id': 'split_middle_model',\n",
      " 'minibatch_size': None,\n",
      " 'shuffle_clients': True,\n",
      " 'start_id': 'split_start_model'}\n",
      "\n",
      "cgan_training_params:\n",
      "{'batch_size': 256,\n",
      " 'batches_per_epoch': 100,\n",
      " 'bb_ckpt_folder': 'blackbox_checkpoint',\n",
      " 'counter_nudge': True,\n",
      " 'd_ckpt_folder': 'discriminator_checkpoint',\n",
      " 'd_priming_epoch_limit': 1000,\n",
      " 'd_refine_epoch_limit': 200,\n",
      " 'd_reset_percentage': 1.0,\n",
      " 'd_restore_after_nudge': True,\n",
      " 'd_trigger': 0.98,\n",
      " 'early_stop_trigger': 5,\n",
      " 'end_id': 'd_end_model',\n",
      " 'epochs': 1,\n",
      " 'extra_depth': 3,\n",
      " 'full_id': 'd_model',\n",
      " 'g_ckpt_folder': 'generator_checkpoint',\n",
      " 'g_nudge_probability': 0.2,\n",
      " 'g_nudge_trigger': 3,\n",
      " 'g_trigger': 1.01,\n",
      " 'loop_times': 0,\n",
      " 'middle_id': 'd_middle_model',\n",
      " 'minibatch_size': None,\n",
      " 'noise_dim': 100,\n",
      " 'reset_g_every_it': False,\n",
      " 'save_best_g': False,\n",
      " 'softmax_power': 2,\n",
      " 'start_id': 'd_start_model',\n",
      " 'stop_sensitivity': 0.02,\n",
      " 'uncertain_loop_times': 1,\n",
      " 'use_bb_ends': True,\n",
      " 'use_blackbox': False}\n",
      "\n",
      "fgsm_training_params:\n",
      "{'epsilon': 0.9, 'norm': 'Inf'}\n",
      "\n",
      "attack_params:\n",
      "{'accumulate_g_queries': True,\n",
      " 'attack_classes': [1],\n",
      " 'attack_trigger': 0.8,\n",
      " 'attacker_clients': 5,\n",
      " 'attacks_per_epoch': 10,\n",
      " 'cgan_query_every_n_its': 1,\n",
      " 'd_refinement_batch_num': 3,\n",
      " 'd_refinement_batch_size': 100,\n",
      " 'flip_to': [7],\n",
      " 'flush_g_queries_every_bb_train': False,\n",
      " 'our_class': 0,\n",
      " 'prime_by_ckpt': True,\n",
      " 'prime_cgan_by_ckpt': False,\n",
      " 'prime_exit_trigger': 1.0,\n",
      " 'prime_first_iteration': True,\n",
      " 'prime_trigger': 0.0,\n",
      " 'refine_exit_trigger': 1.0,\n",
      " 'refine_using_fgsm': True,\n",
      " 'refine_using_ugan': False,\n",
      " 'reset_g_every_bb_train': False,\n",
      " 'train_bb_every_n_its': 2}\n"
     ]
    }
   ],
   "source": [
    "print('split_training_params:')\n",
    "pprint({i:split_training_params[i] for i in split_training_params if 'dataset' not in i})\n",
    "print()\n",
    "print('cgan_training_params:')\n",
    "pprint(cgan_training_params)\n",
    "print()\n",
    "print('fgsm_training_params:')\n",
    "pprint(fgsm_training_params)\n",
    "print()\n",
    "print('attack_params:')\n",
    "pprint({i:attack_params[i] for i in attack_params if 'dataset' not in i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"split_model_pub\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "=================================================================\n",
      "Total params: 79,002\n",
      "Trainable params: 79,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"split_model_sub\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 28, 28, 33)]      0         \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 712,700\n",
      "Trainable params: 712,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"split_model_combined\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_model_sub (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-16-74c6aee7d812>:105: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "saving initial weights for c_G\n",
      "Model: \"d_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "d_middle_model (Model)       (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "saving initial weights for D\n",
      "Model: \"cgan_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c_g_model (Model)               (None, 28, 28, 1)    13741121    input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 28, 28, 1)]  0           c_g_model[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 28, 28, 1)]  0           tf_op_layer_Mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "d_model (Model)                 (None, 10)           791702      tf_op_layer_AddV2[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 14,532,823\n",
      "Trainable params: 14,507,735\n",
      "Non-trainable params: 25,088\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "saved g_acc metric: [None]\n",
      "saved bb_acc metric: [None]\n",
      "saved d_acc metric: []\n",
      "saved bb_ong_acc metric: [None]\n",
      "****************************************\n",
      "Iteration 1\n",
      "\n",
      "D Test Accuracy: 0.104 | Loss: 2.303\n",
      "\n",
      "Restored latest checkpoint from ../gan_attack/checkpoints\\default\\blackbox_checkpoint\n",
      "Restoring D piece: ../gan_attack/checkpoints\\default\\d_start_model_checkpoint\n",
      "Restoring D piece: ../gan_attack/checkpoints\\default\\d_middle_model_checkpoint\n",
      "Restoring D piece: ../gan_attack/checkpoints\\default\\d_end_model_checkpoint\n",
      "oooooooooooooooooooooooooooooooooooooooo\n",
      "SKIPPED STEPS 1 & 2: Primed by checkpoint\n",
      "oooooooooooooooooooooooooooooooooooooooo\n",
      "\n",
      "D Test Accuracy: 0.348 | Loss: 2.102\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Step 3.2: Training cG\n",
      " - performed until cG converges with the current D\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57022d214cd4f1eafe53bc69f593bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87253e54b73c42bd940ab98820ee3c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_acc=0.70, g_loss=1.84, d_loss=1.07\n",
      "Saved D checkpoint: ../gan_attack/checkpoints\\it_1\\d_middle_model\\ckpt-1\n",
      "Saved D checkpoint: ..\\gan_attack\\checkpoints\\it_1\\d_start_model_checkpoint\\checkpoint\n",
      "Saved D checkpoint: ..\\gan_attack\\checkpoints\\it_1\\d_middle_model_checkpoint\\checkpoint\n",
      "Saved D checkpoint: ..\\gan_attack\\checkpoints\\it_1\\d_end_model_checkpoint\\checkpoint\n",
      "Saved c_G checkpoint: ../gan_attack/checkpoints\\it_1\\c_generator_checkpoint\\ckpt-1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Step 4: Training Split Learning (and gathering Black-box labels)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 datasets gathered\n",
      "\n",
      "0.1\n",
      "only querying this iteration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bc70d32a0143969d6008a0321899a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server logits: (100, 28, 28, 33)\n",
      "mask: (100, 28, 28, 33)\n",
      "(100, 28, 28, 33)\n",
      "server logits: (100, 28, 28, 33)\n",
      "mask: (100, 28, 28, 33)\n",
      "(100, 28, 28, 33)\n",
      "server logits: (100, 28, 28, 33)\n",
      "mask: (100, 28, 28, 33)\n",
      "(100, 28, 28, 33)\n",
      "\n",
      "train_acc=0.0000%\n",
      "accuracy of blackbox on G dataset: 58.0000%\n",
      "Saved checkpoint: ../gan_attack/checkpoints\\it_1\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: ..\\gan_attack\\checkpoints\\it_1\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: ..\\gan_attack\\checkpoints\\it_1\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: ..\\gan_attack\\checkpoints\\it_1\\split_end_model_checkpoint\\checkpoint\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ac22b5ed9147>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mslg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSystemTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_training_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcgan_training_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mugan_training_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfgsm_training_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattack_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mslg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_system\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-c26d6e6b9efe>\u001b[0m in \u001b[0;36mtrain_system\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbb_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m                 \u001b[0mqueried_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mg_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterfere_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[1;31m# do not proceed if D is not close enough to the Split Learning model:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: !"
     ]
    }
   ],
   "source": [
    "slg = SystemTrainer(split_training_params, cgan_training_params, ugan_training_params, fgsm_training_params, attack_params)\n",
    "slg.train_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
