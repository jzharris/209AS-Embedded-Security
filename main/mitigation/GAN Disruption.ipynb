{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack attempt, using a cGAN to train D and FGSM to refine D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF 2.1.0\n",
      "Keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution() # default for TF 2.0\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "from tensorflow import keras  # Import the tf version of keras.\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, \\\n",
    "                                    LeakyReLU, Conv2DTranspose, Reshape\n",
    "# import keras.backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "print('TF', tf.__version__)\n",
    "print('Keras', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import pickle\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "\n",
    "import os.path\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility \n",
    "# np.random.seed(0)\n",
    "# tf.random.set_seed(0)\n",
    "\n",
    "# Enlargen plots\n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EASY_MODE: if True, Split Learning NN is used as the Discriminator in the GAN. This is good for testing, but\n",
    "# bypasses the black-box paradigm! Use with caution\n",
    "EASY_MODE = True\n",
    "\n",
    "# Black-box params (optimized for MNIST)\n",
    "depth = 9\n",
    "filters = 33\n",
    "dense = 110\n",
    "num_classes = 10\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "target_rows, target_cols = 28, 28    # governed by the chosen model\n",
    "input_shape = (target_rows, target_cols, 1)\n",
    "\n",
    "# Attack params:\n",
    "attack_params = {\n",
    "    'our_class': 0,                             # the label indices that we want to preserve (and the data we own)\n",
    "    'attacker_clients': 5,                      # attacker controls X number of clients and their data\n",
    "    'attack_classes': [1],                      # the label(s) we want to poison\n",
    "    'flip_to': [7],                             # must be len(attack_classes) - flips the target label ('1') to new class ('7')\n",
    "    'prime_trigger': 0.00, #0.11                # the D test accuracy that, after which, we will move on from priming\n",
    "    'prime_first_iteration': True,              # whether to always prime on the first iteration\n",
    "    'prime_by_ckpt': True,                      # whether to prime manually (False) or by loading a checkpoint file (True)\n",
    "    'prime_cgan_by_ckpt': False,                # whether to load a pretrained cGAN from default/ or start from scratch (False)\n",
    "    'attack_trigger': 0.8,                      # the D accuracy (wrt Black-box) that, after which, we will commence an attack\n",
    "    'd_refinement_batch_num': 3,                # number of batches to refine D with: G -> BB <-> D\n",
    "    'd_refinement_batch_size': 100,             # number of attack images in each refinement batch: G -> BB <-> D\n",
    "    'train_dataset': None,                      # attack dataset - fixed in the beginning by choosing the attacking clients\n",
    "                                                # - this is the only data we have access to throughout the training process\n",
    "    'attacks_per_epoch': 10,                    # how many times to attack per epoch\n",
    "    'prime_exit_trigger': 1.0,                  # how good D has to be on the current blackbox model to exit priming\n",
    "    'refine_exit_trigger': 1.0,                 # how good D has to be after refinement*\n",
    "    'train_bb_every_n_its': 2,                  # only train the BB model while querying if (it % train_bb_every_n_its == 0)\n",
    "    'cgan_query_every_n_its': 1,                # only query BB with cGAN every N iterations\n",
    "    'refine_using_fgsm': True,                 # use FGSM to generate images to refine D with via uG -> BB -> D\n",
    "    'refine_using_ugan': False,                  # use the uGAN to generate images to refine D with via uG -> BB -> D\n",
    "    'accumulate_g_queries': True,               # whether to keep uGAN imgs every iteration, or to just use most recent (False)\n",
    "    'flush_g_queries_every_bb_train': False,    # whether to keep uGAN imgs after new BB is trained, or preserved them (False)\n",
    "    'reset_g_every_bb_train': False,            # whether to reset G back to init every time we train the BB model\n",
    "}\n",
    "\n",
    "# Split Learning training params:\n",
    "split_training_params = {\n",
    "    'minibatch_size': None,                     # number of samples to operate on at one time\n",
    "                                                #  - can vary to optimize computing requirements\n",
    "                                                #  - if None, will evaluate the client's whole batch regardless of its size\n",
    "    'apply_gradients_after': 20,                # after averaging the gradients from X clients, we will apply them to the model\n",
    "    'epochs': 1, #8                               # number of epochs to train for\n",
    "    'shuffle_clients': True,                    # whether to shuffle the clients during training\n",
    "    'eval_batch_size': 5, #256                    # batch size when evaluating test set (not split by clients),\n",
    "    'train_dataset': None,                      # training set - indexed by client\n",
    "    'test_dataset': None,                       # testing set - not batched\n",
    "    'batch_limit': None,                        # how many batches to train on, maximum, per epoch\n",
    "    'ckpt_folder': \"blackbox_checkpoint\",       # folder where to store the checkpoints\n",
    "    'start_id': 'split_start_model',            # start piece\n",
    "    'middle_id': 'split_middle_model',          # middle piece\n",
    "    'end_id': 'split_end_model',                # end piece\n",
    "    'full_id': 'split_model',                   # full model name\n",
    "}\n",
    "\n",
    "# cGAN training params:\n",
    "cgan_training_params = {\n",
    "    'minibatch_size': split_training_params['minibatch_size'],\n",
    "    'extra_depth': 3,                           # number of extra middle layers to put in the D of cGAN\n",
    "    'start_id': 'd_start_model',                # start piece\n",
    "    'middle_id': 'd_middle_model',              # middle piece\n",
    "    'end_id': 'd_end_model',                    # end piece\n",
    "    'full_id': 'd_model',                       # full model name\n",
    "    'use_bb_ends': True,                        # whether to share the weights of the start and end piece from the BB model\n",
    "    'batch_size': 256,                          # number of images to generate from cG at once\n",
    "    'noise_dim': 100,                           # noise vector for cG\n",
    "    'epochs': 1,                                # number of epochs to train cGAN\n",
    "    'use_blackbox': False,                      # if True, copies the Blackbox model into D (easy check)\n",
    "    'd_ckpt_folder': \"discriminator_checkpoint\",# folder where to store the d checkpoints\n",
    "    'bb_ckpt_folder': \"blackbox_checkpoint\",    # folder where the blackbox default ckpt is kept\n",
    "    'g_ckpt_folder': \"generator_checkpoint\",    # folder where to store the g checkpoints\n",
    "    'batches_per_epoch': 100,                   # number of batches to train on per epoch\n",
    "    'd_trigger': 0.98,                          # train D if g_accuracy is >= X\n",
    "    'g_trigger': 1.01,                          # train G if g_accuracy is < X\n",
    "    'loop_times': 0,                            # number of times to apply softmax -> onehot encoding\n",
    "    'uncertain_loop_times': 1,                  # number to use in the uncertain_loss used by D\n",
    "    'softmax_power': 2,                         # number used in softmax -> onehot encoding operation\n",
    "    'd_reset_percentage': 1.0,                  # reset D if the test d_accuracy dips below X% of the original accuracy\n",
    "    'early_stop_trigger': 5,                    # stop training early, if g_accuracy has not improved for X epochs\n",
    "    'stop_sensitivity': 0.02,                   # \"no improvement\" is when the g_accuracy has not moved more than X% from prev\n",
    "    'g_nudge_trigger': 3,                       # if \"no improvement\" for X epochs, turn on D for one turn\n",
    "    'g_nudge_probability': 0.20,                # probability of nudging this sample, if enabled\n",
    "    'counter_nudge': True,                      # whether to train an extra epoch when coming out of training right after nudge\n",
    "    'd_priming_epoch_limit': 1000,              # number of epochs to stop at for priming\n",
    "    'd_refine_epoch_limit': 200,                # number of epochs to stop at for refining D\n",
    "    'save_best_g': False,                       # whether to save the best G during training, or to just use the last one\n",
    "    'd_restore_after_nudge': True,              # whether to restore D back to normal at the end of the epoch if it was nudged\n",
    "    'reset_g_every_it': False,                  # whether to restore cG back to init at the end of Step 5 if not -> Step 6\n",
    "}\n",
    "\n",
    "# uGAN training params:\n",
    "ugan_training_params = {\n",
    "    'minibatch_size': split_training_params['minibatch_size'],\n",
    "    'extra_depth': 3,                           # number of extra middle layers to put in the D of cGAN\n",
    "    'start_id': 'x_start_model',                # start piece\n",
    "    'middle_id': 'x_middle_model',              # middle piece\n",
    "    'end_id': 'x_end_model',                    # end piece\n",
    "    'full_id': 'x_model',                       # full model name\n",
    "    'use_bb_ends': True,                        # whether to share the weights of the start and end piece from the BB model\n",
    "    'is_conditional': True,                     # whether to use the cGAN or uGAN architecture\n",
    "    'batch_size': 256,                          # number of images to generate from uG at once\n",
    "    'noise_dim': 100,                           # noise vector for uG\n",
    "    'epochs': 15,                               # number of epochs to train uGAN\n",
    "    'd_ckpt_folder': \"discriminator_checkpoint\",# folder where to store the d checkpoints\n",
    "    'bb_ckpt_folder': \"blackbox_checkpoint\",    # folder where the blackbox default ckpt is kept\n",
    "    'g_ckpt_folder': \"generator_checkpoint\",    # folder where to store the g checkpoints\n",
    "    'batches_per_epoch': 100,                   # number of batches to train on per epoch\n",
    "    'loop_times': 0,                            # number of times to apply softmax -> onehot encoding\n",
    "    'uncertain_loop_times': 1,                  # number to use in the uncertain_loss used by D\n",
    "    'softmax_power': 2,                         # number used in softmax -> onehot encoding operation\n",
    "    'early_stop_trigger': 5,                    # stop training early, if g_accuracy has not improved for X epochs\n",
    "    'stop_sensitivity': 0.02,                   # \"no improvement\" is when the g_accuracy has not moved more than X% from prev\n",
    "    'save_best_g': False,                       # whether to save the best G during training, or to just use the last one\n",
    "    'reset_g_every_it': True,                   # whether to restore uG back to init at the end of Step 5 if not -> Step 6\n",
    "}\n",
    "\n",
    "# FGSM training params:\n",
    "fgsm_training_params = {\n",
    "    'epsilon': 0.9,\n",
    "    'norm': 'Inf',                                 # can be L1, Inf\n",
    "}\n",
    "\n",
    "# Mitigation params:\n",
    "mitigation_params = {\n",
    "    'percent_to_drop': 0.1                      # what percentage of images in the batch should be replaced with noise\n",
    "}\n",
    "\n",
    "# Data parsing params\n",
    "clients_per_class = 100                         # number of clients per label. Each client only has access to one label\n",
    "                                                # - each unique class is divided into X number of subsets\n",
    "\n",
    "# Dataset params\n",
    "separated_folder = \"./separated_dataset\"\n",
    "os.makedirs(separated_folder, exist_ok=True)\n",
    "separated_train_path = os.path.join(separated_folder, \"train_separated.pkl\")\n",
    "separated_test_path = os.path.join(separated_folder, \"test_separated.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255    # range is [0, 1]\n",
    "x_test /= 255     # range is [0, 1]\n",
    "\n",
    "if target_rows != img_rows or target_cols != img_cols:\n",
    "    # resize x_train\n",
    "    x_train_resized = []\n",
    "    for x_ in x_train:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_train_resized.append(x_)\n",
    "    x_train = np.asarray(x_train_resized)\n",
    "\n",
    "    # resize x_test\n",
    "    x_test_resized = []\n",
    "    for x_ in x_test:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_test_resized.append(x_)\n",
    "    x_test = np.asarray(x_test_resized)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "y: (60000, 10) (10000, 10)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "print('X:', x_train.shape, x_test.shape)\n",
    "print('y:', y_train.shape, y_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "BUFFER_SIZE = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training seperation\n",
      "loaded testing seperation\n"
     ]
    }
   ],
   "source": [
    "# Separating the data by class\n",
    "if os.path.isfile(separated_train_path):\n",
    "    with open(separated_train_path, 'rb') as f:\n",
    "        x_train_dict, y_train_dict = pickle.load(f)\n",
    "        print('loaded training seperation')\n",
    "else:\n",
    "    x_train_dict = {}\n",
    "    y_train_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_train_dict[target_label] = []\n",
    "        y_train_dict[target_label] = []\n",
    "        for i, label in enumerate(y_train):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_train_dict[target_label].append(x_train[i])\n",
    "                y_train_dict[target_label].append(y_train[i])\n",
    "    \n",
    "    with open(separated_train_path, 'wb') as f:\n",
    "        pickle.dump([x_train_dict, y_train_dict], f)\n",
    "        print('saved training seperation')\n",
    "\n",
    "if os.path.isfile(separated_test_path):\n",
    "    with open(separated_test_path, 'rb') as f:\n",
    "        x_test_dict, y_test_dict = pickle.load(f)\n",
    "        print('loaded testing seperation')\n",
    "else:\n",
    "    x_test_dict = {}\n",
    "    y_test_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_test_dict[target_label] = []\n",
    "        y_test_dict[target_label] = []\n",
    "        for i, label in enumerate(y_test):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_test_dict[target_label].append(x_test[i])\n",
    "                y_test_dict[target_label].append(y_test[i])\n",
    "\n",
    "    with open(separated_test_path, 'wb') as f:\n",
    "        pickle.dump([x_test_dict, y_test_dict], f)\n",
    "        print('saved testing seperation')\n",
    "    \n",
    "# convert dicts to lists\n",
    "x_train_seperated = [np.array(x_train_dict[i]) for i in range(10)]\n",
    "y_train_seperated = [np.array(y_train_dict[i]) for i in range(10)]\n",
    "\n",
    "x_test_seperated = [np.array(x_test_dict[i]) for i in range(10)]\n",
    "y_test_seperated = [np.array(y_test_dict[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "plt.figure()\n",
    "plt.title('Data separation per class')\n",
    "plt.bar(x_train_dict.keys(), [len(v) for v in x_train_dict.values()], color='tab:blue')\n",
    "plt.bar(x_test_dict.keys(), [len(v) for v in x_test_dict.values()], color='orange', width=0.6)\n",
    "plt.legend(['x_train', 'x_test'], loc='center right', framealpha=1.0)\n",
    "plt.xlabel('class label')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data into batches for clients to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients per class:  99.6 ~= 100\n",
      "Total number of clients: 996\n",
      "Average batch size: 60.6\n"
     ]
    }
   ],
   "source": [
    "# Separate the data into a long list of batches, each batch representing a client training with that batch of images.\n",
    "# After each batch, a new client will have the opportunity to train their batch of images.\n",
    "# Batches are shuffled to simulate many clients training the model at once.\n",
    "\n",
    "client_counts = {}\n",
    "batch_sizes = {}\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "def ceil(a,b):\n",
    "    return -(-a//b)\n",
    "\n",
    "for class_idx in range(len(x_train_seperated)):\n",
    "    # Get batches from class data:\n",
    "    n_samples_per_class = len(x_train_seperated[class_idx])\n",
    "    samples_per_client = n_samples_per_class / clients_per_class\n",
    "    better_batch_size = int(math.ceil(samples_per_client))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(ceil(n_samples_per_class, better_batch_size)):\n",
    "        x_batches.append((class_idx, x_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        y_batches.append((class_idx, y_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        count += 1\n",
    "    client_counts[class_idx] = count\n",
    "    batch_sizes[class_idx] = better_batch_size\n",
    "        \n",
    "# double check that the clients_per_class is upheld per class\n",
    "# (blue bars should be uniform, orange should change according to class):\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('class label')\n",
    "ax1.set_ylabel('client count', color=color)\n",
    "plt.bar(client_counts.keys(), [v for v in client_counts.values()], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'orange'\n",
    "ax2.set_ylabel('batch size', color=color)  # we already handled the x-label with ax1\n",
    "plt.bar(batch_sizes.keys(), [v for v in batch_sizes.values()], color=color, width=0.6)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylim(0, np.mean([v for v in batch_sizes.values()])*2)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()\n",
    "\n",
    "print('Clients per class:  {} ~= {}'.format(np.mean([v for v in client_counts.values()]), clients_per_class))\n",
    "print('Total number of clients: {}'.format(np.sum([v for v in client_counts.values()])))\n",
    "print('Average batch size: {}'.format(np.mean([v for v in batch_sizes.values()])))\n",
    "\n",
    "split_batch_size = np.floor(np.mean([v for v in batch_sizes.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the attacker's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 clients to choose from:\n",
      "Classes of attack clients: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Choosing the following clients as the attackers:\n",
      "[80 30 65 89 83]\n"
     ]
    }
   ],
   "source": [
    "x_batches_filtered_i = [i for i, batch in enumerate(x_batches) if batch[0] == attack_params['our_class']]\n",
    "y_batches_filtered_i = [i for i, batch in enumerate(y_batches) if batch[0] == attack_params['our_class']]\n",
    "assert x_batches_filtered_i == y_batches_filtered_i\n",
    "\n",
    "x_batches_filtered = list(map(x_batches.__getitem__, x_batches_filtered_i))\n",
    "y_batches_filtered = list(map(y_batches.__getitem__, y_batches_filtered_i))\n",
    "\n",
    "print('{} clients to choose from:'.format(len(x_batches_filtered)))\n",
    "print('Classes of attack clients:', [f[0] for f in x_batches_filtered])\n",
    "print()\n",
    "\n",
    "attack_clients = np.random.choice(len(x_batches_filtered), attack_params['attacker_clients'], replace=False)\n",
    "print('Choosing the following clients as the attackers:\\n{}'.format(attack_clients))\n",
    "x_attack_batches = list(map(x_batches_filtered.__getitem__, attack_clients))\n",
    "y_attack_batches = list(map(y_batches_filtered.__getitem__, attack_clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset length: 996 996\n",
      "New dataset length:      991 991\n"
     ]
    }
   ],
   "source": [
    "# remove the attackers from the original training dataset\n",
    "# BREAKS THE ORIGINAL X_BATCHES AND Y_BATCHES!\n",
    "print('Original dataset length:', len(x_batches), len(y_batches))\n",
    "\n",
    "x_attackers_i = list(map(x_batches_filtered_i.__getitem__, attack_clients))\n",
    "y_attackers_i = list(map(y_batches_filtered_i.__getitem__, attack_clients))\n",
    "\n",
    "x_batches = [batch for i, batch in enumerate(x_batches) if i not in x_attackers_i]\n",
    "y_batches = [batch for i, batch in enumerate(y_batches) if i not in y_attackers_i]\n",
    "\n",
    "print('New dataset length:     ', len(x_batches), len(y_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data for Split Learning\n",
    "split_train_dataset = (x_batches, y_batches)\n",
    "split_test_dataset = (x_test, y_test)\n",
    "\n",
    "# place into train params:\n",
    "split_training_params['train_dataset'] = split_train_dataset\n",
    "split_training_params['test_dataset'] = split_test_dataset\n",
    "\n",
    "# Build attack dataset\n",
    "attack_train_dataset = (x_attack_batches, y_attack_batches)\n",
    "attack_params['train_dataset'] = attack_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0; Max: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Show min and max of the dataset (ensure you are using the right normalization)\n",
    "min_ = np.inf\n",
    "max_ = -np.inf\n",
    "for batch in x_batches:\n",
    "    min__ = np.min(batch[1])\n",
    "    max__ = np.max(batch[1])\n",
    "    min_ = min(min_, min__)\n",
    "    max_ = max(max_, max__)\n",
    "print('Min: {}; Max: {}'.format(min_, max_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "\n",
    "def start_piece(identifier, input_shape, filters=4):\n",
    "    assert filters >= 1\n",
    "    \n",
    "    input_1 = keras.layers.Input(input_shape)\n",
    "    conv1 = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(input_1)\n",
    "    model = keras.models.Model(inputs=[input_1], outputs=conv1)\n",
    "    model._name = identifier\n",
    "    \n",
    "    return model\n",
    "\n",
    "def blackbox_piece(identifier, input_shape, depth=1, filters=4):\n",
    "    assert depth >= 1\n",
    "    assert filters >= 1\n",
    "    \n",
    "    input_2 = keras.layers.Input(input_shape)\n",
    "    \n",
    "    # for now, we will just give the black-box all the CNN layers\n",
    "    for i in range(depth-1):\n",
    "        if i == 0:\n",
    "            convs = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(input_2)\n",
    "        else:\n",
    "            convs = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(convs)\n",
    "            \n",
    "    model = keras.models.Model(inputs=[input_2], outputs=convs)\n",
    "    model._name = identifier\n",
    "    \n",
    "    return model\n",
    "\n",
    "def approximator_piece(identifier, input_shape, depth=1, filters=4):\n",
    "    assert depth >= 1\n",
    "    assert filters >= 1\n",
    "    \n",
    "    input_2 = keras.layers.Input(input_shape)\n",
    "    \n",
    "    # for now, we will just give the black-box all the CNN layers\n",
    "    for i in range(depth-1):\n",
    "        if i == 0:\n",
    "            convs = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(input_2)\n",
    "        else:\n",
    "            convs = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(convs)\n",
    "            \n",
    "    model = keras.models.Model(inputs=[input_2], outputs=convs)\n",
    "    model._name = identifier\n",
    "    \n",
    "    return model\n",
    "\n",
    "def end_piece(identifier, input_shape, dense_breadth=128, num_classes=10):\n",
    "    assert dense_breadth >= num_classes\n",
    "    \n",
    "    input_3 = keras.layers.Input(input_shape)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(input_3)\n",
    "    drop1 = Dropout(0.25)(pool1)\n",
    "    flat1 = Flatten()(drop1)\n",
    "    dense1 = Dense(dense_breadth, activation='relu')(flat1)\n",
    "    drop2 = Dropout(0.5)(dense1)\n",
    "    dense2 = Dense(num_classes, activation='softmax')(drop2)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_3], outputs=dense2)\n",
    "    model._name = identifier\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the params are acceptable:\n",
    "assert depth >= 1\n",
    "assert filters >= 1\n",
    "assert dense >= num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitLearning:\n",
    "    \n",
    "    def __init__(self, split_training_params):\n",
    "        self.minibatch_size = split_training_params['minibatch_size']\n",
    "        self.batches_per_train_step = split_training_params['apply_gradients_after']\n",
    "        self.eval_batch_size = split_training_params['eval_batch_size']\n",
    "        self.shuffle_clients = split_training_params['shuffle_clients']\n",
    "        \n",
    "        self.ckpt_folder = split_training_params['ckpt_folder']\n",
    "        self.start_id = split_training_params['start_id']\n",
    "        self.middle_id = split_training_params['middle_id']\n",
    "        self.end_id = split_training_params['end_id']\n",
    "        self.full_id = split_training_params['full_id']\n",
    "        \n",
    "        # define the NN model\n",
    "        self.start_piece = None\n",
    "        self.middle_piece = None\n",
    "        self.end_piece = None\n",
    "        self.model = self.blackbox_model()\n",
    "        \n",
    "        # define loss function\n",
    "        self.cross_entropy = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define metrics\n",
    "        self.acc_train_avg = None\n",
    "        self.loss_train_avg = None\n",
    "        \n",
    "        # setup checkpointing\n",
    "        self.init_ckpt()\n",
    "        \n",
    "        # setup ops\n",
    "        self.setup_ops()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Black-box model\n",
    "        \n",
    "    def blackbox_model(self):\n",
    "        # create all three models\n",
    "        \n",
    "        #   start piece...\n",
    "        self.start_piece = start_piece(self.start_id, input_shape, filters)\n",
    "        output_shape = self.start_piece.layers[-1].output_shape[1:]\n",
    "        \n",
    "        #   middle...\n",
    "        self.middle_piece = blackbox_piece(self.middle_id, output_shape, depth, filters)\n",
    "        output_shape = self.middle_piece.layers[-1].output_shape[1:]\n",
    "        \n",
    "        #   end piece...\n",
    "        self.end_piece = end_piece(self.end_id, output_shape, dense, num_classes)\n",
    "        \n",
    "        # glue the three models together\n",
    "        input_ = keras.layers.Input(input_shape)\n",
    "        hidden1 = self.start_piece(input_)\n",
    "        hidden2 = self.middle_piece(hidden1)\n",
    "        output_ = self.end_piece(hidden2)\n",
    "        \n",
    "        # create the full model\n",
    "        model = keras.models.Model(inputs=[input_], outputs=output_)\n",
    "        model._name = self.full_id\n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def model_loss(self, y_true, y_pred):\n",
    "        return self.cross_entropy(y_true, y_pred)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Train\n",
    "    \n",
    "    def setup_ops(self):\n",
    "        # INSPIRED BY: https://stackoverflow.com/questions/42156957/how-to-update-model-parameters-with-accumulated-gradients\n",
    "        # https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\n",
    "        \n",
    "        self.tvs = self.model.trainable_variables\n",
    "        self.accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in self.tvs]\n",
    "        self.accum_counter = tf.Variable(0.0, trainable=False)\n",
    "    \n",
    "    def train(self, datasets, iteration, g_dataset=None, batch_limit=None, mask=None):\n",
    "        # setup checkpointing\n",
    "        self.setup_ckpt(iteration)\n",
    "        \n",
    "        # setup bb_dataset (stores labels if g_dataset is passed in)\n",
    "        bb_dataset = []\n",
    "        \n",
    "        g_dataset_acc = tf.keras.metrics.Accuracy()\n",
    "        \n",
    "        # initialize the metrics each new epoch\n",
    "        if self.acc_train_avg is not None:\n",
    "            del self.acc_train_avg\n",
    "        if self.loss_train_avg is not None:\n",
    "            del self.loss_train_avg\n",
    "        self.acc_train_avg = tf.keras.metrics.Accuracy()\n",
    "        self.loss_train_avg = tf.keras.metrics.Mean()\n",
    "        \n",
    "        # append all datasets together for training:\n",
    "        x_batches = []\n",
    "        y_batches = []\n",
    "        for dataset in datasets:\n",
    "            x_batches_, y_batches_ = dataset\n",
    "            x_batches = x_batches + x_batches_\n",
    "            y_batches = y_batches + y_batches_\n",
    "        # if g_dataset is not None, add those batches to the end:\n",
    "        if g_dataset is not None:\n",
    "            g_x_batches, g_y_batches = g_dataset\n",
    "            g_batch_idxs = list(range(len(x_batches), len(x_batches)+len(g_x_batches)))\n",
    "            x_batches = x_batches + g_x_batches\n",
    "            y_batches = y_batches + g_y_batches\n",
    "        else:\n",
    "            g_batch_idxs = []\n",
    "            \n",
    "        # setup progress bar\n",
    "        total_batches = batch_limit if batch_limit is not None and batch_limit < len(x_batches) else len(x_batches)\n",
    "        pbar = tqdm_notebook(total=total_batches)\n",
    "        \n",
    "        batch_idxs = list(range(len(x_batches)))\n",
    "        if self.shuffle_clients:\n",
    "            # shuffle the batches each time\n",
    "            random.shuffle(batch_idxs)\n",
    "            \n",
    "        for i, batch_idx in enumerate(batch_idxs):\n",
    "            x_batch = x_batches[batch_idx][1]\n",
    "            y_batch = y_batches[batch_idx][1]\n",
    "            \n",
    "            if batch_idx in g_batch_idxs:\n",
    "                # this is a g_x_batch! don't apply gradients, but store the prediction\n",
    "                logit_batch = self.pred_step(x_batch)\n",
    "                g_dataset_acc(tf.argmax(y_batch, 1), tf.argmax(logit_batch, 1))\n",
    "                \n",
    "                # if a mask is applied, replace the cases when the mask is 1\n",
    "                if mask is not None:\n",
    "                    mask_idx = g_batch_indxs.index(batch_idx)\n",
    "                    mask_batch = mask[:, mask_idx, 0] # (100, 28, 28, 1)\n",
    "                    \n",
    "                    # replacing with just zeros for now:\n",
    "                    logit_batch = logit_batch * (1.0 - mask_batch)\n",
    "                \n",
    "                bb_dataset.append((x_batch, y_batch, logit_batch))\n",
    "            else:\n",
    "                self.train_step(i, x_batch, y_batch, len(batch_idxs) - 1)\n",
    "            pbar.update(1)\n",
    "            pbar.set_description('train_acc={:.2f}%'.format(self.acc_train_avg.result()*100))\n",
    "            \n",
    "            if batch_limit is not None and i-1 >= batch_limit:\n",
    "                break\n",
    "        pbar.close()\n",
    "        print('train_acc={:.4f}%'.format(self.acc_train_avg.result()*100))\n",
    "        print('accuracy of blackbox on G dataset: {:.4f}%'.format(g_dataset_acc.result()*100))\n",
    "        \n",
    "        # save checkpoints\n",
    "        self.checkpoint()\n",
    "        \n",
    "        return bb_dataset\n",
    "        \n",
    "    def pred_step(self, x_batch):\n",
    "        logit_batch = []\n",
    "        # Iterate over the client's batch in minibatches:\n",
    "        j = 0\n",
    "        while(j < len(x_batch)):\n",
    "            if self.minibatch_size is None:\n",
    "                # use whole batch (no minibatch)\n",
    "                x_minibatch = x_batch\n",
    "            else:\n",
    "                x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "\n",
    "            logits = self.model(x_minibatch, training=True) # TODO: should this be False?\n",
    "            logit_batch = logit_batch + list(logits.numpy())\n",
    "\n",
    "            if self.minibatch_size is None:\n",
    "                break\n",
    "            else:\n",
    "                j += self.minibatch_size\n",
    "                \n",
    "        return logit_batch\n",
    "        \n",
    "    def train_step(self, i, x_batch, y_batch, limit):\n",
    "        # Iterate over the client's batch in minibatches:\n",
    "        j = 0\n",
    "        while(j < len(x_batch)):\n",
    "            if self.minibatch_size is None:\n",
    "                # use whole batch (no minibatch)\n",
    "                x_minibatch = x_batch\n",
    "                y_minibatch = y_batch\n",
    "            else:\n",
    "                x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                y_minibatch = y_batch[j:(j+self.minibatch_size)]\n",
    "\n",
    "            # run the gradients\n",
    "            loss_value, grads = self.grad(x_minibatch, y_minibatch)\n",
    "\n",
    "            # accumulate them\n",
    "            self.accumulate_grads(grads)\n",
    "\n",
    "            if self.minibatch_size is None:\n",
    "                break\n",
    "            else:\n",
    "                j += self.minibatch_size\n",
    "\n",
    "        # perform a train step every batches_per_train_step number of batches:\n",
    "        if (i > 0 and i % self.batches_per_train_step == 0) or i == limit:\n",
    "            # Run the train_step ops to update the weights based on our accumulated gradients\n",
    "            self.optimize()\n",
    "            self.zero_out()\n",
    "    \n",
    "    def grad(self, inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(inputs, training=True)\n",
    "            loss_value = self.model_loss(targets, logits)\n",
    "            \n",
    "        # evaluate accuracy and append acc and loss to arrays\n",
    "        self.acc_train_avg(tf.argmax(targets, 1), tf.argmax(logits, 1))\n",
    "        self.loss_train_avg(loss_value)\n",
    "        \n",
    "        return loss_value, tape.gradient(loss_value, self.model.trainable_variables)\n",
    "    \n",
    "    def accumulate_grads(self, grads):\n",
    "        # add to accum_vars the new gradients\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.accum_vars[i].assign_add(grad)\n",
    "        # increment the counter by 1\n",
    "        self.accum_counter.assign_add(1.0)\n",
    "        \n",
    "    def optimize(self):\n",
    "        # apply the gradients in accum_vars, dividing by the number in accum_counter\n",
    "        self.optimizer.apply_gradients(\n",
    "            [(accum_var / self.accum_counter, tv) \\\n",
    "                for (accum_var, tv) in zip(self.accum_vars, self.model.trainable_variables)]\n",
    "        )\n",
    "    \n",
    "    def zero_out(self):\n",
    "        # reset accum_vars and accum_counter back to 0\n",
    "        for i, tv in enumerate(self.accum_vars):\n",
    "            self.accum_vars[i].assign(tf.zeros_like(tv))\n",
    "        self.accum_counter = tf.Variable(0.0, trainable=False)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = None\n",
    "        self.internal_iteration = None\n",
    "        self.iteration_offset = 0\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        # setup fresh checkpointer every new iteration\n",
    "        if self.internal_iteration is None or iteration != self.internal_iteration - self.iteration_offset:\n",
    "            ckpt_save_folder = os.path.join('../gan_attack/checkpoints', 'it_{}'.format(iteration + self.iteration_offset), self.ckpt_folder)\n",
    "            os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "        \n",
    "            if self.ckpt is not None:\n",
    "                del self.ckpt\n",
    "            if self.manager is not None:\n",
    "                del self.manager\n",
    "\n",
    "            self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "            self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "            self.internal_iteration = iteration + self.iteration_offset\n",
    "    \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved checkpoint: {}\".format(save_path))\n",
    "        self.save_all_models(save_path)\n",
    "        \n",
    "    def save_all_models(self, save_path):\n",
    "        # in addition to checkpointing, save all of the models into their own ckpt files\n",
    "        it_folder = \"\"\n",
    "        for folder in self.splitall(save_path):\n",
    "            if \"it\" not in folder:\n",
    "                it_folder = os.path.join(it_folder, folder)\n",
    "            else:\n",
    "                it_folder = os.path.join(it_folder, folder)\n",
    "                break\n",
    "        \n",
    "        # save all three models\n",
    "        start_piece_folder = os.path.join(it_folder, self.start_id + \"_checkpoint\")\n",
    "        os.makedirs(start_piece_folder, exist_ok=True)\n",
    "        self.start_piece.save_weights(os.path.join(start_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved checkpoint: {}\".format(os.path.join(start_piece_folder, 'checkpoint')))\n",
    "        \n",
    "        middle_piece_folder = os.path.join(it_folder, self.middle_id + \"_checkpoint\")\n",
    "        os.makedirs(middle_piece_folder, exist_ok=True)\n",
    "        self.middle_piece.save_weights(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved checkpoint: {}\".format(os.path.join(middle_piece_folder, 'checkpoint')))\n",
    "        \n",
    "        end_piece_folder = os.path.join(it_folder, self.end_id + \"_checkpoint\")\n",
    "        os.makedirs(end_piece_folder, exist_ok=True)\n",
    "        self.end_piece.save_weights(os.path.join(end_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved checkpoint: {}\".format(os.path.join(end_piece_folder, 'checkpoint')))\n",
    "        \n",
    "    @staticmethod\n",
    "    def splitall(path):\n",
    "        allparts = []\n",
    "        while 1:\n",
    "            parts = os.path.split(path)\n",
    "            if parts[0] == path:  # sentinel for absolute paths\n",
    "                allparts.insert(0, parts[0])\n",
    "                break\n",
    "            elif parts[1] == path: # sentinel for relative paths\n",
    "                allparts.insert(0, parts[1])\n",
    "                break\n",
    "            else:\n",
    "                path = parts[0]\n",
    "                allparts.insert(0, parts[1])\n",
    "        return allparts\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        parent_folder = os.path.join('../gan_attack/checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                self.iteration_offset = largest_it\n",
    "                print('Restored latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found, starting with a fresh network')\n",
    "        else:\n",
    "            if load_default:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    self.iteration_offset = it_restore\n",
    "                print('Restored latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "        \n",
    "    def evaluate(self, dataset):\n",
    "        '''\n",
    "        NOTE: dataset here is tailored for standard 'test' dataset provided by Keras\n",
    "        '''\n",
    "        \n",
    "        x, y = dataset\n",
    "        \n",
    "        acc_test_avg = tf.keras.metrics.Accuracy()\n",
    "        loss_test_avg = tf.keras.metrics.Mean()\n",
    "        for i in range(0, len(x), self.eval_batch_size):\n",
    "            # get batch\n",
    "            x_batch = x[i:i+self.eval_batch_size]\n",
    "            y_batch = y[i:i+self.eval_batch_size]\n",
    "            \n",
    "            # evaluate\n",
    "            logits = self.model(x_batch, training=False)\n",
    "            acc_test_avg(tf.argmax(y_batch, 1), tf.argmax(logits, 1))\n",
    "            loss_test_avg(self.model_loss(y_batch, logits))\n",
    "        \n",
    "        if self.acc_train_avg is not None and self.loss_train_avg is not None:\n",
    "            print('Train Accuracy: {:.3f} | Loss: {:.3f}'.format(self.acc_train_avg.result(), self.loss_train_avg.result()))\n",
    "        print('Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test_avg.result(), loss_test_avg.result()))\n",
    "        print()\n",
    "        return acc_test_avg.result()\n",
    "        \n",
    "    def predict(self, dataset, return_tensors=True):\n",
    "        '''\n",
    "        Returns a list of label batches of each client that was in the dataset\n",
    "        '''\n",
    "        \n",
    "        x, _ = dataset\n",
    "        labels = []\n",
    "        \n",
    "        for i, client_x in enumerate(x):\n",
    "            x_batch = client_x[1]\n",
    "            label_batch = []\n",
    "            \n",
    "            # run through every minibatch:\n",
    "            j = 0\n",
    "            while(j < len(x_batch)):\n",
    "                if self.minibatch_size is None:\n",
    "                    # use whole batch (no minibatch)\n",
    "                    x_minibatch = x_batch\n",
    "                else:\n",
    "                    x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                    \n",
    "                # evaluate\n",
    "                preds = self.model(x_batch, training=False)\n",
    "                if not return_tensors:\n",
    "                    preds = tf.nn.softmax(preds)\n",
    "                    preds = tf.argmax(preds, axis=1)\n",
    "                    \n",
    "                label_batch = label_batch + list(preds.numpy())\n",
    "                \n",
    "                if self.minibatch_size is None:\n",
    "                    break\n",
    "                else:\n",
    "                    j += self.minibatch_size\n",
    "            \n",
    "            # add to list\n",
    "            labels.append(label_batch)\n",
    "            \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D:\n",
    "    '''\n",
    "    The Discriminator portion of the GAN. Accepts a network, otherwise creates a new model.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, start_piece=None, middle_piece=None, end_piece=None, d_model=None):\n",
    "        \n",
    "#         self.ckpt_folder = gan_training_params['d_ckpt_folder']\n",
    "        self.ckpt_folder = gan_training_params['middle_id']\n",
    "        self.bb_ckpt_folder = gan_training_params['bb_ckpt_folder']\n",
    "        self.loop_times = gan_training_params['loop_times']\n",
    "        self.softmax_power = gan_training_params['softmax_power']\n",
    "        self.minibatch_size = gan_training_params['minibatch_size']\n",
    "        \n",
    "        self.use_bb_ends = gan_training_params['use_bb_ends']\n",
    "        self.start_id = gan_training_params['start_id']\n",
    "        self.middle_id = gan_training_params['middle_id']\n",
    "        self.end_id = gan_training_params['end_id']\n",
    "        self.full_id = gan_training_params['full_id']\n",
    "        \n",
    "        # make FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "        \n",
    "        # define the NN model\n",
    "        if d_model is not None:\n",
    "            assert start_piece is None and middle_piece is None and end_piece is None\n",
    "            self.model = d_model\n",
    "        else:\n",
    "            self.start_piece = start_piece\n",
    "            self.middle_piece = middle_piece\n",
    "            self.end_piece = end_piece\n",
    "            self.model = self.discriminator_model()\n",
    "            \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define entropies\n",
    "        self.cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        self.bin_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            \n",
    "        # setup checkpointing\n",
    "        self.ckpt = None\n",
    "        self.manager = None\n",
    "        \n",
    "        # save the initial weights\n",
    "        if middle_piece is None:\n",
    "            self.save_initial_weights()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Discriminator model\n",
    "    \n",
    "    def discriminator_model(self):\n",
    "        # create all three models\n",
    "        \n",
    "        #   start piece...\n",
    "        if self.use_bb_ends:\n",
    "            assert self.start_piece is not None\n",
    "        else:\n",
    "            self.start_piece = start_piece(self.start_id, input_shape, filters)\n",
    "        output_shape = self.start_piece.layers[-1].output_shape[1:]\n",
    "        \n",
    "        #   middle...\n",
    "        if self.middle_piece is None:\n",
    "            self.middle_piece = approximator_piece(self.middle_id, output_shape, depth, filters)\n",
    "        else:\n",
    "            print('WARNING: using the middle piece in D')\n",
    "        output_shape = self.middle_piece.layers[-1].output_shape[1:]\n",
    "        \n",
    "        #   end piece...\n",
    "        if self.use_bb_ends:\n",
    "            assert self.end_piece is not None\n",
    "        else:\n",
    "            self.end_piece = end_piece(self.end_id, output_shape, dense, num_classes)\n",
    "        \n",
    "        # glue the three models together\n",
    "        input_ = keras.layers.Input(input_shape)\n",
    "        hidden1 = self.start_piece(input_)\n",
    "        hidden2 = self.middle_piece(hidden1)\n",
    "        output_ = self.end_piece(hidden2)\n",
    "        \n",
    "        # create the full model\n",
    "        model = keras.models.Model(inputs=[input_], outputs=output_)\n",
    "        model._name = self.full_id\n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Loss\n",
    "    \n",
    "    def loss(self, fake_discrimination, labels):\n",
    "        matches = self.matches_labels(fake_discrimination, labels, loop_times=self.loop_times)\n",
    "        # we want the discriminator to NOT be fooled by these fake images\n",
    "        cross_entropy = self.bin_cross_entropy(tf.zeros_like(matches), matches)\n",
    "        return cross_entropy\n",
    "    \n",
    "    def entropy(self, y_true, y_pred):\n",
    "        return self.cat_cross_entropy(y_true, y_pred)\n",
    "        \n",
    "    def matches_labels(self, fake_output, labels, loop_times=0):\n",
    "        '''\n",
    "        Only works if the Discriminator is already trained on real images!!\n",
    "        1. Performs a softmax -> onehot conversion (differentiable approx.)\n",
    "        2. Multiplies this by the onehot version of the onehot attack label\n",
    "        3. Sums to reduce dimension\n",
    "        \n",
    "        - if the sum is close to 1, the nn thinks that the image is a part of the attack class\n",
    "        - if the sum is close to 0, the nn thinks that the image is not of the attack class\n",
    "        - the sum should not be in between, due to the onehot conversion we perform in step 1\n",
    "        '''\n",
    "        # 1.\n",
    "        my_power = self.softmax_power\n",
    "        for i in range(loop_times):\n",
    "            fake_output = self.soft_onehot(fake_output)\n",
    "        \n",
    "        # 2.\n",
    "        matches = tf.math.multiply(fake_output, labels)\n",
    "        \n",
    "        # 3.\n",
    "        reduced = tf.math.reduce_sum(matches, axis=-1)\n",
    "        \n",
    "        return reduced\n",
    "        \n",
    "    def soft_onehot(self, softmax, my_power=8):\n",
    "        '''\n",
    "        Shown to not really work... vanishing gradients problem\n",
    "        '''\n",
    "        soft_extreme = softmax ** my_power\n",
    "        norm = tf.reduce_sum(soft_extreme, axis=-1)\n",
    "        almost_onehot = tf.math.divide(soft_extreme, tf.reshape(norm, (-1, 1)))\n",
    "        return almost_onehot\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        ckpt_save_folder = os.path.join('../gan_attack/checkpoints', 'it_{}'.format(iteration), self.ckpt_folder)\n",
    "        os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "        if self.ckpt is not None:\n",
    "            del self.ckpt\n",
    "        if self.manager is not None:\n",
    "            del self.manager\n",
    "\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.middle_piece)\n",
    "        self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "        \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved D checkpoint: {}\".format(save_path))\n",
    "        self.save_all_models(save_path)\n",
    "        \n",
    "    def save_all_models(self, save_path):\n",
    "        # in addition to checkpointing, save all of the models into their own ckpt files\n",
    "        it_folder = \"\"\n",
    "        for folder in self.splitall(save_path):\n",
    "            if \"it\" not in folder:\n",
    "                it_folder = os.path.join(it_folder, folder)\n",
    "            else:\n",
    "                it_folder = os.path.join(it_folder, folder)\n",
    "                break\n",
    "        \n",
    "        # save all three models\n",
    "        start_piece_folder = os.path.join(it_folder, self.start_id + \"_checkpoint\")\n",
    "        os.makedirs(start_piece_folder, exist_ok=True)\n",
    "        self.start_piece.save_weights(os.path.join(start_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved D checkpoint: {}\".format(os.path.join(start_piece_folder, 'checkpoint')))\n",
    "        \n",
    "        middle_piece_folder = os.path.join(it_folder, self.middle_id + \"_checkpoint\")\n",
    "        os.makedirs(middle_piece_folder, exist_ok=True)\n",
    "        self.middle_piece.save_weights(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved D checkpoint: {}\".format(os.path.join(middle_piece_folder, 'checkpoint')))\n",
    "        \n",
    "        end_piece_folder = os.path.join(it_folder, self.end_id + \"_checkpoint\")\n",
    "        os.makedirs(end_piece_folder, exist_ok=True)\n",
    "        self.end_piece.save_weights(os.path.join(end_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved D checkpoint: {}\".format(os.path.join(end_piece_folder, 'checkpoint')))\n",
    "        \n",
    "    @staticmethod\n",
    "    def splitall(path):\n",
    "        allparts = []\n",
    "        while 1:\n",
    "            parts = os.path.split(path)\n",
    "            if parts[0] == path:  # sentinel for absolute paths\n",
    "                allparts.insert(0, parts[0])\n",
    "                break\n",
    "            elif parts[1] == path: # sentinel for relative paths\n",
    "                allparts.insert(0, parts[1])\n",
    "                break\n",
    "            else:\n",
    "                path = parts[0]\n",
    "                allparts.insert(0, parts[1])\n",
    "        return allparts\n",
    "    \n",
    "    def freeze_ends(self, yes):\n",
    "        self.start_piece.is_training = not yes\n",
    "        self.end_piece.is_training = not yes\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Load/save weights\n",
    "    \n",
    "    def save_initial_weights(self):\n",
    "        print('saving initial weights for D')\n",
    "        init_folder = os.path.join('../gan_attack/checkpoints', 'init', self.ckpt_folder)\n",
    "        os.makedirs(init_folder, exist_ok=True)\n",
    "        self.model.save_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def load_initial_weights(self):\n",
    "        print('loading initial weights for D')\n",
    "        init_folder = os.path.join('../gan_attack/checkpoints', 'init', self.ckpt_folder)\n",
    "        self.model.load_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False, use_blackbox=False):\n",
    "        iteration_offset = 0\n",
    "        parent_folder = os.path.join('../gan_attack/checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "#                 checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "#                 self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                self.restore_pieces(it_restore_ends=largest_it, it_restore_middle=largest_it)\n",
    "                iteration_offset = largest_it\n",
    "#                 print('Restored D to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found for D, starting with a fresh network')\n",
    "        else:\n",
    "            if load_default:\n",
    "                if use_blackbox:\n",
    "                    checkpoint_directory = os.path.join(parent_folder, 'default', self.bb_ckpt_folder)\n",
    "                else:\n",
    "                    checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    iteration_offset = it_restore\n",
    "                print('Restored D to checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        return iteration_offset\n",
    "    \n",
    "    def restore_middle(self, it_restore_middle):\n",
    "        parent_folder = os.path.join('../gan_attack/checkpoints')\n",
    "        it_folder_middle = os.path.join(parent_folder, 'it_{}'.format(it_restore_middle))\n",
    "        middle_piece_folder = os.path.join(it_folder_middle, self.middle_id + \"_checkpoint\")\n",
    "        print('Restoring D piece: {}'.format(middle_piece_folder))\n",
    "        \n",
    "        assert os.path.isfile(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        self.middle_piece.load_weights(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "    \n",
    "    def restore_pieces(self, it_restore_ends=None, it_restore_middle=None, start_id=None, middle_id=None, \n",
    "                       end_id=None, load_default=False):\n",
    "        \n",
    "        if it_restore_ends is None:\n",
    "            it_restore_ends = 1\n",
    "        if it_restore_middle is None:\n",
    "            it_restore_middle = 1\n",
    "        \n",
    "        if start_id is None:\n",
    "            start_id = self.start_id\n",
    "        if middle_id is None:\n",
    "            middle_id = self.middle_id\n",
    "        if end_id is None:\n",
    "            end_id = self.end_id\n",
    "        \n",
    "        parent_folder = os.path.join('../gan_attack/checkpoints')\n",
    "        it_folder_ends = os.path.join(parent_folder, 'default' if load_default else 'it_{}'.format(it_restore_ends))\n",
    "        it_folder_middle = os.path.join(parent_folder, 'default' if load_default else 'it_{}'.format(it_restore_middle))\n",
    "        \n",
    "        start_piece_folder = os.path.join(it_folder_ends, start_id + \"_checkpoint\")\n",
    "        print('Restoring D piece: {}'.format(start_piece_folder))\n",
    "        middle_piece_folder = os.path.join(it_folder_middle, middle_id + \"_checkpoint\")\n",
    "        print('Restoring D piece: {}'.format(middle_piece_folder))\n",
    "        end_piece_folder = os.path.join(it_folder_ends, end_id + \"_checkpoint\")\n",
    "        print('Restoring D piece: {}'.format(end_piece_folder))\n",
    "        \n",
    "        assert os.path.isfile(os.path.join(start_piece_folder, 'checkpoint'))\n",
    "        assert os.path.isfile(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        assert os.path.isfile(os.path.join(end_piece_folder, 'checkpoint'))\n",
    "        \n",
    "        self.start_piece.load_weights(os.path.join(start_piece_folder, 'checkpoint'))\n",
    "        self.middle_piece.load_weights(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        self.end_piece.load_weights(os.path.join(end_piece_folder, 'checkpoint'))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluation\n",
    "\n",
    "    def discriminate(self, generated_images, training=True):\n",
    "        return self.model(generated_images, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G:\n",
    "    '''\n",
    "    The Generator portion of the GAN. Generates images given a conditional label.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, is_conditional=True, identifier=None, extra_depth=0):\n",
    "        self.is_conditional = is_conditional\n",
    "        self.identifier = identifier\n",
    "        \n",
    "        self.ckpt_folder = self.g_identifier() + gan_training_params['g_ckpt_folder']\n",
    "        self.noise_dim = gan_training_params['noise_dim']\n",
    "        self.uncertain_loop_times = gan_training_params['uncertain_loop_times']\n",
    "        self.softmax_power = gan_training_params['softmax_power']\n",
    "        \n",
    "        # make FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "        self.input_shapes = []\n",
    "        if is_conditional:\n",
    "            self.model = self.c_generator_model(extra_depth)\n",
    "        else:\n",
    "            self.model = self.u_generator_model()\n",
    "            \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define entropies\n",
    "        self.cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        self.bin_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            \n",
    "        # setup checkpointing\n",
    "        self.ckpt = None\n",
    "        self.manager = None\n",
    "        \n",
    "        # save initial weights\n",
    "        self.save_initial_weights()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Generator model\n",
    "    \n",
    "    def g_identifier(self):\n",
    "        return self.identifier if self.identifier is not None else ''\n",
    "    \n",
    "    def c_generator_model(self, extra_depth=0):\n",
    "        '''\n",
    "        CONDITIONAL version of G\n",
    "        '''\n",
    "        ACTIVATION = keras.layers.Activation(\"tanh\")\n",
    "        \n",
    "        # Prepare noise input\n",
    "        self.input_shapes.append((self.noise_dim,))\n",
    "        input_z = keras.layers.Input((self.noise_dim,))\n",
    "        dense_z_1 = keras.layers.Dense(1024)(input_z)\n",
    "        act_z_1 = ACTIVATION(dense_z_1)\n",
    "        dense_z_2 = keras.layers.Dense(128 * 7 * 7)(act_z_1)\n",
    "        bn_z_1 = keras.layers.BatchNormalization()(dense_z_2)\n",
    "        reshape_z = keras.layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,))(bn_z_1)\n",
    "\n",
    "        # Prepare Conditional (label) input\n",
    "        self.input_shapes.append((num_classes,))\n",
    "        input_c = keras.layers.Input((num_classes,))\n",
    "        dense_c_1 = keras.layers.Dense(1024)(input_c)\n",
    "        act_c_1 = ACTIVATION(dense_c_1)\n",
    "        dense_c_2 = keras.layers.Dense(128 * 7 * 7)(act_c_1)\n",
    "        bn_c_1 = keras.layers.BatchNormalization()(dense_c_2)\n",
    "        reshape_c = keras.layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,))(bn_c_1)\n",
    "\n",
    "        # Combine input source\n",
    "        concat_z_c = keras.layers.Concatenate()([reshape_z, reshape_c])\n",
    "\n",
    "        # Image generation with the concatenated inputs\n",
    "        up_1 = keras.layers.UpSampling2D(size=(2, 2))(concat_z_c)\n",
    "        conv_1 = keras.layers.Conv2D(64, (5, 5), padding='same')(up_1)\n",
    "        for i in range(extra_depth):\n",
    "            conv_1 = keras.layers.Conv2D(64, (5, 5), padding='same')(conv_1)\n",
    "        act_1 = ACTIVATION(conv_1)\n",
    "        up_2 = keras.layers.UpSampling2D(size=(2, 2))(act_1)\n",
    "        #\n",
    "        drop_1 = keras.layers.Dropout(0.1)(up_2)\n",
    "        #\n",
    "        conv_2 = keras.layers.Conv2D(1, (5, 5), padding='same')(drop_1)\n",
    "        act_2 = keras.layers.Activation(\"tanh\")(conv_2)\n",
    "        model = keras.models.Model(inputs=[input_z, input_c], outputs=act_2)\n",
    "        model._name = \"{}g_model\".format(self.g_identifier())\n",
    "        return model\n",
    "    \n",
    "    def u_generator_model(self):\n",
    "        '''\n",
    "        NORMAL version of G\n",
    "        '''\n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        self.input_shapes.append((self.noise_dim,))\n",
    "        model.add(Dense(7*7*256, use_bias=False, input_shape=(self.noise_dim,)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Reshape((7, 7, 256)))\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "        model._name = \"{}g_model\".format(self.g_identifier())\n",
    "\n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Loss\n",
    "    \n",
    "    def loss(self, fake_discrimination, labels):\n",
    "        # we want the discriminator to be fooled by these fake images\n",
    "        cross_entropy = self.cat_cross_entropy(fake_discrimination, labels)\n",
    "        return cross_entropy\n",
    "    \n",
    "    def u_loss(self, fake_discrimination):\n",
    "        '''\n",
    "        Loss that measures how close the output is to having a single peak.\n",
    "        In other words we are measuring how certain the model thinks it is\n",
    "        correct, regardless of the answer\n",
    "        1. Performs a softmax -> onehot conversion (differentiable approx.)\n",
    "        2. Compare to the original output -- return this cat crossentropy\n",
    "        '''\n",
    "        fake_output = tf.identity(fake_discrimination)\n",
    "        \n",
    "        # 1.\n",
    "        my_power = self.softmax_power\n",
    "        for i in range(self.uncertain_loop_times):\n",
    "            fake_output = self.soft_onehot(fake_output)\n",
    "            \n",
    "        # 2.\n",
    "        return self.cat_cross_entropy(fake_output, fake_discrimination)\n",
    "        \n",
    "    def soft_onehot(self, softmax, my_power=8):\n",
    "        '''\n",
    "        Shown to not really work... vanishing gradients problem\n",
    "        '''\n",
    "        soft_extreme = softmax ** my_power\n",
    "        norm = tf.reduce_sum(soft_extreme, axis=-1)\n",
    "        almost_onehot = tf.math.divide(soft_extreme, tf.reshape(norm, (-1, 1)))\n",
    "        return almost_onehot\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        ckpt_save_folder = os.path.join('../gan_attack/checkpoints', 'it_{}'.format(iteration), self.ckpt_folder)\n",
    "        os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "        if self.ckpt is not None:\n",
    "            del self.ckpt\n",
    "        if self.manager is not None:\n",
    "            del self.manager\n",
    "\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "        \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved {}G checkpoint: {}\".format(self.g_identifier(), save_path))\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Load/save weights\n",
    "    \n",
    "    def save_initial_weights(self):\n",
    "        print('saving initial weights for {}G'.format(self.g_identifier()))\n",
    "        init_folder = os.path.join('../gan_attack/checkpoints', 'init', self.ckpt_folder)\n",
    "        os.makedirs(init_folder, exist_ok=True)\n",
    "        self.model.save_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def load_initial_weights(self):\n",
    "        print('loading initial weights for {}G'.format(self.g_identifier()))\n",
    "        init_folder = os.path.join('../gan_attack/checkpoints', 'init', self.ckpt_folder)\n",
    "        self.model.load_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        iteration_offset = 0\n",
    "        parent_folder = os.path.join('../gan_attack/checkpoints')\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                iteration_offset = largest_it\n",
    "                print('Restored {}G to latest checkpoint from {}'.format(self.g_identifier(), checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found for {}G, starting with a fresh network'.format(self.g_identifier()))\n",
    "        else:\n",
    "            if load_default:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    iteration_offset = it_restore\n",
    "                print('Restored {}G to checkpoint from {}'.format(self.g_identifier(), checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        return iteration_offset\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluation\n",
    "        \n",
    "    def generate(self, inputs, training=True):\n",
    "        generated_images = self.model(inputs, training=training)\n",
    "        return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cGAN:\n",
    "    '''\n",
    "    The cGAN. Trains the G and D.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, start_piece=None, middle_piece=None, end_piece=None):\n",
    "        self.is_conditional = True\n",
    "        self.extra_depth = gan_training_params['extra_depth']\n",
    "        self.noise_dim = gan_training_params['noise_dim']\n",
    "        self.batch_size = gan_training_params['batch_size']\n",
    "        self.batches_per_epoch = gan_training_params['batches_per_epoch']\n",
    "        self.d_trigger = gan_training_params['d_trigger']\n",
    "        self.g_trigger = gan_training_params['g_trigger']\n",
    "        self.early_stop_trigger = gan_training_params['early_stop_trigger']\n",
    "        self.stop_sensitivity = gan_training_params['stop_sensitivity']\n",
    "        self.g_nudge_trigger = gan_training_params['g_nudge_trigger']\n",
    "        self.g_nudge_probability = gan_training_params['g_nudge_probability']\n",
    "        self.minibatch_size = gan_training_params['minibatch_size']\n",
    "        self.d_restore_after_nudge = gan_training_params['d_restore_after_nudge']\n",
    "\n",
    "        # define the D and G models\n",
    "        self.g = G(gan_training_params, is_conditional=self.is_conditional, identifier='c_', extra_depth=self.extra_depth)\n",
    "        self.d = D(gan_training_params, start_piece, middle_piece, end_piece)\n",
    "            \n",
    "        # stack G on top of D\n",
    "        self.gd = self.stack_models()\n",
    "        print(self.gd.summary())\n",
    "        \n",
    "        # define losses\n",
    "        self.mse = tf.keras.losses.MeanSquaredError()\n",
    "        \n",
    "        # define metrics\n",
    "        self.gen_loss_train_avg = None\n",
    "        self.gen_acc_train_avg = None\n",
    "        self.disc_loss_train_avg = None\n",
    "        self.disc_loss_refine_avg = None\n",
    "        \n",
    "        # define plotting metrics\n",
    "        self.gen_loss_train_arr = []\n",
    "        self.gen_acc_train_arr = []\n",
    "        self.disc_loss_train_arr = []\n",
    "        self.disc_acc_test_arr = []\n",
    "        \n",
    "        # seed for image generation\n",
    "        num_examples_to_generate = 16\n",
    "        self.seed = tf.random.normal([num_examples_to_generate, self.noise_dim])\n",
    "        \n",
    "        # labels for image generation\n",
    "        label_pattern = [i % (num_classes) for i in range(num_examples_to_generate)]\n",
    "        self.eval_labels = tf.one_hot(label_pattern, num_classes, dtype=tf.dtypes.float32)\n",
    "        \n",
    "        # setup checkpointing\n",
    "        self.internal_iteration = None\n",
    "        self.iteration_offset = 0\n",
    "        self.save_ckpts = True\n",
    "        \n",
    "        # initialize d and g checkpoints\n",
    "        self.d.init_ckpt()\n",
    "        self.g.init_ckpt()\n",
    "        \n",
    "        # setup early stop metrics\n",
    "        self.early_stop = False\n",
    "        self.no_change_inc = 0\n",
    "        self.prev_g_acc = None\n",
    "        self.best_g_acc = None\n",
    "        self.nudge_flag = False\n",
    "        \n",
    "    def stack_models(self):\n",
    "        inputs = []\n",
    "        for input_shape in self.g.input_shapes:\n",
    "            inputs.append(keras.layers.Input(input_shape))\n",
    "        \n",
    "        outputG = self.g.model(inputs)\n",
    "        \n",
    "        # output of G needs to be converted from [-1, 1] to [0, 1] spectrum\n",
    "        outputG_converted = 0.5 * outputG + 0.5\n",
    "        \n",
    "        outputD = self.d.model(outputG_converted)\n",
    "        \n",
    "        model = keras.models.Model(inputs=inputs, outputs=outputD)\n",
    "        model._name = \"cgan_model\"\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Trainer\n",
    "        \n",
    "    def train(self, iteration, save_best=False):\n",
    "        # setup checkpointing\n",
    "        self.setup_ckpts(iteration)\n",
    "        \n",
    "        # freeze the ends of D\n",
    "        self.d.freeze_ends(True)\n",
    "        \n",
    "        # initialize the metrics each new epoch\n",
    "        if self.gen_acc_train_avg is not None:\n",
    "            del self.gen_acc_train_avg\n",
    "        if self.gen_loss_train_avg is not None:\n",
    "            del self.gen_loss_train_avg\n",
    "        if self.disc_loss_train_avg is not None:\n",
    "            del self.disc_loss_train_avg\n",
    "        \n",
    "        self.gen_loss_train_avg = tf.keras.metrics.Mean()\n",
    "        self.gen_acc_train_avg = tf.keras.metrics.Accuracy()\n",
    "        self.disc_loss_train_avg = tf.keras.metrics.Mean()\n",
    "        \n",
    "        pbar = tqdm_notebook(total=self.batches_per_epoch)\n",
    "        \n",
    "        for i in range(self.batches_per_epoch):\n",
    "            # nudge generator if nothing is happening:\n",
    "            if self.nudge():\n",
    "                if not self.nudge_flag:\n",
    "                    self.nudge_flag = True\n",
    "                    print(\"*** nudging ***\")\n",
    "                train_discriminator = True\n",
    "            else:\n",
    "                train_discriminator = (self.gen_acc_train_avg.result() >= self.d_trigger)\n",
    "            \n",
    "            # logic for training the generator\n",
    "            train_generator = (self.gen_acc_train_avg.result() < self.g_trigger)\n",
    "            \n",
    "            self.c_train_step(train_discriminator=train_discriminator, train_generator=train_generator)\n",
    "            pbar.update(1)\n",
    "            pbar.set_description('g_acc={:.2f}, g_loss={:.2f}, d_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                                     self.gen_loss_train_avg.result(),\n",
    "                                                                                     self.disc_loss_train_avg.result()))\n",
    "        \n",
    "        print('g_acc={:.2f}, g_loss={:.2f}, d_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                  self.gen_loss_train_avg.result(),\n",
    "                                                                  self.disc_loss_train_avg.result()))\n",
    "        \n",
    "        # reload from pre-nudge state\n",
    "        just_nudged = False\n",
    "        if self.nudge_flag:\n",
    "            just_nudged = True\n",
    "            if self.d_restore_after_nudge:\n",
    "                self.d.restore_middle(iteration)\n",
    "            self.nudge_flag = False\n",
    "        \n",
    "        # save checkpoints\n",
    "        # only checkpoint d if we are the cGAN\n",
    "        self.checkpoint_d()\n",
    "        if save_best:\n",
    "            if self.best_g_acc is None or self.gen_acc_train_avg.result() >= self.best_g_acc:\n",
    "                self.best_g_acc = self.gen_acc_train_avg.result()\n",
    "                self.checkpoint_g()\n",
    "        else:\n",
    "            self.checkpoint_g()\n",
    "            \n",
    "        # unfreeze the ends of D\n",
    "        self.d.freeze_ends(False)\n",
    "        \n",
    "        # check for early stop\n",
    "        self.early_stop_check()\n",
    "        \n",
    "        return just_nudged\n",
    "    \n",
    "    def c_train_step(self, train_discriminator, train_generator):\n",
    "        noise = tf.random.normal([self.batch_size, self.noise_dim])\n",
    "        random_classes = tf.random.uniform(shape=(self.batch_size, ), maxval=num_classes, dtype=tf.dtypes.int32)\n",
    "        labels = tf.one_hot(random_classes, num_classes, dtype=tf.dtypes.float32)\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            fake_discrimination = self.gd([noise, labels], training=train_generator)\n",
    "\n",
    "            gen_loss = self.g.loss(fake_discrimination, labels)\n",
    "            disc_loss = self.d.loss(fake_discrimination, labels)\n",
    "            \n",
    "            # evaluate accuracy and append acc and loss to arrays\n",
    "            self.gen_loss_train_avg(gen_loss)\n",
    "            self.gen_acc_train_avg(tf.argmax(labels, 1), tf.argmax(fake_discrimination, 1))\n",
    "            self.disc_loss_train_avg(disc_loss)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.g.model.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.d.middle_piece.trainable_variables)\n",
    "\n",
    "        if train_generator:\n",
    "            self.g.optimizer.apply_gradients(zip(gradients_of_generator, self.g.model.trainable_variables))\n",
    "        if train_discriminator:\n",
    "            self.d.optimizer.apply_gradients(zip(gradients_of_discriminator, self.d.middle_piece.trainable_variables))\n",
    "            \n",
    "    def nudge(self):\n",
    "        nudge = False\n",
    "        if self.no_change_inc >= self.g_nudge_trigger:\n",
    "            nudge = random.random() < self.g_nudge_probability\n",
    "        return nudge\n",
    "    \n",
    "    def refine_discriminator(self, input_datasets, blackbox_labelss, iteration):\n",
    "        assert len(input_datasets) == len(blackbox_labelss)\n",
    "        self.setup_ckpts(iteration)\n",
    "        \n",
    "        # freeze the ends of D\n",
    "        self.d.freeze_ends(True)\n",
    "        \n",
    "        disc_loss_refine_avg = tf.keras.metrics.Mean()\n",
    "        disc_acc_refine_avg = tf.keras.metrics.Accuracy()\n",
    "        optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        for k in range(len(input_datasets)):\n",
    "            # perform for every pair of data:\n",
    "            \n",
    "            input_dataset = input_datasets[k]        # (x, y) --> x: [[ client ... [(id, data) ...]]\n",
    "            blackbox_labels = blackbox_labelss[k]    #               [[ client ... [label_batch ...]]\n",
    "            \n",
    "            x, _ = input_dataset\n",
    "            \n",
    "            client_idxs = list(range(len(x)))\n",
    "            random.shuffle(client_idxs)\n",
    "\n",
    "            for client_idx in client_idxs:\n",
    "\n",
    "                # compare the two using MSE\n",
    "                client_x = x[client_idx]\n",
    "                x_batch = client_x[1]\n",
    "\n",
    "                # run through every minibatch:\n",
    "                j = 0\n",
    "                while(j < len(x_batch)):\n",
    "                    if self.minibatch_size is None:\n",
    "                        # use whole batch (no minibatch)\n",
    "                        x_minibatch = x_batch\n",
    "                        y_minibatch = blackbox_labels[client_idx]\n",
    "                    else:\n",
    "                        x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                        y_minibatch = blackbox_labels[client_idx][j:(j+self.minibatch_size)]\n",
    "                        \n",
    "                    with tf.GradientTape() as refine_tape:\n",
    "                        # predict each minibatch of the input_dataset and match it with its counterpart from the blackbox\n",
    "                        label_batch = self.d.discriminate(x_minibatch)\n",
    "                        refine_loss = self.mse(y_minibatch, label_batch)\n",
    "                        disc_loss_refine_avg(refine_loss)\n",
    "                        disc_acc_refine_avg(tf.argmax(y_minibatch, 1), tf.argmax(label_batch, 1))\n",
    "\n",
    "                    # train the discriminator, one client batch at a time\n",
    "                    gradients_of_discriminator = refine_tape.gradient(refine_loss, self.d.middle_piece.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients_of_discriminator, self.d.middle_piece.trainable_variables))\n",
    "\n",
    "                    if self.minibatch_size is None:\n",
    "                        break\n",
    "                    else:\n",
    "                        j += self.minibatch_size\n",
    "                        \n",
    "        # unfreeze the ends of D\n",
    "        self.d.freeze_ends(False)\n",
    "                    \n",
    "        return disc_loss_refine_avg.result(), disc_acc_refine_avg.result()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def setup_ckpts(self, iteration):\n",
    "        if self.save_ckpts:\n",
    "            # setup fresh checkpointer every new iteration\n",
    "            if self.internal_iteration is None or (self.internal_iteration != (iteration + self.iteration_offset)):\n",
    "                self.internal_iteration = iteration + self.iteration_offset\n",
    "                self.d.setup_ckpt(self.internal_iteration)\n",
    "                self.g.setup_ckpt(self.internal_iteration)\n",
    "    \n",
    "    def checkpoint_d(self):\n",
    "        if self.save_ckpts:\n",
    "            self.d.checkpoint()\n",
    "    \n",
    "    def checkpoint_g(self):\n",
    "        if self.save_ckpts:\n",
    "            self.g.checkpoint()\n",
    "            \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        self.d.restore_pieces(it_restore_ends=it_restore, it_restore_middle=it_restore, load_default=load_default)\n",
    "        self.iteration_offset = self.g.restore(it_restore, load_default)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Early stop\n",
    "        \n",
    "    def early_stop_check(self):\n",
    "        if self.prev_g_acc is not None:\n",
    "            perc_diff = abs(self.gen_acc_train_avg.result() - self.prev_g_acc) / self.prev_g_acc\n",
    "            #print(perc_diff, self.stop_sensitivity)\n",
    "            if perc_diff <= self.stop_sensitivity:\n",
    "                self.no_change_inc += 1\n",
    "                print('> no change inc: {}/{}'.format(self.no_change_inc, self.early_stop_trigger))\n",
    "                if self.no_change_inc >= self.early_stop_trigger:\n",
    "                    self.early_stop = True\n",
    "                    self.no_change_inc = 0\n",
    "            else:\n",
    "                self.no_change_inc = 0\n",
    "\n",
    "        self.prev_g_acc = self.gen_acc_train_avg.result()\n",
    "        \n",
    "    def reset_early_stop(self):\n",
    "        self.no_change_inc = 0\n",
    "        self.prev_g_acc = None\n",
    "        self.best_g_acc = None\n",
    "        self.nudge_flag = False\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "            \n",
    "    def generate_images(self, images=None, labels=None):\n",
    "        # Notice `training` is set to False.\n",
    "        # This is so all layers run in inference mode (batchnorm).\n",
    "        \n",
    "        if images is None:\n",
    "            images = self.g.generate([self.seed, self.eval_labels], training=False)\n",
    "            images = 0.5 * images + 0.5\n",
    "            labels = self.eval_labels\n",
    "        assert images.shape[0] >= 16\n",
    "        assert labels is not None\n",
    "        assert len(labels) == len(images)\n",
    "\n",
    "        categories = [self.g.g_identifier()+str(x) for x in list(range(10))]\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        for i in range(16):\n",
    "            ax = plt.subplot(4, 4, i+1)\n",
    "            if self.is_conditional:\n",
    "                ax.title.set_text(categories[np.argmax(labels[i])])\n",
    "            plt.imshow(images[i, :, :, 0] * 255.0, cmap='gray')\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def generate_dataset(self, batch_num, batch_size, verbose=False):\n",
    "        '''\n",
    "        Generates a list of batches (x_batch, y_batch) to pass into the black-box model\n",
    "        '''\n",
    "        x_batches = []\n",
    "        y_batches = []\n",
    "        for b in range(batch_num):\n",
    "            \n",
    "            # create a list of random ints\n",
    "            seed = tf.random.normal([batch_size, self.noise_dim])\n",
    "            gen_labels = np.random.randint(num_classes, size=batch_size)\n",
    "            y_batch = self.onehot_vals(gen_labels)\n",
    "            \n",
    "            predictions = self.g.generate([seed, y_batch], training=False)\n",
    "            x_batch = 0.5 * predictions + 0.5\n",
    "            \n",
    "            x_batches.append((None, x_batch)) # making into a tuple to match previous dataset scheme\n",
    "            y_batches.append((None, y_batch))\n",
    "            \n",
    "        if verbose:\n",
    "            self.generate_images(x_batches[0][1], y_batches[0][1])\n",
    "        return [x_batches, y_batches]\n",
    "    \n",
    "    def onehot_vals(self, a):\n",
    "        b = np.zeros((a.size, num_classes), dtype=np.float32)\n",
    "        b[np.arange(a.size), a] = 1\n",
    "        return b\n",
    "        \n",
    "    def evaluate_gan(self, dataset):\n",
    "        \n",
    "        if self.gen_acc_train_avg is not None:\n",
    "            print('G Train Acc:     {:.3f} | Loss: {:.3f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                self.gen_loss_train_avg.result()))\n",
    "            print('D Train Acc:     NaN   | Loss: {:.3f}'.format(self.disc_loss_train_avg.result()))\n",
    "        disc_acc_test = self.evaluate_discriminator(dataset)\n",
    "        \n",
    "        # define plotting metrics\n",
    "        self.gen_loss_train_arr.append(self.gen_loss_train_avg.result())\n",
    "        self.gen_acc_train_arr.append(self.gen_acc_train_avg.result())\n",
    "        self.disc_loss_train_arr.append(self.disc_loss_train_avg.result())\n",
    "        self.disc_acc_test_arr.append(disc_acc_test)\n",
    "        \n",
    "        return disc_acc_test\n",
    "        \n",
    "    def evaluate_discriminator(self, dataset, verbose=True):\n",
    "        \n",
    "        x, y = dataset\n",
    "        \n",
    "        acc_test_avg = tf.keras.metrics.Accuracy()\n",
    "        loss_test_avg = tf.keras.metrics.Mean()\n",
    "        for i in range(0, len(x), self.batch_size):\n",
    "            # get batch\n",
    "            x_batch = x[i:i+self.batch_size]\n",
    "            y_batch = y[i:i+self.batch_size]\n",
    "            \n",
    "            # evaluate\n",
    "            logits = self.d.discriminate(x_batch, training=False)\n",
    "            acc_test_avg(tf.argmax(y_batch, 1), tf.argmax(logits, 1))\n",
    "            loss_test_avg(self.d.entropy(y_batch, logits))\n",
    "            \n",
    "        if verbose:\n",
    "            print('D Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test_avg.result(), loss_test_avg.result()))\n",
    "            print()\n",
    "        \n",
    "        return acc_test_avg.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class uGAN:\n",
    "    '''\n",
    "    The uGAN. Trains the uG. uG can be either conditional or not conditional.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, is_conditional=True, start_piece=None, middle_piece=None, end_piece=None):\n",
    "        self.is_conditional = is_conditional\n",
    "        \n",
    "        self.extra_depth = gan_training_params['extra_depth']\n",
    "        self.noise_dim = gan_training_params['noise_dim']\n",
    "        self.batch_size = gan_training_params['batch_size']\n",
    "        self.batches_per_epoch = gan_training_params['batches_per_epoch']\n",
    "        self.early_stop_trigger = gan_training_params['early_stop_trigger']\n",
    "        self.stop_sensitivity = gan_training_params['stop_sensitivity']\n",
    "\n",
    "        # define the D and G models (D comes from cGAN)\n",
    "        self.g = G(gan_training_params, is_conditional=self.is_conditional, identifier='u_', extra_depth=self.extra_depth)\n",
    "        self.d = D(gan_training_params, start_piece, middle_piece, end_piece)\n",
    "            \n",
    "        # stack G on top of D\n",
    "        self.gd = self.stack_models()\n",
    "        print(self.gd.summary())\n",
    "        \n",
    "        # define metrics\n",
    "        self.gen_loss_train_avg = None\n",
    "        self.gen_acc_train_avg = None\n",
    "        \n",
    "        # define plotting metrics\n",
    "        self.gen_loss_train_arr = []\n",
    "        self.gen_acc_train_arr = []\n",
    "        \n",
    "        # seed for image generation\n",
    "        num_examples_to_generate = 16\n",
    "        self.seed = tf.random.normal([num_examples_to_generate, self.noise_dim])\n",
    "        \n",
    "        # labels for image generation\n",
    "        label_pattern = [i % (num_classes) for i in range(num_examples_to_generate)]\n",
    "        self.eval_labels = tf.one_hot(label_pattern, num_classes, dtype=tf.dtypes.float32)\n",
    "        \n",
    "        # setup checkpointing\n",
    "        self.internal_iteration = None\n",
    "        self.iteration_offset = 0\n",
    "        self.save_ckpts = True\n",
    "        \n",
    "        # initialize d and g checkpoints\n",
    "        self.g.init_ckpt()\n",
    "        \n",
    "        # setup early stop metrics\n",
    "        self.early_stop = False\n",
    "        self.no_change_inc = 0\n",
    "        self.prev_g_acc = None\n",
    "        self.best_g_acc = None\n",
    "        self.nudge_flag = False\n",
    "        \n",
    "    def stack_models(self):\n",
    "        inputs = []\n",
    "        for input_shape in self.g.input_shapes:\n",
    "            inputs.append(keras.layers.Input(input_shape))\n",
    "        \n",
    "        outputG = self.g.model(inputs)\n",
    "        \n",
    "        # output of G needs to be converted from [-1, 1] to [0, 1] spectrum\n",
    "        outputG_converted = 0.5 * outputG + 0.5\n",
    "        \n",
    "        outputD = self.d.model(outputG_converted)\n",
    "        \n",
    "        model = keras.models.Model(inputs=inputs, outputs=outputD)\n",
    "        model._name = \"ugan_model\"\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Trainer\n",
    "        \n",
    "    def train(self, iteration, save_best=False):\n",
    "        # setup checkpointing\n",
    "        self.setup_ckpts(iteration)\n",
    "        \n",
    "        # initialize the metrics each new epoch\n",
    "        if self.gen_acc_train_avg is not None:\n",
    "            del self.gen_acc_train_avg\n",
    "        if self.gen_loss_train_avg is not None:\n",
    "            del self.gen_loss_train_avg\n",
    "        \n",
    "        self.gen_loss_train_avg = tf.keras.metrics.Mean()\n",
    "        if self.is_conditional:\n",
    "            self.gen_acc_train_avg = tf.keras.metrics.Accuracy()\n",
    "        \n",
    "        pbar = tqdm_notebook(total=self.batches_per_epoch)\n",
    "        \n",
    "        for i in range(self.batches_per_epoch):\n",
    "            # logic for training the generator\n",
    "            train_generator = True\n",
    "            \n",
    "            if self.is_conditional:\n",
    "                self.c_train_step(train_generator=train_generator)\n",
    "                pbar.update(1)\n",
    "                pbar.set_description('g_acc={:.2f}, g_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                                          self.gen_loss_train_avg.result()))\n",
    "            else:\n",
    "                self.u_train_step(train_generator=train_generator)\n",
    "                pbar.update(1)\n",
    "                pbar.set_description('g_loss={:.8f}'.format(self.gen_loss_train_avg.result()))\n",
    "        \n",
    "        if self.is_conditional:\n",
    "            print('g_acc={:.2f}, g_loss={:.2f}'.format(self.gen_acc_train_avg.result(),\n",
    "                                                       self.gen_loss_train_avg.result()))\n",
    "        else:\n",
    "            print('g_loss={:.2f}'.format(self.gen_loss_train_avg.result()))\n",
    "        \n",
    "        # save checkpoints\n",
    "        if save_best:\n",
    "            if self.is_conditional:\n",
    "                if self.best_g_acc is None or self.gen_acc_train_avg.result() >= self.best_g_acc:\n",
    "                    self.best_g_acc = self.gen_acc_train_avg.result()\n",
    "                    self.checkpoint_g()\n",
    "            else:\n",
    "                # TODO: maybe make a best_ug_loss?\n",
    "                self.checkpoint_g()\n",
    "        else:\n",
    "            self.checkpoint_g()\n",
    "        \n",
    "        # check for early stop\n",
    "        self.early_stop_check()\n",
    "    \n",
    "    def c_train_step(self, train_generator):\n",
    "        noise = tf.random.normal([self.batch_size, self.noise_dim])\n",
    "        random_classes = tf.random.uniform(shape=(self.batch_size, ), maxval=num_classes, dtype=tf.dtypes.int32)\n",
    "        labels = tf.one_hot(random_classes, num_classes, dtype=tf.dtypes.float32)\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            fake_discrimination = self.gd([noise, labels], training=train_generator)\n",
    "\n",
    "            gen_loss = self.g.u_loss(fake_discrimination) + self.g.loss(fake_discrimination, labels)\n",
    "            \n",
    "            # evaluate accuracy and append acc and loss to arrays\n",
    "            self.gen_loss_train_avg(gen_loss)\n",
    "            self.gen_acc_train_avg(tf.argmax(labels, 1), tf.argmax(fake_discrimination, 1))\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.g.model.trainable_variables)\n",
    "\n",
    "        if train_generator:\n",
    "            self.g.optimizer.apply_gradients(zip(gradients_of_generator, self.g.model.trainable_variables))\n",
    "    \n",
    "    def u_train_step(self, train_generator):\n",
    "        '''\n",
    "        Train G, knowing we are trying to generate the most appropriate dataset to pass to BB\n",
    "        '''\n",
    "        noise = tf.random.normal([self.batch_size, self.noise_dim])\n",
    "        random_classes = tf.random.uniform(shape=(self.batch_size, ), maxval=num_classes, dtype=tf.dtypes.int32)\n",
    "\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            fake_discrimination = self.gd(noise, training=train_generator)\n",
    "\n",
    "            gen_loss = self.g.u_loss(fake_discrimination)\n",
    "            \n",
    "            # evaluate accuracy and append acc and loss to arrays\n",
    "            self.gen_loss_train_avg(gen_loss)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.g.model.trainable_variables)\n",
    "\n",
    "        if train_generator:\n",
    "            self.g.optimizer.apply_gradients(zip(gradients_of_generator, self.g.model.trainable_variables))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def setup_ckpts(self, iteration):\n",
    "        if self.save_ckpts:\n",
    "            # setup fresh checkpointer every new iteration\n",
    "            if self.internal_iteration is None or (self.internal_iteration != (iteration + self.iteration_offset)):\n",
    "                self.internal_iteration = iteration + self.iteration_offset\n",
    "                self.g.setup_ckpt(self.internal_iteration)\n",
    "    \n",
    "    def checkpoint_g(self):\n",
    "        if self.save_ckpts:\n",
    "            self.g.checkpoint()\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        self.iteration_offset = self.g.restore(it_restore, load_default)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Early stop\n",
    "        \n",
    "    def early_stop_check(self):\n",
    "        if self.is_conditional:\n",
    "            if self.prev_g_acc is not None:\n",
    "                perc_diff = abs(self.gen_acc_train_avg.result() - self.prev_g_acc) / self.prev_g_acc\n",
    "                #print(perc_diff, self.stop_sensitivity)\n",
    "                if perc_diff <= self.stop_sensitivity:\n",
    "                    self.no_change_inc += 1\n",
    "                    print('> no change inc: {}/{}'.format(self.no_change_inc, self.early_stop_trigger))\n",
    "                    if self.no_change_inc >= self.early_stop_trigger:\n",
    "                        self.early_stop = True\n",
    "                        self.no_change_inc = 0\n",
    "                else:\n",
    "                    self.no_change_inc = 0\n",
    "\n",
    "            self.prev_g_acc = self.gen_acc_train_avg.result()\n",
    "        else:\n",
    "            # TODO: maybe make a prev_ug_loss?\n",
    "            pass\n",
    "        \n",
    "    def reset_early_stop(self):\n",
    "        self.no_change_inc = 0\n",
    "        self.prev_g_acc = None\n",
    "        self.best_g_acc = None\n",
    "        self.nudge_flag = False\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "            \n",
    "    def generate_images(self, predictions=None, labels=None):\n",
    "        # Notice `training` is set to False.\n",
    "        # This is so all layers run in inference mode (batchnorm).\n",
    "        \n",
    "        if predictions is None:\n",
    "            predictions = self.g.generate([self.seed, self.eval_labels], training=False)\n",
    "            predictions = 0.5 * predictions + 0.5\n",
    "            labels = self.eval_labels\n",
    "        assert predictions.shape[0] >= 16\n",
    "        assert labels is not None\n",
    "        assert len(labels) == len(predictions)\n",
    "\n",
    "        if self.is_conditional:\n",
    "            categories = [self.g.g_identifier()+str(x) for x in list(range(10))]\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        for i in range(16):\n",
    "            ax = plt.subplot(4, 4, i+1)\n",
    "            if self.is_conditional:\n",
    "                ax.title.set_text(categories[np.argmax(labels[i])])\n",
    "            plt.imshow(predictions[i, :, :, 0] * 255.0, cmap='gray')\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def generate_dataset(self, batch_num, batch_size, verbose=False):\n",
    "        '''\n",
    "        Generates a list of batches (x_batch, y_batch) to pass into the black-box model\n",
    "        '''\n",
    "        x_batches = []\n",
    "        y_batches = []\n",
    "        for b in range(batch_num):\n",
    "            \n",
    "            # create a list of random ints\n",
    "            seed = tf.random.normal([batch_size, self.noise_dim])\n",
    "            gen_labels = np.random.randint(num_classes, size=batch_size)\n",
    "            y_batch = self.onehot_vals(gen_labels)\n",
    "            \n",
    "            if self.is_conditional:\n",
    "                predictions = self.g.generate([seed, y_batch], training=False)\n",
    "            else:\n",
    "                predictions = self.g.generate(seed, training=False)\n",
    "            x_batch = 0.5 * predictions + 0.5\n",
    "            \n",
    "            x_batches.append((None, x_batch)) # making into a tuple to match previous dataset scheme\n",
    "            y_batches.append((None, y_batch))\n",
    "            \n",
    "        if verbose:\n",
    "            self.generate_images(x_batches[0][1], y_batches[0][1])\n",
    "        return [x_batches, y_batches]\n",
    "    \n",
    "    def onehot_vals(self, a):\n",
    "        b = np.zeros((a.size, num_classes), dtype=np.float32)\n",
    "        b[np.arange(a.size), a] = 1\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGSM:\n",
    "    '''\n",
    "    The FGSM trainer. Generates better images to be used in the cGAN\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, fgsm_training_params, d):\n",
    "        \n",
    "        self.epsilon = fgsm_training_params['epsilon']\n",
    "        self.norm = fgsm_training_params['norm']\n",
    "        \n",
    "        # D must be the one we are using in the cGAN (because that's the D we are refining)\n",
    "        assert d is not None and type(d) is D\n",
    "        self.d = d\n",
    "        # self.d = D(fgsm_training_params, start_piece=d.start_piece, middle_piece=d.middle_piece, end_piece=d.end_piece)\n",
    "        \n",
    "        # define losses\n",
    "        self.cross_entropy = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Trainer\n",
    "    \n",
    "    def augment_dataset(self, input_datasets, blackbox_labelss, iteration):\n",
    "        assert len(input_datasets) == len(blackbox_labelss)\n",
    "        \n",
    "        # freeze the ends of D\n",
    "        self.d.freeze_ends(True)\n",
    "        \n",
    "        disc_loss_refine_avg = tf.keras.metrics.Mean()\n",
    "        disc_acc_refine_avg = tf.keras.metrics.Accuracy()\n",
    "        optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # Set the parameter epsilon = 0.5 for FGSM (Only alter the first 5 terms , X0~X4)\n",
    "        print (\"Fast Gradient Sign Method based on {} norm\".format(self.norm))\n",
    "        g_x_batches = []\n",
    "        g_y_batches = []\n",
    "        for k in tqdm_notebook(range(len(input_datasets))):\n",
    "            # perform for every pair of data:\n",
    "            \n",
    "            input_dataset = input_datasets[k]        # (x, y) --> x: [[ client ... [(id, data) ...]]\n",
    "            blackbox_labels = blackbox_labelss[k]    #               [[ client ... [label_batch ...]]\n",
    "            \n",
    "            x, y = input_dataset\n",
    "\n",
    "            # compare the two using MSE\n",
    "            for i, client_x in enumerate(x):\n",
    "                x_batch = x[i][1]\n",
    "                \n",
    "                g_x_batch = []\n",
    "                g_y_batch = []\n",
    "                # print(g_x_batch.shape, y[i][1].shape)\n",
    "                \n",
    "                for j in range(x_batch.shape[0]):\n",
    "                    \n",
    "                    x_ = tf.convert_to_tensor(np.expand_dims(x_batch[j], axis=0), np.float32)\n",
    "                    y_ = np.expand_dims(blackbox_labels[i][j], axis=0)\n",
    "                    \n",
    "                    with tf.GradientTape() as tape:\n",
    "                        tape.watch(x_)\n",
    "                        prediction = self.d.discriminate(x_)\n",
    "                        loss = self.cross_entropy(y_, prediction)\n",
    "                        \n",
    "                        disc_loss_refine_avg(loss)\n",
    "                        disc_acc_refine_avg(tf.argmax(y_, 1), tf.argmax(prediction, 1))\n",
    "                        \n",
    "                    # Get the gradients of the loss w.r.t to the input image.\n",
    "                    grad = tape.gradient(loss, x_)\n",
    "                    \n",
    "                    if self.norm == 'L1':\n",
    "                        grad = grad/(sum(abs(grad)))\n",
    "                    elif self.norm == 'Inf':\n",
    "                        grad = tf.sign(grad)\n",
    "                    else:\n",
    "                        raise Exception('L-norm not recognized')\n",
    "                        \n",
    "                    if not np.any(np.isnan(grad.numpy())):\n",
    "                        # Append the augmented image to the list (only if all elements in grad are not NaN)\n",
    "                        g_x_batch.append((np.expand_dims(x_batch[j], axis=0) + self.epsilon * grad.numpy())[0])\n",
    "                        g_y_batch.append(y[i][1][j])\n",
    "                    \n",
    "                if len(g_x_batch) > 0:\n",
    "                    g_x_batches.append((None, np.array(g_x_batch)))\n",
    "                    g_y_batches.append((None, np.array(g_y_batch)))\n",
    "            \n",
    "        # unfreeze the ends of D\n",
    "        self.d.freeze_ends(False)\n",
    "            \n",
    "        return (g_x_batches, g_y_batches)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False):\n",
    "        self.iteration_offset = self.d.restore(it_restore, load_default, use_blackbox=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemTrainer:\n",
    "    \n",
    "    def __init__(self, split_training_params, cgan_training_params, ugan_training_params, fgsm_training_params, attack_params):\n",
    "        # Datasets:\n",
    "        self.split_train_dataset = split_training_params['train_dataset']\n",
    "        assert self.split_train_dataset is not None\n",
    "        self.split_test_dataset = split_training_params['test_dataset']\n",
    "        assert self.split_test_dataset is not None\n",
    "        self.attack_train_dataset = attack_params['train_dataset']\n",
    "        assert self.attack_train_dataset is not None\n",
    "        \n",
    "        # Split Learning params:\n",
    "        self.split_epochs = split_training_params['epochs']\n",
    "        self.split_batch_limit = split_training_params['batch_limit']\n",
    "        \n",
    "        # GAN params:\n",
    "        self.cgan_training_params = cgan_training_params\n",
    "        self.fgsm_training_params = fgsm_training_params\n",
    "        \n",
    "        self.cgan_epochs = cgan_training_params['epochs']\n",
    "        self.use_blackbox= cgan_training_params['use_blackbox']\n",
    "        self.d_reset_percentage = cgan_training_params['d_reset_percentage']\n",
    "        self.d_priming_epoch_limit = cgan_training_params['d_priming_epoch_limit']\n",
    "        self.d_refine_epoch_limit = cgan_training_params['d_refine_epoch_limit']\n",
    "        self.save_best_cg = cgan_training_params['save_best_g']\n",
    "        self.reset_c_g_every_it = cgan_training_params['reset_g_every_it']\n",
    "        self.counter_nudge = cgan_training_params['counter_nudge']\n",
    "        \n",
    "        # Attack params:\n",
    "        self.prime_first_iteration = attack_params['prime_first_iteration']\n",
    "        self.prime_exit_trigger = attack_params['prime_exit_trigger']\n",
    "        self.prime_cgan_by_ckpt = attack_params['prime_cgan_by_ckpt']\n",
    "        self.refine_exit_trigger = attack_params['refine_exit_trigger']\n",
    "        self.prime_trigger = attack_params['prime_trigger']\n",
    "        self.prime_by_ckpt = attack_params['prime_by_ckpt']\n",
    "        self.attack_trigger = attack_params['attack_trigger']\n",
    "        self.attack_classes = attack_params['attack_classes']\n",
    "        self.d_refinement_batch_num = attack_params['d_refinement_batch_num']\n",
    "        self.d_refinement_batch_size = attack_params['d_refinement_batch_size']\n",
    "        self.train_bb_every_n_its = attack_params['train_bb_every_n_its']\n",
    "        self.cgan_query_every_n_its = attack_params['cgan_query_every_n_its']\n",
    "        self.accumulate_g_queries = attack_params['accumulate_g_queries']\n",
    "        self.flush_g_queries_every_bb_train = attack_params['flush_g_queries_every_bb_train']\n",
    "        self.refine_using_fgsm = attack_params['refine_using_fgsm']\n",
    "        self.reset_g_every_bb_train = attack_params['reset_g_every_bb_train']\n",
    "        \n",
    "        self.ugan_training_params = ugan_training_params\n",
    "        self.ugan_epochs = ugan_training_params['epochs']\n",
    "        self.ugan_is_conditional = ugan_training_params['is_conditional']\n",
    "        self.reset_u_g_every_it = ugan_training_params['reset_g_every_it']\n",
    "        self.refine_using_ugan = attack_params['refine_using_ugan']\n",
    "        \n",
    "        # create the Split Learning Trainer\n",
    "        self.split = SplitLearning(split_training_params)\n",
    "        \n",
    "        # create the cGAN Trainer\n",
    "        if not self.use_blackbox:\n",
    "            # treat the Split Learning NN as a Black-box\n",
    "            self.cgan = cGAN(cgan_training_params, start_piece=self.split.start_piece, end_piece=self.split.end_piece)\n",
    "        else:\n",
    "            # use the Split Learning NN as the GAN's Discriminator as an easy check:\n",
    "            self.cgan = cGAN(cgan_training_params, start_piece=self.split.start_piece, middle_piece=self.split.middle_piece,\n",
    "                             end_piece=self.split.end_piece)\n",
    "            \n",
    "        if self.refine_using_fgsm:\n",
    "            self.fgsm = FGSM(fgsm_training_params, self.cgan.d)\n",
    "        else:\n",
    "            self.fgsm = None\n",
    "            \n",
    "        # create uGAN Trainer, depend on cGAN's D\n",
    "        if self.refine_using_ugan:\n",
    "            # when trained, will use u_loss instead of loss\n",
    "            self.ugan = uGAN(ugan_training_params, is_conditional=self.ugan_is_conditional, start_piece=self.cgan.d.start_piece, \n",
    "                             middle_piece=self.cgan.d.middle_piece, end_piece=self.cgan.d.end_piece)\n",
    "            \n",
    "        # create metric accumulaters\n",
    "        self.g_acc = [None]\n",
    "        self.bb_acc = [None]\n",
    "        self.d_acc = []\n",
    "        self.bb_ong_acc = [None]\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Training\n",
    "    \n",
    "    def rand_bin_array(self, K, N):\n",
    "        arr = np.zeros(N)\n",
    "        arr[..., :K]  = 1\n",
    "        np.random.shuffle(arr)\n",
    "        return arr\n",
    "        \n",
    "    def train_system(self):\n",
    "        '''\n",
    "        Train the entire system, updating D while performing Split Learning, and train GAN until ready for attack\n",
    "        '''\n",
    "        \n",
    "        iteration = 0\n",
    "        previous_g_datasets = [] # [g_dataset ...] \n",
    "        while(True):\n",
    "            self.save_metrics()\n",
    "            \n",
    "            # Increment the iteration count:\n",
    "            iteration += 1\n",
    "            print('*'*40)\n",
    "            print('Iteration {}'.format(iteration))\n",
    "            print()\n",
    "        \n",
    "            # Prime the Black-box and D models (normal client, normal training):\n",
    "            d_acc = self.cgan.evaluate_discriminator(self.split_test_dataset, verbose=True)\n",
    "            if d_acc < self.prime_trigger or (self.prime_first_iteration and iteration == 1):\n",
    "                if self.prime_by_ckpt:\n",
    "                    # prime BB and D by loading in their default checkpoints\n",
    "                    self.split.restore(load_default=True)\n",
    "                    self.cgan.d.restore_pieces(load_default=True)\n",
    "                    \n",
    "                    print('o'*40)\n",
    "                    print('SKIPPED STEPS 1 & 2: Primed by checkpoint')\n",
    "                    print('o'*40)\n",
    "                    print()\n",
    "                else:\n",
    "                    ########################################################################\n",
    "                    # Step 1: \"Prime\" the Split Learning model if the model is not trained enough:\n",
    "                    print('~'*40)\n",
    "                    print('Step 1: Priming Split Learning')\n",
    "                    for e in tqdm_notebook(range(self.split_epochs)):\n",
    "                        print('-'*20)\n",
    "                        print('Epoch {}/{}'.format(e+1, self.split_epochs))\n",
    "                        # the attacker is pretending to be a normal client:\n",
    "                        self.split.train([self.split_train_dataset, self.attack_train_dataset], iteration, \n",
    "                                         batch_limit=self.split_batch_limit)\n",
    "                        self.split.evaluate(self.split_test_dataset)\n",
    "\n",
    "                    ########################################################################\n",
    "                    # Step 2: \"Prime\" D:\n",
    "                    print('~'*40)\n",
    "                    print('Step 2: Priming D')\n",
    "\n",
    "                    blackbox_labels = self.split.predict(self.attack_train_dataset)\n",
    "\n",
    "                    pbar = tqdm_notebook(total=self.d_priming_epoch_limit)\n",
    "                    d_prime_acc = None\n",
    "                    prime_inc = 0\n",
    "                    while (d_prime_acc is None or d_prime_acc < self.prime_exit_trigger) and prime_inc < self.d_priming_epoch_limit:\n",
    "                        d_refine_loss, d_prime_acc = self.cgan.refine_discriminator([self.attack_train_dataset], \n",
    "                                                                                    [blackbox_labels],\n",
    "                                                                                    iteration)\n",
    "                        pbar.set_description('d_prime_acc: {:.3f}'.format(d_prime_acc))\n",
    "                        pbar.update(1)\n",
    "                        prime_inc += 1\n",
    "                    pbar.close()\n",
    "                    \n",
    "                    # save checkpoints\n",
    "                    self.cgan.checkpoint_d()\n",
    "                    print('d_prime_acc: {:.3f}'.format(d_prime_acc))\n",
    "\n",
    "                # do not proceed if D is not close enough to the Split Learning model:\n",
    "                d_acc = self.cgan.evaluate_discriminator(self.split_test_dataset, verbose=True)\n",
    "                # Accumulate D Accuracy (starts at it 0)\n",
    "                self.d_acc.append(d_acc.numpy())\n",
    "                if d_acc < self.prime_trigger:\n",
    "                    # D is not trained enough, we will train the Black-box model more and then prime D again\n",
    "                    self.cgan.d.load_initial_weights()\n",
    "                    continue\n",
    "            else:\n",
    "                print('x'*40)\n",
    "                print('SKIPPED STEPS 1 & 2')\n",
    "                print('x'*40)\n",
    "                print()\n",
    "                \n",
    "                # Accumulate D Accuracy\n",
    "                self.d_acc.append(d_acc.numpy())\n",
    "\n",
    "            ################################################################################\n",
    "            # Step 3: Train GAN(s) on D:\n",
    "            if (iteration-1) % self.cgan_query_every_n_its == 0:\n",
    "                if (iteration-1 == 0) and self.prime_cgan_by_ckpt:\n",
    "                    self.cgan.restore(load_default=True)\n",
    "                    print('o'*40)\n",
    "                    print('SKIPPED STEP 3: Primed by checkpoint')\n",
    "                    print('o'*40)\n",
    "                    print()\n",
    "                else:\n",
    "                    if self.refine_using_ugan:\n",
    "                        print('~'*40)\n",
    "                        print('Step 3.1: Training uG')\n",
    "                        print(' - performed until uG converges with the current D')\n",
    "                        self.ugan.reset_early_stop()\n",
    "                        for e in tqdm_notebook(range(self.ugan_epochs)):\n",
    "                            print('-'*20)\n",
    "                            print('Epoch {}/{}'.format(e+1, self.ugan_epochs))\n",
    "                            self.ugan.train(iteration, save_best=False)\n",
    "                            self.ugan.generate_images()\n",
    "\n",
    "                            if self.get_early_stop_check(self.ugan):\n",
    "                                print('** Early stop! **')\n",
    "                                print()\n",
    "                                break\n",
    "                                \n",
    "                    print('~'*40)\n",
    "                    print('Step 3.2: Training cG')\n",
    "                    print(' - performed until cG converges with the current D')\n",
    "                    self.cgan.reset_early_stop()\n",
    "                    for e in tqdm_notebook(range(self.cgan_epochs)):\n",
    "                        print('-'*20)\n",
    "                        print('Epoch {}/{}'.format(e+1, self.cgan_epochs))\n",
    "                        just_nudged = self.cgan.train(iteration, save_best=self.save_best_cg)\n",
    "                        self.cgan.generate_images()\n",
    "                        \n",
    "                        stop_early = self.get_early_stop_check(self.cgan)\n",
    "                        if stop_early or e == self.cgan_epochs - 1:\n",
    "                            if just_nudged and self.counter_nudge:\n",
    "                                print('** Extra training to counter nudge **')\n",
    "                                self.cgan.train(iteration, save_best=self.save_best_cg)\n",
    "\n",
    "                        if stop_early:\n",
    "                            print('** Early stop! **')\n",
    "                            print()\n",
    "                            break\n",
    "                            \n",
    "                    # Accumulate G Accuracy\n",
    "                    self.g_acc.append(self.cgan.gen_acc_train_avg.result().numpy())\n",
    "\n",
    "                    # reload G with the best weights we found during training:\n",
    "                    if self.save_best_cg:\n",
    "                        self.cgan.g.restore(it_restore=iteration)\n",
    "                        self.cgan.generate_images()\n",
    "            else:\n",
    "                print('x'*40)\n",
    "                print('SKIPPED STEP 3')\n",
    "                print('x'*40)\n",
    "                print()\n",
    "                \n",
    "                # Accumulate G Accuracy\n",
    "                self.g_acc.append(None)\n",
    "                    \n",
    "            ################################################################################\n",
    "            # Step 4: Train Split Learning, but now add images from G\n",
    "            print('~'*40)\n",
    "            print('Step 4: Training Split Learning (and gathering Black-box labels)')\n",
    "            \n",
    "            if self.refine_using_ugan:\n",
    "                # the attacker weaves their images into the Black-box training step:\n",
    "                ug_dataset = self.ugan.generate_dataset(batch_num=self.d_refinement_batch_num,\n",
    "                                                        batch_size=self.d_refinement_batch_size, verbose=True)\n",
    "                g_dataset = ug_dataset\n",
    "\n",
    "                if (iteration-1) % self.cgan_query_every_n_its == 0:\n",
    "                    cg_dataset = self.cgan.generate_dataset(batch_num=self.d_refinement_batch_num,\n",
    "                                                            batch_size=self.d_refinement_batch_size, verbose=True)\n",
    "                    # append the two g_datasets together\n",
    "                    g_dataset[0] = g_dataset[0] + cg_dataset[0]\n",
    "                    g_dataset[1] = g_dataset[1] + cg_dataset[1]\n",
    "            else:\n",
    "                # the attacker weaves their images into the Black-box training step:\n",
    "                if (iteration-1) % self.cgan_query_every_n_its == 0:\n",
    "                    g_dataset = self.cgan.generate_dataset(batch_num=self.d_refinement_batch_num,\n",
    "                                                           batch_size=self.d_refinement_batch_size, verbose=True)\n",
    "                else:\n",
    "                    g_dataset = None\n",
    "                \n",
    "            # ** append all previous g_datasets into one\n",
    "            if self.accumulate_g_queries:\n",
    "                # append the previous g_dataset:\n",
    "                if g_dataset is not None:\n",
    "                    previous_g_datasets.append(g_dataset)\n",
    "                \n",
    "                for prev_d, prev_dataset in enumerate(previous_g_datasets):\n",
    "                    if prev_d == 0:\n",
    "                        g_dataset = deepcopy(prev_dataset)\n",
    "                    else:\n",
    "                        g_dataset[0] = g_dataset[0] + prev_dataset[0]\n",
    "                        g_dataset[1] = g_dataset[1] + prev_dataset[1]\n",
    "                \n",
    "            print('{} datasets gathered\\n'.format(len(previous_g_datasets)))\n",
    "            \n",
    "            # generate a mask, where '1' represents samples the server will interfere with, and '0' represents samples\n",
    "            # the server will leave alone\n",
    "            interfere_mask = self.rand_bin_array(K=int(mitigation_params['percent_to_drop']*self.d_refinement_batch_size),\n",
    "                                                 N=(1, self.d_refinement_batch_num, 1, self.d_refinement_batch_size))\n",
    "#             print(np.sum(interfere_mask[interfere_mask == 1]) / interfere_mask.size)\n",
    "            \n",
    "            if iteration % self.train_bb_every_n_its == 0:\n",
    "                queried_dataset = self.split.train([self.split_train_dataset, self.attack_train_dataset], iteration, \n",
    "                                                   g_dataset=g_dataset, mask=interfere_mask)\n",
    "                \n",
    "                # Accumulate the BB Accuracy \n",
    "                bb_acc = self.split.acc_train_avg.result()\n",
    "                self.bb_acc.append(bb_acc.numpy())\n",
    "                \n",
    "                if self.flush_g_queries_every_bb_train:\n",
    "                    previous_g_datasets = []\n",
    "                if self.reset_g_every_bb_train:\n",
    "                    self.cgan.g.load_initial_weights()\n",
    "            else:\n",
    "                # do not train bb - only get the queried labels\n",
    "                print('only querying this iteration')\n",
    "                self.bb_acc.append(None)\n",
    "                queried_dataset = self.split.train(datasets=[], iteration=iteration, g_dataset=g_dataset, mask=interfere_mask)\n",
    "            raise Exception('!')\n",
    "            \n",
    "            # do not proceed if D is not close enough to the Split Learning model:\n",
    "            d_acc = self.cgan.evaluate_discriminator(self.split_test_dataset, verbose=False)\n",
    "            if d_acc < self.attack_trigger:\n",
    "                ###########################################################################\n",
    "                # Step 5: Refine D using the blackbox_labels we gathered and the dataset that we have available to us\n",
    "                print('~'*40)\n",
    "                print('Step 5.1: Gathering queries')\n",
    "                \n",
    "                # blackbox labels from our original dataset, \"stored\" when performing Step 4\n",
    "                blackbox_labels = self.split.predict(self.attack_train_dataset)\n",
    "                \n",
    "                # REDO g_dataset IN THE ORDER of what was queried\n",
    "                g_dataset = ([(None, x[0]) for x in queried_dataset], [(None, x[1]) for x in queried_dataset])\n",
    "                queried_labels = [x[2] for x in queried_dataset]\n",
    "\n",
    "                datasets = [self.attack_train_dataset] + [g_dataset]\n",
    "                labels = [blackbox_labels] + [queried_labels]\n",
    "                \n",
    "                ###########################\n",
    "                # FGSM\n",
    "                \n",
    "                if self.fgsm is not None:\n",
    "                    augmented_dataset = self.fgsm.augment_dataset(datasets, labels, iteration)\n",
    "                    \n",
    "                    # query using the augmented set:\n",
    "                    print('~'*40)\n",
    "                    print('Step 5.2: Gathering Blackbox labels for the augmented images')\n",
    "                    aug_sample_x = augmented_dataset[0][-1][1][0:16]\n",
    "                    aug_sample_y = augmented_dataset[1][-1][1][0:16]\n",
    "                    self.cgan.generate_images(aug_sample_x, aug_sample_y)\n",
    "\n",
    "                    queried_augmented_datasets = self.split.train(datasets=[], iteration=iteration, g_dataset=augmented_dataset)\n",
    "                    # REDO g_dataset IN THE ORDER of what was queried\n",
    "                    augmented_dataset = ([(None, x[0]) for x in queried_augmented_datasets], \n",
    "                                         [(None, x[1]) for x in queried_augmented_datasets])\n",
    "                    augmented_labels = [x[2] for x in queried_augmented_datasets]\n",
    "\n",
    "                    # add the original samples to the augmented dataset:\n",
    "                    datasets = [augmented_dataset] + datasets\n",
    "                    labels = [augmented_labels] + labels\n",
    "                else:\n",
    "                    assert self.refine_using_fgsm is False\n",
    "                \n",
    "                ###########################\n",
    "                \n",
    "                print('~'*40)\n",
    "                print('Step 5.3: Refining D')\n",
    "                pbar = tqdm_notebook(total=self.d_refine_epoch_limit)\n",
    "                d_refine_acc = None\n",
    "                refine_inc = 0\n",
    "                while (d_refine_acc is None or d_refine_acc < self.refine_exit_trigger) and refine_inc < self.d_refine_epoch_limit:\n",
    "                    d_refine_loss, d_refine_acc = self.cgan.refine_discriminator(datasets, labels, iteration)\n",
    "                    pbar.set_description('d_refine_acc: {:.3f}'.format(d_refine_acc))\n",
    "                    pbar.update(1)\n",
    "                    refine_inc += 1\n",
    "                pbar.close()\n",
    "                print('d_refine_acc: {:.3f}'.format(d_refine_acc))\n",
    "                \n",
    "                # gather statistics on how well G is able to trick BB:\n",
    "                print()\n",
    "                print('Split accuracy on G dataset:')\n",
    "                dset = self.cgan.generate_dataset(batch_num=self.d_refinement_batch_num,\n",
    "                                                  batch_size=self.d_refinement_batch_size, verbose=False)\n",
    "                bb_ong_acc = self.split.evaluate((dset[0][-1][1], dset[1][-1][1]))\n",
    "                self.bb_ong_acc.append(bb_ong_acc.numpy())\n",
    "                print()\n",
    "            \n",
    "                # do not proceed if D is not close enough to the Split Learning model:\n",
    "                d_acc = self.cgan.evaluate_discriminator(self.split_test_dataset, verbose=True)\n",
    "                if d_acc < self.attack_trigger:\n",
    "                    # D is not trained enough, we will train the Black-box model more and continue refining D\n",
    "                    if self.reset_c_g_every_it:\n",
    "                        self.cgan.g.load_initial_weights()\n",
    "                        \n",
    "                    if self.reset_u_g_every_it and self.refine_using_ugan:\n",
    "                        self.ugan.g.load_initial_weights()\n",
    "                    continue\n",
    "            else:\n",
    "                print('x'*40)\n",
    "                print('SKIPPED STEP 5')\n",
    "                print('x'*40)\n",
    "                print()\n",
    "            continue\n",
    "                \n",
    "            print('All done!')\n",
    "            break\n",
    "    \n",
    "    def get_early_stop_check(self, gan):\n",
    "        '''\n",
    "        Check if any models have triggered an early stop in their training\n",
    "        '''\n",
    "        early_stop = copy(gan.early_stop)\n",
    "        gan.early_stop = False\n",
    "        return early_stop\n",
    "    \n",
    "    def save_metrics(self):\n",
    "        '''\n",
    "        Save the accuracies to pickle files for later. Update new versions each iteration\n",
    "        '''\n",
    "        metric_save_folder = os.path.join('../gan_attack/checkpoints', 'metrics')\n",
    "        os.makedirs(metric_save_folder, exist_ok=True)\n",
    "        \n",
    "        g_acc_file = os.path.join(metric_save_folder, 'g_acc.pkl')\n",
    "        with open(g_acc_file, 'wb') as f:\n",
    "            pickle.dump(self.g_acc, f)\n",
    "            print('saved g_acc metric:', self.g_acc)\n",
    "        \n",
    "        bb_acc_file = os.path.join(metric_save_folder, 'bb_acc.pkl')\n",
    "        with open(bb_acc_file, 'wb') as f:\n",
    "            pickle.dump(self.bb_acc, f)\n",
    "            print('saved bb_acc metric:', self.bb_acc)\n",
    "        \n",
    "        d_acc_file = os.path.join(metric_save_folder, 'd_acc.pkl')\n",
    "        with open(d_acc_file, 'wb') as f:\n",
    "            pickle.dump(self.d_acc, f)\n",
    "            print('saved d_acc metric:', self.d_acc)\n",
    "        \n",
    "        bb_ong_acc_file = os.path.join(metric_save_folder, 'bb_ong_acc.pkl')\n",
    "        with open(bb_ong_acc_file, 'wb') as f:\n",
    "            pickle.dump(self.bb_ong_acc, f)\n",
    "            print('saved bb_ong_acc metric:', self.bb_ong_acc)\n",
    "        \n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "                \n",
    "    def plot_gan_training(self):\n",
    "        gen_loss_train_arr = self.cgan.gen_loss_train_arr\n",
    "        gen_acc_train_arr = self.cgan.gen_acc_train_arr\n",
    "        disc_loss_train_arr = self.cgan.disc_loss_train_arr\n",
    "        disc_acc_test_arr = self.cgan.disc_acc_test_arr\n",
    "        \n",
    "        epochs = list(range(max([len(gen_loss_train_arr), len(gen_acc_train_arr), \n",
    "                                 len(disc_loss_train_arr), len(disc_acc_test_arr)])))\n",
    "        epochs = [e + 1 for e in epochs]\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Generator Loss during Training')\n",
    "        plt.plot(epochs, gen_loss_train_arr)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Generator Accuracy during Training')\n",
    "        plt.plot(epochs, gen_acc_train_arr)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Discriminator Loss during Training')\n",
    "        plt.plot(epochs, disc_loss_train_arr)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Discriminator Accuracy (Test) during Training')\n",
    "        plt.plot(epochs, disc_acc_test_arr)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_training_params:\n",
      "{'apply_gradients_after': 20,\n",
      " 'batch_limit': None,\n",
      " 'ckpt_folder': 'blackbox_checkpoint',\n",
      " 'end_id': 'split_end_model',\n",
      " 'epochs': 1,\n",
      " 'eval_batch_size': 5,\n",
      " 'full_id': 'split_model',\n",
      " 'middle_id': 'split_middle_model',\n",
      " 'minibatch_size': None,\n",
      " 'shuffle_clients': True,\n",
      " 'start_id': 'split_start_model'}\n",
      "\n",
      "cgan_training_params:\n",
      "{'batch_size': 256,\n",
      " 'batches_per_epoch': 100,\n",
      " 'bb_ckpt_folder': 'blackbox_checkpoint',\n",
      " 'counter_nudge': True,\n",
      " 'd_ckpt_folder': 'discriminator_checkpoint',\n",
      " 'd_priming_epoch_limit': 1000,\n",
      " 'd_refine_epoch_limit': 200,\n",
      " 'd_reset_percentage': 1.0,\n",
      " 'd_restore_after_nudge': True,\n",
      " 'd_trigger': 0.98,\n",
      " 'early_stop_trigger': 5,\n",
      " 'end_id': 'd_end_model',\n",
      " 'epochs': 1,\n",
      " 'extra_depth': 3,\n",
      " 'full_id': 'd_model',\n",
      " 'g_ckpt_folder': 'generator_checkpoint',\n",
      " 'g_nudge_probability': 0.2,\n",
      " 'g_nudge_trigger': 3,\n",
      " 'g_trigger': 1.01,\n",
      " 'loop_times': 0,\n",
      " 'middle_id': 'd_middle_model',\n",
      " 'minibatch_size': None,\n",
      " 'noise_dim': 100,\n",
      " 'reset_g_every_it': False,\n",
      " 'save_best_g': False,\n",
      " 'softmax_power': 2,\n",
      " 'start_id': 'd_start_model',\n",
      " 'stop_sensitivity': 0.02,\n",
      " 'uncertain_loop_times': 1,\n",
      " 'use_bb_ends': True,\n",
      " 'use_blackbox': False}\n",
      "\n",
      "fgsm_training_params:\n",
      "{'epsilon': 0.9, 'norm': 'Inf'}\n",
      "\n",
      "attack_params:\n",
      "{'accumulate_g_queries': True,\n",
      " 'attack_classes': [1],\n",
      " 'attack_trigger': 0.8,\n",
      " 'attacker_clients': 5,\n",
      " 'attacks_per_epoch': 10,\n",
      " 'cgan_query_every_n_its': 1,\n",
      " 'd_refinement_batch_num': 3,\n",
      " 'd_refinement_batch_size': 100,\n",
      " 'flip_to': [7],\n",
      " 'flush_g_queries_every_bb_train': False,\n",
      " 'our_class': 0,\n",
      " 'prime_by_ckpt': True,\n",
      " 'prime_cgan_by_ckpt': False,\n",
      " 'prime_exit_trigger': 1.0,\n",
      " 'prime_first_iteration': True,\n",
      " 'prime_trigger': 0.0,\n",
      " 'refine_exit_trigger': 1.0,\n",
      " 'refine_using_fgsm': True,\n",
      " 'refine_using_ugan': False,\n",
      " 'reset_g_every_bb_train': False,\n",
      " 'train_bb_every_n_its': 2}\n"
     ]
    }
   ],
   "source": [
    "print('split_training_params:')\n",
    "pprint({i:split_training_params[i] for i in split_training_params if 'dataset' not in i})\n",
    "print()\n",
    "print('cgan_training_params:')\n",
    "pprint(cgan_training_params)\n",
    "print()\n",
    "print('fgsm_training_params:')\n",
    "pprint(fgsm_training_params)\n",
    "print()\n",
    "print('attack_params:')\n",
    "pprint({i:attack_params[i] for i in attack_params if 'dataset' not in i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-16-52c1415498a4>:78: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "saving initial weights for c_G\n",
      "Model: \"d_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "d_middle_model (Model)       (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "saving initial weights for D\n",
      "Model: \"cgan_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c_g_model (Model)               (None, 28, 28, 1)    13741121    input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul (TensorFlowOpLa [(None, 28, 28, 1)]  0           c_g_model[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add (TensorFlowOpLa [(None, 28, 28, 1)]  0           tf_op_layer_mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "d_model (Model)                 (None, 10)           791702      tf_op_layer_add[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 14,532,823\n",
      "Trainable params: 14,507,735\n",
      "Non-trainable params: 25,088\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "saved g_acc metric: [None]\n",
      "saved bb_acc metric: [None]\n",
      "saved d_acc metric: []\n",
      "saved bb_ong_acc metric: [None]\n",
      "****************************************\n",
      "Iteration 1\n",
      "\n",
      "D Test Accuracy: 0.094 | Loss: 2.303\n",
      "\n",
      "Restored latest checkpoint from ../gan_attack/checkpoints\\default\\blackbox_checkpoint\n",
      "Restoring D piece: ../gan_attack/checkpoints\\default\\d_start_model_checkpoint\n",
      "Restoring D piece: ../gan_attack/checkpoints\\default\\d_middle_model_checkpoint\n",
      "Restoring D piece: ../gan_attack/checkpoints\\default\\d_end_model_checkpoint\n",
      "oooooooooooooooooooooooooooooooooooooooo\n",
      "SKIPPED STEPS 1 & 2: Primed by checkpoint\n",
      "oooooooooooooooooooooooooooooooooooooooo\n",
      "\n",
      "D Test Accuracy: 0.348 | Loss: 2.102\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Step 3.2: Training cG\n",
      " - performed until cG converges with the current D\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aea18e6365a47ea9c000cefe58069ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b66aa3ad164674a1a2eaea3e507f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_acc=0.66, g_loss=1.86, d_loss=1.06\n",
      "Saved D checkpoint: ../gan_attack/checkpoints\\it_1\\d_middle_model\\ckpt-1\n",
      "Saved D checkpoint: ..\\gan_attack\\checkpoints\\it_1\\d_start_model_checkpoint\\checkpoint\n",
      "Saved D checkpoint: ..\\gan_attack\\checkpoints\\it_1\\d_middle_model_checkpoint\\checkpoint\n",
      "Saved D checkpoint: ..\\gan_attack\\checkpoints\\it_1\\d_end_model_checkpoint\\checkpoint\n",
      "Saved c_G checkpoint: ../gan_attack/checkpoints\\it_1\\c_generator_checkpoint\\ckpt-1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Step 4: Training Split Learning (and gathering Black-box labels)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 datasets gathered\n",
      "\n",
      "0.1\n",
      "10.0\n",
      "10\n",
      "(1, 3, 1, 100)\n",
      "(1, 3, 1, 100)\n",
      "0.1\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ac22b5ed9147>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mslg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSystemTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_training_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcgan_training_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mugan_training_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfgsm_training_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattack_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mslg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_system\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-12af89551ed4>\u001b[0m in \u001b[0;36mtrain_system\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;31m#             interfere_mask = np.random.binomial(1, mitigation_params['percent_to_drop'], size=len(g_dataset[0]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_bb_every_n_its\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: !"
     ]
    }
   ],
   "source": [
    "slg = SystemTrainer(split_training_params, cgan_training_params, ugan_training_params, fgsm_training_params, attack_params)\n",
    "slg.train_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
