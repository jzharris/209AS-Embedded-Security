{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack attempt, using a cGAN to train D and FGSM to refine D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF 2.1.0\n",
      "Keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution() # default for TF 2.0\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "from tensorflow import keras  # Import the tf version of keras.\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, \\\n",
    "                                    LeakyReLU, Conv2DTranspose, Reshape\n",
    "# import keras.backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "print('TF', tf.__version__)\n",
    "print('Keras', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import pickle\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "\n",
    "import os.path\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility \n",
    "# np.random.seed(0)\n",
    "# tf.random.set_seed(0)\n",
    "\n",
    "# Enlargen plots\n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EASY_MODE: if True, Split Learning NN is used as the Discriminator in the GAN. This is good for testing, but\n",
    "# bypasses the black-box paradigm! Use with caution\n",
    "EASY_MODE = False\n",
    "\n",
    "# Black-box params (optimized for MNIST)\n",
    "depth = 9\n",
    "filters = 33\n",
    "dense = 110\n",
    "num_classes = 10\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "target_rows, target_cols = 28, 28    # governed by the chosen model\n",
    "input_shape = (target_rows, target_cols, 1)\n",
    "\n",
    "# Attack params:\n",
    "attack_params = {\n",
    "    'our_class': 0,                             # the label indices that we want to preserve (and the data we own)\n",
    "    'attacker_clients': 5,                      # attacker controls X number of clients and their data\n",
    "    'attack_classes': [1],                      # the label(s) we want to poison\n",
    "    'flip_to': [7],                             # must be len(attack_classes) - flips the target label ('1') to new class ('7')\n",
    "    'batch_size': 25,\n",
    "    'attack_clients_list': list(range(0, 30, 3)) + [50, 100], # list(np.arange(0, 3, 0.5))\n",
    "#     'num_clients': 1000,\n",
    "    'prime_trigger': 0.00, #0.11                # the D test accuracy that, after which, we will move on from priming\n",
    "    'prime_first_iteration': True,              # whether to always prime on the first iteration\n",
    "    'prime_by_ckpt': True,                      # whether to prime manually (False) or by loading a checkpoint file (True)\n",
    "    'prime_cgan_by_ckpt': False,                # whether to load a pretrained cGAN from default/ or start from scratch (False)\n",
    "    'attack_trigger': 0.8,                      # the D accuracy (wrt Black-box) that, after which, we will commence an attack\n",
    "    'd_refinement_batch_num': 3,                # number of batches to refine D with: G -> BB <-> D\n",
    "    'd_refinement_batch_size': 100,             # number of attack images in each refinement batch: G -> BB <-> D\n",
    "    'train_dataset': None,                      # attack dataset - fixed in the beginning by choosing the attacking clients\n",
    "                                                # - this is the only data we have access to throughout the training process\n",
    "    'attacks_per_train_step': 1,                # how many times to attack per epoch\n",
    "    'prime_exit_trigger': 1.0,                  # how good D has to be on the current blackbox model to exit priming\n",
    "    'refine_exit_trigger': 1.0,                 # how good D has to be after refinement*\n",
    "    'train_bb_every_n_its': 6,                  # only train the BB model while querying if (it % train_bb_every_n_its == 0)\n",
    "    'cgan_query_every_n_its': 1,                # only query BB with cGAN every N iterations\n",
    "    'refine_using_fgsm': True,                  # use the uGAN to generate images to refine D with via uG -> BB -> D\n",
    "    'accumulate_g_queries': True,               # whether to keep uGAN imgs every iteration, or to just use most recent (False)\n",
    "    'flush_g_queries_every_bb_train': False,    # whether to keep uGAN imgs after new BB is trained, or preserved them (False)\n",
    "    'reset_g_every_bb_train': False,            # whether to reset G back to init every time we train the BB model\n",
    "}\n",
    "\n",
    "# Split Learning training params:\n",
    "split_training_params = {\n",
    "    'minibatch_size': None,                     # number of samples to operate on at one time\n",
    "                                                #  - can vary to optimize computing requirements\n",
    "                                                #  - if None, will evaluate the client's whole batch regardless of its size\n",
    "    'apply_gradients_after': 20,                # after averaging the gradients from X clients, we will apply them to the model\n",
    "    'epochs': 1,                                # number of epochs to train for\n",
    "    'shuffle_clients': True,                    # whether to shuffle the clients during training\n",
    "    'eval_batch_size': 256,                     # batch size when evaluating test set (not split by clients),\n",
    "    'train_dataset': None,                      # training set - indexed by client\n",
    "    'test_dataset': None,                       # testing set - not batched\n",
    "    'batch_limit': None,                        # how many batches to train on, maximum, per epoch\n",
    "    'ckpt_folder': \"blackbox_checkpoint\",       # folder where to store the checkpoints\n",
    "    'start_id': 'split_start_model',            # start piece\n",
    "    'middle_id': 'split_middle_model',          # middle piece\n",
    "    'end_id': 'split_end_model',                # end piece\n",
    "    'full_id': 'split_model',                   # full model name\n",
    "}\n",
    "\n",
    "# cGAN training params:\n",
    "cgan_training_params = {\n",
    "    'minibatch_size': split_training_params['minibatch_size'],\n",
    "    'extra_depth': 3,                           # number of extra middle layers to put in the D of cGAN\n",
    "    'start_id': 'd_start_model',                # start piece\n",
    "    'middle_id': 'd_middle_model',              # middle piece\n",
    "    'end_id': 'd_end_model',                    # end piece\n",
    "    'full_id': 'd_model',                       # full model name\n",
    "    'use_bb_ends': True,                        # whether to share the weights of the start and end piece from the BB model\n",
    "    'batch_size': 256,                          # number of images to generate from cG at once\n",
    "    'noise_dim': 100,                           # noise vector for cG\n",
    "    'epochs': 8,                                # number of epochs to train cGAN\n",
    "    'use_blackbox': False,                      # if True, copies the Blackbox model into D (easy check)\n",
    "    'd_ckpt_folder': \"discriminator_checkpoint\",# folder where to store the d checkpoints\n",
    "    'bb_ckpt_folder': \"blackbox_checkpoint\",    # folder where the blackbox default ckpt is kept\n",
    "    'g_ckpt_folder': \"generator_checkpoint\",    # folder where to store the g checkpoints\n",
    "    'batches_per_epoch': 100,                   # number of batches to train on per epoch\n",
    "    'd_trigger': 0.98,                          # train D if g_accuracy is >= X\n",
    "    'g_trigger': 1.01,                          # train G if g_accuracy is < X\n",
    "    'loop_times': 0,                            # number of times to apply softmax -> onehot encoding\n",
    "    'uncertain_loop_times': 1,                  # number to use in the uncertain_loss used by D\n",
    "    'softmax_power': 2,                         # number used in softmax -> onehot encoding operation\n",
    "    'd_reset_percentage': 1.0,                  # reset D if the test d_accuracy dips below X% of the original accuracy\n",
    "    'early_stop_trigger': 5,                    # stop training early, if g_accuracy has not improved for X epochs\n",
    "    'stop_sensitivity': 0.02,                   # \"no improvement\" is when the g_accuracy has not moved more than X% from prev\n",
    "    'g_nudge_trigger': 3,                       # if \"no improvement\" for X epochs, turn on D for one turn\n",
    "    'g_nudge_probability': 0.20,                # probability of nudging this sample, if enabled\n",
    "    'counter_nudge': True,                      # whether to train an extra epoch when coming out of training right after nudge\n",
    "    'd_priming_epoch_limit': 1000,              # number of epochs to stop at for priming\n",
    "    'd_refine_epoch_limit': 500,                # number of epochs to stop at for refining D\n",
    "    'save_best_g': False,                       # whether to save the best G during training, or to just use the last one\n",
    "    'd_restore_after_nudge': True,              # whether to restore D back to normal at the end of the epoch if it was nudged\n",
    "    'reset_g_every_it': False,                  # whether to restore cG back to init at the end of Step 5 if not -> Step 6\n",
    "}\n",
    "\n",
    "# FGSM training params:\n",
    "fgsm_training_params = {\n",
    "    'epsilon': 0.5,\n",
    "    'norm': 'L1',                                 # can be L1, Inf\n",
    "}\n",
    "\n",
    "# Data parsing params\n",
    "clients_per_class = 100                         # number of clients per label. Each client only has access to one label\n",
    "                                                # - each unique class is divided into X number of subsets\n",
    "\n",
    "# Dataset params\n",
    "separated_folder = \"./separated_dataset\"\n",
    "os.makedirs(separated_folder, exist_ok=True)\n",
    "separated_train_path = os.path.join(separated_folder, \"train_separated.pkl\")\n",
    "separated_test_path = os.path.join(separated_folder, \"test_separated.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Parameters for Label Poisoning:\n",
    "\n",
    "attack_params['attacker_clients'] = 95\n",
    "num_poisoning_iterations = 1\n",
    "\n",
    "training_classes_to_keep = [0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
    "# training_classes_to_keep = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255    # range is [0, 1]\n",
    "x_test /= 255     # range is [0, 1]\n",
    "\n",
    "if target_rows != img_rows or target_cols != img_cols:\n",
    "    # resize x_train\n",
    "    x_train_resized = []\n",
    "    for x_ in x_train:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_train_resized.append(x_)\n",
    "    x_train = np.asarray(x_train_resized)\n",
    "\n",
    "    # resize x_test\n",
    "    x_test_resized = []\n",
    "    for x_ in x_test:\n",
    "        # scale image to be the same WxH as we need:\n",
    "        x_ = cv2.resize(x_, dsize=(target_rows, target_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        x_test_resized.append(x_)\n",
    "    x_test = np.asarray(x_test_resized)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "y: (60000, 10) (10000, 10)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "print('X:', x_train.shape, x_test.shape)\n",
    "print('y:', y_train.shape, y_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "BUFFER_SIZE = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training seperation\n",
      "loaded testing seperation\n"
     ]
    }
   ],
   "source": [
    "# Separating the data by class\n",
    "if os.path.isfile(separated_train_path):\n",
    "    with open(separated_train_path, 'rb') as f:\n",
    "        x_train_dict, y_train_dict = pickle.load(f)\n",
    "        print('loaded training seperation')\n",
    "else:\n",
    "    x_train_dict = {}\n",
    "    y_train_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_train_dict[target_label] = []\n",
    "        y_train_dict[target_label] = []\n",
    "        for i, label in enumerate(y_train):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_train_dict[target_label].append(x_train[i])\n",
    "                y_train_dict[target_label].append(y_train[i])\n",
    "    \n",
    "    with open(separated_train_path, 'wb') as f:\n",
    "        pickle.dump([x_train_dict, y_train_dict], f)\n",
    "        print('saved training seperation')\n",
    "\n",
    "if os.path.isfile(separated_test_path):\n",
    "    with open(separated_test_path, 'rb') as f:\n",
    "        x_test_dict, y_test_dict = pickle.load(f)\n",
    "        print('loaded testing seperation')\n",
    "else:\n",
    "    x_test_dict = {}\n",
    "    y_test_dict = {}\n",
    "    for target_label in tqdm_notebook(range(10)):\n",
    "        x_test_dict[target_label] = []\n",
    "        y_test_dict[target_label] = []\n",
    "        for i, label in enumerate(y_test):\n",
    "            if list(label).index(1) == target_label:\n",
    "                x_test_dict[target_label].append(x_test[i])\n",
    "                y_test_dict[target_label].append(y_test[i])\n",
    "\n",
    "    with open(separated_test_path, 'wb') as f:\n",
    "        pickle.dump([x_test_dict, y_test_dict], f)\n",
    "        print('saved testing seperation')\n",
    "    \n",
    "# convert dicts to lists\n",
    "x_train_seperated = [np.array(x_train_dict[i]) for i in range(10)]\n",
    "y_train_seperated = [np.array(y_train_dict[i]) for i in range(10)]\n",
    "\n",
    "x_test_seperated = [np.array(x_test_dict[i]) for i in range(10)]\n",
    "y_test_seperated = [np.array(y_test_dict[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary of data shapes:\n",
    "plt.figure()\n",
    "plt.title('Data separation per class')\n",
    "plt.bar(x_train_dict.keys(), [len(v) for v in x_train_dict.values()], color='tab:blue')\n",
    "plt.bar(x_test_dict.keys(), [len(v) for v in x_test_dict.values()], color='orange', width=0.6)\n",
    "plt.legend(['x_train', 'x_test'], loc='center right', framealpha=1.0)\n",
    "plt.xlabel('class label')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the data into batches for clients to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients per class:  99.6 ~= 100\n",
      "Total number of clients: 996\n",
      "Average batch size: 60\n"
     ]
    }
   ],
   "source": [
    "# Separate the data into a long list of batches, each batch representing a client training with that batch of images.\n",
    "# After each batch, a new client will have the opportunity to train their batch of images.\n",
    "# Batches are shuffled to simulate many clients training the model at once.\n",
    "\n",
    "client_counts = {}\n",
    "batch_sizes = {}\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "def ceil(a,b):\n",
    "    return -(-a//b)\n",
    "\n",
    "for class_idx in range(len(x_train_seperated)):\n",
    "    # Get batches from class data:\n",
    "    n_samples_per_class = len(x_train_seperated[class_idx])\n",
    "    samples_per_client = n_samples_per_class / clients_per_class\n",
    "    better_batch_size = int(math.ceil(samples_per_client))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(ceil(n_samples_per_class, better_batch_size)):\n",
    "        x_batches.append((class_idx, x_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        y_batches.append((class_idx, y_train_seperated[class_idx][i * better_batch_size: (i+1) * better_batch_size]))\n",
    "        count += 1\n",
    "    client_counts[class_idx] = count\n",
    "    batch_sizes[class_idx] = better_batch_size\n",
    "        \n",
    "# double check that the clients_per_class is upheld per class\n",
    "# (blue bars should be uniform, orange should change according to class):\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('class label')\n",
    "ax1.set_ylabel('client count', color=color)\n",
    "plt.bar(client_counts.keys(), [v for v in client_counts.values()], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'orange'\n",
    "ax2.set_ylabel('batch size', color=color)  # we already handled the x-label with ax1\n",
    "plt.bar(batch_sizes.keys(), [v for v in batch_sizes.values()], color=color, width=0.6)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylim(0, np.mean([v for v in batch_sizes.values()])*2)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()\n",
    "\n",
    "print('Clients per class:  {} ~= {}'.format(np.mean([v for v in client_counts.values()]), clients_per_class))\n",
    "print('Total number of clients: {}'.format(np.sum([v for v in client_counts.values()])))\n",
    "batch_average = int(np.mean([v for v in batch_sizes.values()]))\n",
    "print('Average batch size: {}'.format(batch_average))\n",
    "\n",
    "split_batch_size = np.floor(np.mean([v for v in batch_sizes.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the attacker's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 clients to choose from:\n",
      "Classes of attack clients: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Choosing the following clients as the attackers:\n",
      "[59  2 96 23 94 64 60 17 53 54 22 70 67  0 26 72 27 51 21 43 39 93 82 85\n",
      " 92  9 83 68 32 48 98 80 79 90 81 24 50 66 35 73  5 71 42 77  4 97 41 46\n",
      " 16 38 76 36 87 40 61 12 11 91 18  8 63 74 52 20 65 49 95 78 31 25 13  1\n",
      " 30 84 14 15 86 29 44 75 56 47 37 10 55 58 34 57 28 45  3 33 62 89 88]\n"
     ]
    }
   ],
   "source": [
    "x_batches_filtered_i = [i for i, batch in enumerate(x_batches) if batch[0] == attack_params['our_class']]\n",
    "y_batches_filtered_i = [i for i, batch in enumerate(y_batches) if batch[0] == attack_params['our_class']]\n",
    "assert x_batches_filtered_i == y_batches_filtered_i\n",
    "\n",
    "x_batches_filtered = list(map(x_batches.__getitem__, x_batches_filtered_i))\n",
    "y_batches_filtered = list(map(y_batches.__getitem__, y_batches_filtered_i))\n",
    "\n",
    "print('{} clients to choose from:'.format(len(x_batches_filtered)))\n",
    "print('Classes of attack clients:', [f[0] for f in x_batches_filtered])\n",
    "print()\n",
    "\n",
    "attack_clients = np.random.choice(len(x_batches_filtered), attack_params['attacker_clients'], replace=False)\n",
    "print('Choosing the following clients as the attackers:\\n{}'.format(attack_clients))\n",
    "x_attack_batches = list(map(x_batches_filtered.__getitem__, attack_clients))\n",
    "y_attack_batches = list(map(y_batches_filtered.__getitem__, attack_clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset length: 996 996\n",
      "New dataset length:      901 901\n"
     ]
    }
   ],
   "source": [
    "# remove the attackers from the original training dataset\n",
    "# BREAKS THE ORIGINAL X_BATCHES AND Y_BATCHES!\n",
    "print('Original dataset length:', len(x_batches), len(y_batches))\n",
    "\n",
    "x_attackers_i = list(map(x_batches_filtered_i.__getitem__, attack_clients))\n",
    "y_attackers_i = list(map(y_batches_filtered_i.__getitem__, attack_clients))\n",
    "\n",
    "x_batches = [batch for i, batch in enumerate(x_batches) if i not in x_attackers_i]\n",
    "y_batches = [batch for i, batch in enumerate(y_batches) if i not in y_attackers_i]\n",
    "\n",
    "print('New dataset length:     ', len(x_batches), len(y_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data for Split Learning\n",
    "split_train_dataset = (x_batches, y_batches)\n",
    "split_test_dataset = (x_test, y_test)\n",
    "\n",
    "# place into train params:\n",
    "split_training_params['train_dataset'] = split_train_dataset\n",
    "split_training_params['test_dataset'] = split_test_dataset\n",
    "\n",
    "# Build attack dataset\n",
    "attack_train_dataset = (x_attack_batches, y_attack_batches)\n",
    "attack_params['train_dataset'] = attack_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0; Max: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Show min and max of the dataset (ensure you are using the right normalization)\n",
    "min_ = np.inf\n",
    "max_ = -np.inf\n",
    "for batch in x_batches:\n",
    "    min__ = np.min(batch[1])\n",
    "    max__ = np.max(batch[1])\n",
    "    min_ = min(min_, min__)\n",
    "    max_ = max(max_, max__)\n",
    "print('Min: {}; Max: {}'.format(min_, max_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "\n",
    "def start_piece(identifier, input_shape, filters=4):\n",
    "    assert filters >= 1\n",
    "    \n",
    "    input_1 = keras.layers.Input(input_shape)\n",
    "    conv1 = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(input_1)\n",
    "    model = keras.models.Model(inputs=[input_1], outputs=conv1)\n",
    "    model._name = identifier\n",
    "    \n",
    "    return model\n",
    "\n",
    "def blackbox_piece(identifier, input_shape, depth=1, filters=4):\n",
    "    assert depth >= 1\n",
    "    assert filters >= 1\n",
    "    \n",
    "    input_2 = keras.layers.Input(input_shape)\n",
    "    \n",
    "    # for now, we will just give the black-box all the CNN layers\n",
    "    for i in range(depth-1):\n",
    "        if i == 0:\n",
    "            convs = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(input_2)\n",
    "        else:\n",
    "            convs = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(convs)\n",
    "            \n",
    "    model = keras.models.Model(inputs=[input_2], outputs=convs)\n",
    "    model._name = identifier\n",
    "    \n",
    "    return model\n",
    "\n",
    "def approximator_piece(identifier, input_shape, depth=1, filters=4):\n",
    "    assert depth >= 1\n",
    "    assert filters >= 1\n",
    "    \n",
    "    input_2 = keras.layers.Input(input_shape)\n",
    "    \n",
    "    # for now, we will just give the black-box all the CNN layers\n",
    "    for i in range(depth-1):\n",
    "        if i == 0:\n",
    "            convs = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(input_2)\n",
    "        else:\n",
    "            convs = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(convs)\n",
    "            \n",
    "    model = keras.models.Model(inputs=[input_2], outputs=convs)\n",
    "    model._name = identifier\n",
    "    \n",
    "    return model\n",
    "\n",
    "def end_piece(identifier, input_shape, dense_breadth=128, num_classes=10):\n",
    "    assert dense_breadth >= num_classes\n",
    "    \n",
    "    input_3 = keras.layers.Input(input_shape)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(input_3)\n",
    "    drop1 = Dropout(0.25)(pool1)\n",
    "    flat1 = Flatten()(drop1)\n",
    "    dense1 = Dense(dense_breadth, activation='relu')(flat1)\n",
    "    drop2 = Dropout(0.5)(dense1)\n",
    "    dense2 = Dense(num_classes, activation='softmax')(drop2)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_3], outputs=dense2)\n",
    "    model._name = identifier\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the params are acceptable:\n",
    "assert depth >= 1\n",
    "assert filters >= 1\n",
    "assert dense >= num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitLearning:\n",
    "    \n",
    "    def __init__(self, split_training_params):\n",
    "        self.minibatch_size = split_training_params['minibatch_size']\n",
    "        self.batches_per_train_step = split_training_params['apply_gradients_after']\n",
    "        self.eval_batch_size = split_training_params['eval_batch_size']\n",
    "        self.shuffle_clients = split_training_params['shuffle_clients']\n",
    "        \n",
    "        self.ckpt_folder = split_training_params['ckpt_folder']\n",
    "        self.start_id = split_training_params['start_id']\n",
    "        self.middle_id = split_training_params['middle_id']\n",
    "        self.end_id = split_training_params['end_id']\n",
    "        self.full_id = split_training_params['full_id']\n",
    "        \n",
    "        # define the NN model\n",
    "        self.start_piece = None\n",
    "        self.middle_piece = None\n",
    "        self.end_piece = None\n",
    "        self.model = self.blackbox_model()\n",
    "        \n",
    "        # define loss function\n",
    "        self.cross_entropy = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define metrics\n",
    "        self.acc_train_avg = None\n",
    "        self.loss_train_avg = None\n",
    "        \n",
    "        # setup checkpointing\n",
    "        self.init_ckpt()\n",
    "        \n",
    "        # setup ops\n",
    "        self.setup_ops()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Black-box model\n",
    "        \n",
    "    def blackbox_model(self):\n",
    "        # create all three models\n",
    "        \n",
    "        #   start piece...\n",
    "        self.start_piece = start_piece(self.start_id, input_shape, filters)\n",
    "        output_shape = self.start_piece.layers[-1].output_shape[1:]\n",
    "        \n",
    "        #   middle...\n",
    "        self.middle_piece = blackbox_piece(self.middle_id, output_shape, depth, filters)\n",
    "        output_shape = self.middle_piece.layers[-1].output_shape[1:]\n",
    "        \n",
    "        #   end piece...\n",
    "        self.end_piece = end_piece(self.end_id, output_shape, dense, num_classes)\n",
    "        \n",
    "        # glue the three models together\n",
    "        input_ = keras.layers.Input(input_shape)\n",
    "        hidden1 = self.start_piece(input_)\n",
    "        hidden2 = self.middle_piece(hidden1)\n",
    "        output_ = self.end_piece(hidden2)\n",
    "        \n",
    "        # create the full model\n",
    "        model = keras.models.Model(inputs=[input_], outputs=output_)\n",
    "        model._name = self.full_id\n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def model_loss(self, y_true, y_pred):\n",
    "        return self.cross_entropy(y_true, y_pred)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Train\n",
    "    \n",
    "    def setup_ops(self):\n",
    "        # INSPIRED BY: https://stackoverflow.com/questions/42156957/how-to-update-model-parameters-with-accumulated-gradients\n",
    "        # https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\n",
    "        \n",
    "        self.tvs = self.model.trainable_variables\n",
    "        self.accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in self.tvs]\n",
    "        self.accum_counter = tf.Variable(0.0, trainable=False)\n",
    "    \n",
    "    def train(self, datasets, iteration, g_dataset=None, batch_limit=None, attack_datasets=None, attack_clients=1):\n",
    "        # setup checkpointing\n",
    "        self.setup_ckpt(iteration)\n",
    "        \n",
    "        # setup bb_dataset (stores labels if g_dataset is passed in)\n",
    "        bb_dataset = []\n",
    "        \n",
    "        g_dataset_acc = tf.keras.metrics.Accuracy()\n",
    "        \n",
    "        # initialize the metrics each new epoch\n",
    "        if self.acc_train_avg is not None:\n",
    "            del self.acc_train_avg\n",
    "        if self.loss_train_avg is not None:\n",
    "            del self.loss_train_avg\n",
    "        self.acc_train_avg = tf.keras.metrics.Accuracy()\n",
    "        self.loss_train_avg = tf.keras.metrics.Mean()\n",
    "        \n",
    "        # append all datasets together for training:\n",
    "        x_batches = []\n",
    "        y_batches = []\n",
    "        for dataset in datasets:\n",
    "            x_batches_, y_batches_ = dataset\n",
    "            x_batches = x_batches + x_batches_\n",
    "            y_batches = y_batches + y_batches_\n",
    "        # if g_dataset is not None, add those batches to the end:\n",
    "        if g_dataset is not None:\n",
    "            g_x_batches, g_y_batches = g_dataset\n",
    "            g_batch_idxs = list(range(len(x_batches), len(x_batches)+len(g_x_batches)))\n",
    "            x_batches = x_batches + g_x_batches\n",
    "            y_batches = y_batches + g_y_batches\n",
    "        else:\n",
    "            g_batch_idxs = []\n",
    "            \n",
    "        # do the same thing with the attack datasets\n",
    "        if attack_datasets is None:\n",
    "            attack_datasets = []\n",
    "        x_attack = []\n",
    "        y_attack = []\n",
    "        for dataset in attack_datasets:\n",
    "            x_attack_, y_attack_ = dataset\n",
    "            x_attack = x_attack + x_attack_\n",
    "            y_attack = y_attack + y_attack_\n",
    "            \n",
    "#         print(len_x_attack)\n",
    "#         print(len_x_attack[0])\n",
    "#         print(len_x_attack[0][1])\n",
    "            \n",
    "        # setup progress bar\n",
    "        total_batches = batch_limit if batch_limit is not None and batch_limit < len(x_batches) else len(x_batches)\n",
    "        pbar = tqdm_notebook(total=total_batches)\n",
    "        \n",
    "        batch_idxs = list(range(len(x_batches)))\n",
    "        if self.shuffle_clients:\n",
    "            # shuffle the batches each time\n",
    "            random.shuffle(batch_idxs)\n",
    "            \n",
    "        for i, batch_idx in enumerate(batch_idxs):\n",
    "            x_batch = x_batches[batch_idx][1]\n",
    "            y_batch = y_batches[batch_idx][1]\n",
    "            \n",
    "            if batch_idx in g_batch_idxs:\n",
    "                # this is a g_x_batch! don't apply gradients, but store the prediction\n",
    "                logit_batch = self.pred_step(x_batch)\n",
    "                g_dataset_acc(tf.argmax(y_batch, 1), tf.argmax(logit_batch, 1))\n",
    "                bb_dataset.append((x_batch, y_batch, logit_batch))\n",
    "            else:\n",
    "                self.train_step(i, x_batch, y_batch, len(batch_idxs) - 1, attack=(x_attack, y_attack), \n",
    "                                attack_clients=attack_clients)\n",
    "            pbar.update(1)\n",
    "            pbar.set_description('train_acc={:.2f}%'.format(self.acc_train_avg.result()*100))\n",
    "            \n",
    "            if batch_limit is not None and i-1 >= batch_limit:\n",
    "                break\n",
    "        pbar.close()\n",
    "        print('train_acc={:.4f}%'.format(self.acc_train_avg.result()*100))\n",
    "        print('accuracy of blackbox on G dataset: {:.4f}%'.format(g_dataset_acc.result()*100))\n",
    "        \n",
    "        # save checkpoints\n",
    "        self.checkpoint()\n",
    "        \n",
    "        return bb_dataset\n",
    "        \n",
    "    def pred_step(self, x_batch):\n",
    "        logit_batch = []\n",
    "        # Iterate over the client's batch in minibatches:\n",
    "        j = 0\n",
    "        while(j < len(x_batch)):\n",
    "            if self.minibatch_size is None:\n",
    "                # use whole batch (no minibatch)\n",
    "                x_minibatch = x_batch\n",
    "            else:\n",
    "                x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "\n",
    "            logits = self.model(x_minibatch, training=True) # TODO: should this be False?\n",
    "            logit_batch = logit_batch + list(logits.numpy())\n",
    "\n",
    "            if self.minibatch_size is None:\n",
    "                break\n",
    "            else:\n",
    "                j += self.minibatch_size\n",
    "                \n",
    "        return logit_batch\n",
    "        \n",
    "    def train_step(self, i, x_batch, y_batch, limit, attack=None, attack_clients=1):\n",
    "        # Iterate over the client's batch in minibatches:\n",
    "        j = 0\n",
    "        while(j < len(x_batch)):\n",
    "            if self.minibatch_size is None:\n",
    "                # use whole batch (no minibatch)\n",
    "                x_minibatch = x_batch\n",
    "                y_minibatch = y_batch\n",
    "            else:\n",
    "                x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                y_minibatch = y_batch[j:(j+self.minibatch_size)]\n",
    "\n",
    "            # run the gradients\n",
    "            loss_value, grads = self.grad(x_minibatch, y_minibatch)\n",
    "\n",
    "            # accumulate them\n",
    "            self.accumulate_grads(grads)\n",
    "\n",
    "            if self.minibatch_size is None:\n",
    "                break\n",
    "            else:\n",
    "                j += self.minibatch_size\n",
    "\n",
    "        # perform a train step every batches_per_train_step number of batches:\n",
    "        if (i > 0 and i % self.batches_per_train_step == 0) or i == limit:\n",
    "            \n",
    "            if attack is not None and len(attack[0]) > 0:\n",
    "                x_batches = attack[0]\n",
    "                y_batches = attack[1]\n",
    "                \n",
    "                for b in range(len(x_batches)):\n",
    "                    x_batch = x_batches[b][1]\n",
    "                    y_batch = y_batches[b][1]\n",
    "                \n",
    "                    for i in range(attack_params['attacks_per_train_step']):\n",
    "                        ##########\n",
    "                        # Add attack to the grads X number of times:\n",
    "                        j = 0\n",
    "                        while(j < len(x_batch)):\n",
    "                            if self.minibatch_size is None:\n",
    "                                # use whole batch (no minibatch)\n",
    "                                x_minibatch = x_batch\n",
    "                                y_minibatch = y_batch\n",
    "                            else:\n",
    "                                x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                                y_minibatch = y_batch[j:(j+self.minibatch_size)]\n",
    "\n",
    "                            # run the gradients\n",
    "                            loss_value, grads = self.grad(x_minibatch, y_minibatch)\n",
    "\n",
    "                            # accumulate them\n",
    "                            self.accumulate_grads(grads, num_times=attack_clients)\n",
    "\n",
    "                            if self.minibatch_size is None:\n",
    "                                break\n",
    "                            else:\n",
    "                                j += self.minibatch_size\n",
    "                        ##########\n",
    "            \n",
    "            # Run the train_step ops to update the weights based on our accumulated gradients\n",
    "            self.optimize()\n",
    "            self.zero_out()\n",
    "    \n",
    "    def grad(self, inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(inputs, training=True)\n",
    "            loss_value = self.model_loss(targets, logits)\n",
    "            \n",
    "        # evaluate accuracy and append acc and loss to arrays\n",
    "        self.acc_train_avg(tf.argmax(targets, 1), tf.argmax(logits, 1))\n",
    "        self.loss_train_avg(loss_value)\n",
    "        \n",
    "        return loss_value, tape.gradient(loss_value, self.model.trainable_variables)\n",
    "    \n",
    "    def accumulate_grads(self, grads, num_times=1):\n",
    "        # add to accum_vars the new gradients\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.accum_vars[i].assign_add(grad * num_times)\n",
    "        # increment the counter by 1\n",
    "        self.accum_counter.assign_add(1.0 * num_times)\n",
    "        \n",
    "    def optimize(self):\n",
    "        # apply the gradients in accum_vars, dividing by the number in accum_counter\n",
    "        self.optimizer.apply_gradients(\n",
    "            [(accum_var / self.accum_counter, tv) \\\n",
    "                for (accum_var, tv) in zip(self.accum_vars, self.model.trainable_variables)]\n",
    "        )\n",
    "    \n",
    "    def zero_out(self):\n",
    "        # reset accum_vars and accum_counter back to 0\n",
    "        for i, tv in enumerate(self.accum_vars):\n",
    "            self.accum_vars[i].assign(tf.zeros_like(tv))\n",
    "        self.accum_counter = tf.Variable(0.0, trainable=False)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_optimer(self):\n",
    "        del self.optimizer\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = None\n",
    "        self.internal_iteration = None\n",
    "        self.iteration_offset = 0\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        # setup fresh checkpointer every new iteration\n",
    "        if self.internal_iteration is None or iteration != self.internal_iteration - self.iteration_offset:\n",
    "            ckpt_save_folder = os.path.join('checkpoints', 'it_{}'.format(iteration + self.iteration_offset), self.ckpt_folder)\n",
    "            os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "        \n",
    "            if self.ckpt is not None:\n",
    "                del self.ckpt\n",
    "            if self.manager is not None:\n",
    "                del self.manager\n",
    "\n",
    "            self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "            self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "            self.internal_iteration = iteration + self.iteration_offset\n",
    "    \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved checkpoint: {}\".format(save_path))\n",
    "        self.save_all_models(save_path)\n",
    "        \n",
    "    def save_all_models(self, save_path):\n",
    "        # in addition to checkpointing, save all of the models into their own ckpt files\n",
    "        it_folder = \"\"\n",
    "        for folder in self.splitall(save_path):\n",
    "            if \"it\" not in folder:\n",
    "                it_folder = os.path.join(it_folder, folder)\n",
    "            else:\n",
    "                it_folder = os.path.join(it_folder, folder)\n",
    "                break\n",
    "        \n",
    "        # save all three models\n",
    "        start_piece_folder = os.path.join(it_folder, self.start_id + \"_checkpoint\")\n",
    "        os.makedirs(start_piece_folder, exist_ok=True)\n",
    "        self.start_piece.save_weights(os.path.join(start_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved checkpoint: {}\".format(os.path.join(start_piece_folder, 'checkpoint')))\n",
    "        \n",
    "        middle_piece_folder = os.path.join(it_folder, self.middle_id + \"_checkpoint\")\n",
    "        os.makedirs(middle_piece_folder, exist_ok=True)\n",
    "        self.middle_piece.save_weights(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved checkpoint: {}\".format(os.path.join(middle_piece_folder, 'checkpoint')))\n",
    "        \n",
    "        end_piece_folder = os.path.join(it_folder, self.end_id + \"_checkpoint\")\n",
    "        os.makedirs(end_piece_folder, exist_ok=True)\n",
    "        self.end_piece.save_weights(os.path.join(end_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved checkpoint: {}\".format(os.path.join(end_piece_folder, 'checkpoint')))\n",
    "        \n",
    "    @staticmethod\n",
    "    def splitall(path):\n",
    "        allparts = []\n",
    "        while 1:\n",
    "            parts = os.path.split(path)\n",
    "            if parts[0] == path:  # sentinel for absolute paths\n",
    "                allparts.insert(0, parts[0])\n",
    "                break\n",
    "            elif parts[1] == path: # sentinel for relative paths\n",
    "                allparts.insert(0, parts[1])\n",
    "                break\n",
    "            else:\n",
    "                path = parts[0]\n",
    "                allparts.insert(0, parts[1])\n",
    "        return allparts\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False, checkpoint_folder='checkpoints'):\n",
    "        parent_folder = os.path.join(checkpoint_folder)\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                self.iteration_offset = largest_it\n",
    "                print('Restored latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found, starting with a fresh network')\n",
    "        else:\n",
    "            if load_default:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    self.iteration_offset = it_restore\n",
    "                print('Restored latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluate\n",
    "        \n",
    "    def evaluate(self, dataset, verbose=True):\n",
    "        '''\n",
    "        NOTE: dataset here is tailored for standard 'test' dataset provided by Keras\n",
    "        '''\n",
    "        \n",
    "        x, y = dataset\n",
    "        \n",
    "        acc_test_avg = tf.keras.metrics.Accuracy()\n",
    "        loss_test_avg = tf.keras.metrics.Mean()\n",
    "        for i in range(0, len(x), self.eval_batch_size):\n",
    "            # get batch\n",
    "            x_batch = x[i:i+self.eval_batch_size]\n",
    "            y_batch = y[i:i+self.eval_batch_size]\n",
    "            \n",
    "            # evaluate\n",
    "            logits = self.model(x_batch, training=False)\n",
    "            acc_test_avg(tf.argmax(y_batch, 1), tf.argmax(logits, 1))\n",
    "            loss_test_avg(self.model_loss(y_batch, logits))\n",
    "        \n",
    "        if verbose:\n",
    "            if self.acc_train_avg is not None and self.loss_train_avg is not None:\n",
    "                print('Train Accuracy: {:.3f} | Loss: {:.3f}'.format(self.acc_train_avg.result(), self.loss_train_avg.result()))\n",
    "            print('Test Accuracy: {:.3f} | Loss: {:.3f}'.format(acc_test_avg.result(), loss_test_avg.result()))\n",
    "            print()\n",
    "        return acc_test_avg.result(), loss_test_avg.result()\n",
    "        \n",
    "    def predict(self, dataset, return_tensors=True):\n",
    "        '''\n",
    "        Returns a list of label batches of each client that was in the dataset\n",
    "        '''\n",
    "        \n",
    "        x, _ = dataset\n",
    "        labels = []\n",
    "        \n",
    "        for i, client_x in enumerate(x):\n",
    "            x_batch = client_x[1]\n",
    "            label_batch = []\n",
    "            \n",
    "            # run through every minibatch:\n",
    "            j = 0\n",
    "            while(j < len(x_batch)):\n",
    "                if self.minibatch_size is None:\n",
    "                    # use whole batch (no minibatch)\n",
    "                    x_minibatch = x_batch\n",
    "                else:\n",
    "                    x_minibatch = x_batch[j:(j+self.minibatch_size)]\n",
    "                    \n",
    "                # evaluate\n",
    "                preds = self.model(x_batch, training=False)\n",
    "                if not return_tensors:\n",
    "                    preds = tf.nn.softmax(preds)\n",
    "                    preds = tf.argmax(preds, axis=1)\n",
    "                    \n",
    "                label_batch = label_batch + list(preds.numpy())\n",
    "                \n",
    "                if self.minibatch_size is None:\n",
    "                    break\n",
    "                else:\n",
    "                    j += self.minibatch_size\n",
    "            \n",
    "            # add to list\n",
    "            labels.append(label_batch)\n",
    "            \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D:\n",
    "    '''\n",
    "    The Discriminator portion of the GAN. Accepts a network, otherwise creates a new model.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, start_piece=None, middle_piece=None, end_piece=None, d_model=None):\n",
    "        \n",
    "#         self.ckpt_folder = gan_training_params['d_ckpt_folder']\n",
    "        self.ckpt_folder = gan_training_params['middle_id']\n",
    "        self.bb_ckpt_folder = gan_training_params['bb_ckpt_folder']\n",
    "        self.loop_times = gan_training_params['loop_times']\n",
    "        self.softmax_power = gan_training_params['softmax_power']\n",
    "        self.minibatch_size = gan_training_params['minibatch_size']\n",
    "        \n",
    "        self.use_bb_ends = gan_training_params['use_bb_ends']\n",
    "        self.start_id = gan_training_params['start_id']\n",
    "        self.middle_id = gan_training_params['middle_id']\n",
    "        self.end_id = gan_training_params['end_id']\n",
    "        self.full_id = gan_training_params['full_id']\n",
    "        \n",
    "        # make FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "        \n",
    "        # define the NN model\n",
    "        if d_model is not None:\n",
    "            assert start_piece is None and middle_piece is None and end_piece is None\n",
    "            self.model = d_model\n",
    "        else:\n",
    "            self.start_piece = start_piece\n",
    "            self.middle_piece = middle_piece\n",
    "            self.end_piece = end_piece\n",
    "            self.model = self.discriminator_model()\n",
    "            \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define entropies\n",
    "        self.cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        self.bin_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            \n",
    "        # setup checkpointing\n",
    "        self.ckpt = None\n",
    "        self.manager = None\n",
    "        \n",
    "        # save the initial weights\n",
    "        if middle_piece is None:\n",
    "            self.save_initial_weights()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Discriminator model\n",
    "    \n",
    "    def discriminator_model(self):\n",
    "        # create all three models\n",
    "        \n",
    "        #   start piece...\n",
    "        if self.use_bb_ends:\n",
    "            assert self.start_piece is not None\n",
    "        else:\n",
    "            self.start_piece = start_piece(self.start_id, input_shape, filters)\n",
    "        output_shape = self.start_piece.layers[-1].output_shape[1:]\n",
    "        \n",
    "        #   middle...\n",
    "        if self.middle_piece is None:\n",
    "            self.middle_piece = approximator_piece(self.middle_id, output_shape, depth, filters)\n",
    "        else:\n",
    "            print('WARNING: using the middle piece in D')\n",
    "        output_shape = self.middle_piece.layers[-1].output_shape[1:]\n",
    "        \n",
    "        #   end piece...\n",
    "        if self.use_bb_ends:\n",
    "            assert self.end_piece is not None\n",
    "        else:\n",
    "            self.end_piece = end_piece(self.end_id, output_shape, dense, num_classes)\n",
    "        \n",
    "        # glue the three models together\n",
    "        input_ = keras.layers.Input(input_shape)\n",
    "        hidden1 = self.start_piece(input_)\n",
    "        hidden2 = self.middle_piece(hidden1)\n",
    "        output_ = self.end_piece(hidden2)\n",
    "        \n",
    "        # create the full model\n",
    "        model = keras.models.Model(inputs=[input_], outputs=output_)\n",
    "        model._name = self.full_id\n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Loss\n",
    "    \n",
    "    def loss(self, fake_discrimination, labels):\n",
    "        matches = self.matches_labels(fake_discrimination, labels, loop_times=self.loop_times)\n",
    "        # we want the discriminator to NOT be fooled by these fake images\n",
    "        cross_entropy = self.bin_cross_entropy(tf.zeros_like(matches), matches)\n",
    "        return cross_entropy\n",
    "    \n",
    "    def entropy(self, y_true, y_pred):\n",
    "        return self.cat_cross_entropy(y_true, y_pred)\n",
    "        \n",
    "    def matches_labels(self, fake_output, labels, loop_times=0):\n",
    "        '''\n",
    "        Only works if the Discriminator is already trained on real images!!\n",
    "        1. Performs a softmax -> onehot conversion (differentiable approx.)\n",
    "        2. Multiplies this by the onehot version of the onehot attack label\n",
    "        3. Sums to reduce dimension\n",
    "        \n",
    "        - if the sum is close to 1, the nn thinks that the image is a part of the attack class\n",
    "        - if the sum is close to 0, the nn thinks that the image is not of the attack class\n",
    "        - the sum should not be in between, due to the onehot conversion we perform in step 1\n",
    "        '''\n",
    "        # 1.\n",
    "        my_power = self.softmax_power\n",
    "        for i in range(loop_times):\n",
    "            fake_output = self.soft_onehot(fake_output)\n",
    "        \n",
    "        # 2.\n",
    "        matches = tf.math.multiply(fake_output, labels)\n",
    "        \n",
    "        # 3.\n",
    "        reduced = tf.math.reduce_sum(matches, axis=-1)\n",
    "        \n",
    "        return reduced\n",
    "        \n",
    "    def soft_onehot(self, softmax, my_power=8):\n",
    "        '''\n",
    "        Shown to not really work... vanishing gradients problem\n",
    "        '''\n",
    "        soft_extreme = softmax ** my_power\n",
    "        norm = tf.reduce_sum(soft_extreme, axis=-1)\n",
    "        almost_onehot = tf.math.divide(soft_extreme, tf.reshape(norm, (-1, 1)))\n",
    "        return almost_onehot\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        ckpt_save_folder = os.path.join('checkpoints', 'it_{}'.format(iteration), self.ckpt_folder)\n",
    "        os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "        if self.ckpt is not None:\n",
    "            del self.ckpt\n",
    "        if self.manager is not None:\n",
    "            del self.manager\n",
    "\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.middle_piece)\n",
    "        self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "        \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved D checkpoint: {}\".format(save_path))\n",
    "        self.save_all_models(save_path)\n",
    "        \n",
    "    def save_all_models(self, save_path):\n",
    "        # in addition to checkpointing, save all of the models into their own ckpt files\n",
    "        it_folder = \"\"\n",
    "        for folder in self.splitall(save_path):\n",
    "            if \"it\" not in folder:\n",
    "                it_folder = os.path.join(it_folder, folder)\n",
    "            else:\n",
    "                it_folder = os.path.join(it_folder, folder)\n",
    "                break\n",
    "        \n",
    "        # save all three models\n",
    "        start_piece_folder = os.path.join(it_folder, self.start_id + \"_checkpoint\")\n",
    "        os.makedirs(start_piece_folder, exist_ok=True)\n",
    "        self.start_piece.save_weights(os.path.join(start_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved D checkpoint: {}\".format(os.path.join(start_piece_folder, 'checkpoint')))\n",
    "        \n",
    "        middle_piece_folder = os.path.join(it_folder, self.middle_id + \"_checkpoint\")\n",
    "        os.makedirs(middle_piece_folder, exist_ok=True)\n",
    "        self.middle_piece.save_weights(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved D checkpoint: {}\".format(os.path.join(middle_piece_folder, 'checkpoint')))\n",
    "        \n",
    "        end_piece_folder = os.path.join(it_folder, self.end_id + \"_checkpoint\")\n",
    "        os.makedirs(end_piece_folder, exist_ok=True)\n",
    "        self.end_piece.save_weights(os.path.join(end_piece_folder, 'checkpoint'))\n",
    "        print(\"Saved D checkpoint: {}\".format(os.path.join(end_piece_folder, 'checkpoint')))\n",
    "        \n",
    "    @staticmethod\n",
    "    def splitall(path):\n",
    "        allparts = []\n",
    "        while 1:\n",
    "            parts = os.path.split(path)\n",
    "            if parts[0] == path:  # sentinel for absolute paths\n",
    "                allparts.insert(0, parts[0])\n",
    "                break\n",
    "            elif parts[1] == path: # sentinel for relative paths\n",
    "                allparts.insert(0, parts[1])\n",
    "                break\n",
    "            else:\n",
    "                path = parts[0]\n",
    "                allparts.insert(0, parts[1])\n",
    "        return allparts\n",
    "    \n",
    "    def freeze_ends(self, yes):\n",
    "        self.start_piece.is_training = not yes\n",
    "        self.end_piece.is_training = not yes\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Load/save weights\n",
    "    \n",
    "    def save_initial_weights(self):\n",
    "        print('saving initial weights for D')\n",
    "        init_folder = os.path.join('checkpoints', 'init', self.ckpt_folder)\n",
    "        os.makedirs(init_folder, exist_ok=True)\n",
    "        self.model.save_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def load_initial_weights(self):\n",
    "        print('loading initial weights for D')\n",
    "        init_folder = os.path.join('checkpoints', 'init', self.ckpt_folder)\n",
    "        self.model.load_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False, use_blackbox=False, checkpoint_folder='checkpoints'):\n",
    "        parent_folder = os.path.join(checkpoint_folder)\n",
    "        iteration_offset = 0\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "#                 checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "#                 self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                self.restore_pieces(it_restore_ends=largest_it, it_restore_middle=largest_it)\n",
    "                iteration_offset = largest_it\n",
    "#                 print('Restored D to latest checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found for D, starting with a fresh network')\n",
    "        else:\n",
    "            if load_default:\n",
    "                if use_blackbox:\n",
    "                    checkpoint_directory = os.path.join(parent_folder, 'default', self.bb_ckpt_folder)\n",
    "                else:\n",
    "                    checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    iteration_offset = it_restore\n",
    "                print('Restored D to checkpoint from {}'.format(checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        return iteration_offset\n",
    "    \n",
    "    def restore_middle(self, it_restore_middle, checkpoint_folder='checkpoints'):\n",
    "        parent_folder = os.path.join(checkpoint_folder)\n",
    "        it_folder_middle = os.path.join(parent_folder, 'it_{}'.format(it_restore_middle))\n",
    "        middle_piece_folder = os.path.join(it_folder_middle, self.middle_id + \"_checkpoint\")\n",
    "        print('Restoring D piece: {}'.format(middle_piece_folder))\n",
    "        \n",
    "        assert os.path.isfile(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        self.middle_piece.load_weights(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "    \n",
    "    def restore_pieces(self, it_restore_ends=None, it_restore_middle=None, start_id=None, middle_id=None, \n",
    "                       end_id=None, load_default=False, checkpoint_folder='checkpoints'):\n",
    "        \n",
    "        if it_restore_ends is None:\n",
    "            it_restore_ends = 1\n",
    "        if it_restore_middle is None:\n",
    "            it_restore_middle = 1\n",
    "        \n",
    "        if start_id is None:\n",
    "            start_id = self.start_id\n",
    "        if middle_id is None:\n",
    "            middle_id = self.middle_id\n",
    "        if end_id is None:\n",
    "            end_id = self.end_id\n",
    "        \n",
    "        parent_folder = os.path.join(checkpoint_folder)\n",
    "        it_folder_ends = os.path.join(parent_folder, 'default' if load_default else 'it_{}'.format(it_restore_ends))\n",
    "        it_folder_middle = os.path.join(parent_folder, 'default' if load_default else 'it_{}'.format(it_restore_middle))\n",
    "        \n",
    "        start_piece_folder = os.path.join(it_folder_ends, start_id + \"_checkpoint\")\n",
    "        print('Restoring D piece: {}'.format(start_piece_folder))\n",
    "        middle_piece_folder = os.path.join(it_folder_middle, middle_id + \"_checkpoint\")\n",
    "        print('Restoring D piece: {}'.format(middle_piece_folder))\n",
    "        end_piece_folder = os.path.join(it_folder_ends, end_id + \"_checkpoint\")\n",
    "        print('Restoring D piece: {}'.format(end_piece_folder))\n",
    "        \n",
    "        assert os.path.isfile(os.path.join(start_piece_folder, 'checkpoint'))\n",
    "        assert os.path.isfile(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        assert os.path.isfile(os.path.join(end_piece_folder, 'checkpoint'))\n",
    "        \n",
    "        self.start_piece.load_weights(os.path.join(start_piece_folder, 'checkpoint'))\n",
    "        self.middle_piece.load_weights(os.path.join(middle_piece_folder, 'checkpoint'))\n",
    "        self.end_piece.load_weights(os.path.join(end_piece_folder, 'checkpoint'))\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluation\n",
    "\n",
    "    def discriminate(self, generated_images, training=True):\n",
    "        return self.model(generated_images, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G:\n",
    "    '''\n",
    "    The Generator portion of the GAN. Generates images given a conditional label.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, gan_training_params, is_conditional=True, identifier=None, extra_depth=0):\n",
    "        self.is_conditional = is_conditional\n",
    "        self.identifier = identifier\n",
    "        \n",
    "        self.ckpt_folder = self.g_identifier() + gan_training_params['g_ckpt_folder']\n",
    "        self.noise_dim = gan_training_params['noise_dim']\n",
    "        self.uncertain_loop_times = gan_training_params['uncertain_loop_times']\n",
    "        self.softmax_power = gan_training_params['softmax_power']\n",
    "        \n",
    "        # make FUNCTIONAL versions of the graphs. When calling them, you will need to specify input_layer= and training=\n",
    "        self.input_shapes = []\n",
    "        if is_conditional:\n",
    "            self.model = self.c_generator_model(extra_depth)\n",
    "        else:\n",
    "            self.model = self.u_generator_model()\n",
    "            \n",
    "        # define optimizers\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # define entropies\n",
    "        self.cat_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        self.bin_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            \n",
    "        # setup checkpointing\n",
    "        self.ckpt = None\n",
    "        self.manager = None\n",
    "        \n",
    "        # save initial weights\n",
    "        self.save_initial_weights()\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Generator model\n",
    "    \n",
    "    def g_identifier(self):\n",
    "        return self.identifier if self.identifier is not None else ''\n",
    "    \n",
    "    def c_generator_model(self, extra_depth=0):\n",
    "        '''\n",
    "        CONDITIONAL version of G\n",
    "        '''\n",
    "        ACTIVATION = keras.layers.Activation(\"tanh\")\n",
    "        \n",
    "        # Prepare noise input\n",
    "        self.input_shapes.append((self.noise_dim,))\n",
    "        input_z = keras.layers.Input((self.noise_dim,))\n",
    "        dense_z_1 = keras.layers.Dense(1024)(input_z)\n",
    "        act_z_1 = ACTIVATION(dense_z_1)\n",
    "        dense_z_2 = keras.layers.Dense(128 * 7 * 7)(act_z_1)\n",
    "        bn_z_1 = keras.layers.BatchNormalization()(dense_z_2)\n",
    "        reshape_z = keras.layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,))(bn_z_1)\n",
    "\n",
    "        # Prepare Conditional (label) input\n",
    "        self.input_shapes.append((num_classes,))\n",
    "        input_c = keras.layers.Input((num_classes,))\n",
    "        dense_c_1 = keras.layers.Dense(1024)(input_c)\n",
    "        act_c_1 = ACTIVATION(dense_c_1)\n",
    "        dense_c_2 = keras.layers.Dense(128 * 7 * 7)(act_c_1)\n",
    "        bn_c_1 = keras.layers.BatchNormalization()(dense_c_2)\n",
    "        reshape_c = keras.layers.Reshape((7, 7, 128), input_shape=(128 * 7 * 7,))(bn_c_1)\n",
    "\n",
    "        # Combine input source\n",
    "        concat_z_c = keras.layers.Concatenate()([reshape_z, reshape_c])\n",
    "\n",
    "        # Image generation with the concatenated inputs\n",
    "        up_1 = keras.layers.UpSampling2D(size=(2, 2))(concat_z_c)\n",
    "        conv_1 = keras.layers.Conv2D(64, (5, 5), padding='same')(up_1)\n",
    "        for i in range(extra_depth):\n",
    "            conv_1 = keras.layers.Conv2D(64, (5, 5), padding='same')(conv_1)\n",
    "        act_1 = ACTIVATION(conv_1)\n",
    "        up_2 = keras.layers.UpSampling2D(size=(2, 2))(act_1)\n",
    "        #\n",
    "        drop_1 = keras.layers.Dropout(0.1)(up_2)\n",
    "        #\n",
    "        conv_2 = keras.layers.Conv2D(1, (5, 5), padding='same')(drop_1)\n",
    "        act_2 = keras.layers.Activation(\"tanh\")(conv_2)\n",
    "        model = keras.models.Model(inputs=[input_z, input_c], outputs=act_2)\n",
    "        model._name = \"{}g_model\".format(self.g_identifier())\n",
    "        return model\n",
    "    \n",
    "    def u_generator_model(self):\n",
    "        '''\n",
    "        NORMAL version of G\n",
    "        '''\n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        self.input_shapes.append((self.noise_dim,))\n",
    "        model.add(Dense(7*7*256, use_bias=False, input_shape=(self.noise_dim,)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Reshape((7, 7, 256)))\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "        model._name = \"{}g_model\".format(self.g_identifier())\n",
    "\n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Loss\n",
    "    \n",
    "    def loss(self, fake_discrimination, labels):\n",
    "        # we want the discriminator to be fooled by these fake images\n",
    "        cross_entropy = self.cat_cross_entropy(fake_discrimination, labels)\n",
    "        return cross_entropy\n",
    "    \n",
    "    def u_loss(self, fake_discrimination):\n",
    "        '''\n",
    "        Loss that measures how close the output is to having a single peak.\n",
    "        In other words we are measuring how certain the model thinks it is\n",
    "        correct, regardless of the answer\n",
    "        1. Performs a softmax -> onehot conversion (differentiable approx.)\n",
    "        2. Compare to the original output -- return this cat crossentropy\n",
    "        '''\n",
    "        fake_output = tf.identity(fake_discrimination)\n",
    "        \n",
    "        # 1.\n",
    "        my_power = self.softmax_power\n",
    "        for i in range(self.uncertain_loop_times):\n",
    "            fake_output = self.soft_onehot(fake_output)\n",
    "            \n",
    "        # 2.\n",
    "        return self.cat_cross_entropy(fake_output, fake_discrimination)\n",
    "        \n",
    "    def soft_onehot(self, softmax, my_power=8):\n",
    "        '''\n",
    "        Shown to not really work... vanishing gradients problem\n",
    "        '''\n",
    "        soft_extreme = softmax ** my_power\n",
    "        norm = tf.reduce_sum(soft_extreme, axis=-1)\n",
    "        almost_onehot = tf.math.divide(soft_extreme, tf.reshape(norm, (-1, 1)))\n",
    "        return almost_onehot\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Checkpoint\n",
    "    \n",
    "    def init_ckpt(self):\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        \n",
    "    def setup_ckpt(self, iteration):\n",
    "        ckpt_save_folder = os.path.join('checkpoints', 'it_{}'.format(iteration), self.ckpt_folder)\n",
    "        os.makedirs(ckpt_save_folder, exist_ok=True)\n",
    "\n",
    "        if self.ckpt is not None:\n",
    "            del self.ckpt\n",
    "        if self.manager is not None:\n",
    "            del self.manager\n",
    "\n",
    "        self.ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.manager = tf.train.CheckpointManager(self.ckpt, ckpt_save_folder, max_to_keep=1)\n",
    "        \n",
    "    def checkpoint(self):\n",
    "        save_path = self.manager.save()\n",
    "        print(\"Saved {}G checkpoint: {}\".format(self.g_identifier(), save_path))\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Load/save weights\n",
    "    \n",
    "    def save_initial_weights(self):\n",
    "        print('saving initial weights for {}G'.format(self.g_identifier()))\n",
    "        init_folder = os.path.join('checkpoints', 'init', self.ckpt_folder)\n",
    "        os.makedirs(init_folder, exist_ok=True)\n",
    "        self.model.save_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def load_initial_weights(self):\n",
    "        print('loading initial weights for {}G'.format(self.g_identifier()))\n",
    "        init_folder = os.path.join('checkpoints', 'init', self.ckpt_folder)\n",
    "        self.model.load_weights(os.path.join(init_folder, 'checkpoint'))\n",
    "        \n",
    "    def restore(self, it_restore=None, load_default=False, checkpoint_folder='checkpoints'):\n",
    "        iteration_offset = 0\n",
    "        parent_folder = os.path.join(checkpoint_folder)\n",
    "        if it_restore is None and not load_default:\n",
    "            # find the most recent iteration and checkpoint\n",
    "            largest_it = None\n",
    "            for d in glob(os.path.join(parent_folder, '*')):\n",
    "                if os.path.isfile(os.path.join(d, self.ckpt_folder, 'checkpoint')):\n",
    "                    # passed, valid checkpoint\n",
    "                    if '_' in d:\n",
    "                        # passed, valid iteration folder\n",
    "                        it = int(d.split('_')[1])\n",
    "                        if largest_it is None or it > largest_it:\n",
    "                            largest_it = it\n",
    "            if largest_it is not None:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(largest_it), self.ckpt_folder)\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                iteration_offset = largest_it\n",
    "                print('Restored {}G to latest checkpoint from {}'.format(self.g_identifier(), checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found for {}G, starting with a fresh network'.format(self.g_identifier()))\n",
    "        else:\n",
    "            if load_default:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'default', self.ckpt_folder)\n",
    "            else:\n",
    "                checkpoint_directory = os.path.join(parent_folder, 'it_{}'.format(it_restore), self.ckpt_folder)\n",
    "            if os.path.isfile(os.path.join(checkpoint_directory, 'checkpoint')):\n",
    "                self.ckpt.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "                if it_restore is not None:\n",
    "                    iteration_offset = it_restore\n",
    "                print('Restored {}G to checkpoint from {}'.format(self.g_identifier(), checkpoint_directory))\n",
    "            else:\n",
    "                print('No weights found at: {}'.format(checkpoint_directory))\n",
    "        return iteration_offset\n",
    "        \n",
    "    ###########################################################################################\n",
    "    # Evaluation\n",
    "        \n",
    "    def generate(self, inputs, training=False):\n",
    "        generated_images = self.model(inputs, training=training)\n",
    "        return generated_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Blackbox and Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = cgan_training_params['batch_size']\n",
    "noise_dim = cgan_training_params['noise_dim']\n",
    "\n",
    "def onehot_vals(a):\n",
    "    b = np.zeros((a.size, num_classes), dtype=np.float32)\n",
    "    b[np.arange(a.size), a] = 1\n",
    "    return b\n",
    "\n",
    "def generate_images(g, batch_size, noise_dim):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    \n",
    "    # create a list of random ints\n",
    "    seed = tf.random.normal([batch_size, noise_dim])\n",
    "    gen_labels = np.random.randint(num_classes, size=batch_size)\n",
    "    y_batch = onehot_vals(gen_labels)\n",
    "\n",
    "    predictions = g.generate([seed, y_batch], training=False)\n",
    "    x_batch = 0.5 * predictions + 0.5\n",
    "    \n",
    "    return x_batch, y_batch\n",
    "\n",
    "def plot_images(g, batch_size, noise_dim):\n",
    "    \n",
    "    images, labels = generate_images(g, batch_size, noise_dim)\n",
    "    \n",
    "    assert images.shape[0] >= 16\n",
    "    assert labels is not None\n",
    "    assert len(labels) == len(images)\n",
    "\n",
    "    categories = [g.g_identifier()+str(x) for x in list(range(10))]\n",
    "    \n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    for i in range(16):\n",
    "        ax = plt.subplot(4, 4, i+1)\n",
    "        if g.is_conditional:\n",
    "            ax.title.set_text(categories[np.argmax(labels[i])])\n",
    "        plt.imshow(images[i, :, :, 0] * 255.0, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-17-a0a097f566b7>:78: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "saving initial weights for c_G\n"
     ]
    }
   ],
   "source": [
    "# create the Split Learning Trainer\n",
    "split = SplitLearning(split_training_params)\n",
    "g = G(cgan_training_params, identifier='c_', extra_depth=cgan_training_params['extra_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Poisoning Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_system(checkpoint_folder):\n",
    "    tf.keras.backend.clear_session()\n",
    "    global split\n",
    "    del split\n",
    "    split = SplitLearning(split_training_params)\n",
    "    \n",
    "    it_restore = None # use None to load the last checkpoint\n",
    "\n",
    "    print('For experiment {}:'.format(checkpoint_folder))\n",
    "    split.restore(it_restore=it_restore, checkpoint_folder=checkpoint_folder)\n",
    "\n",
    "    g.setup_ckpt(it_restore)\n",
    "    g.restore(it_restore=it_restore, checkpoint_folder=checkpoint_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_images(g, target_class, batch_size, noise_dim):\n",
    "    seed = tf.random.normal([batch_size, noise_dim])\n",
    "    gen_labels = np.ones(batch_size,dtype='int64')*target_class\n",
    "    y_batch = onehot_vals(gen_labels)\n",
    "\n",
    "    predictions = g.generate([seed, y_batch], training=False)\n",
    "    x_batch = 0.5 * predictions + 0.5\n",
    "    \n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_target_images(g, target_class, batch_size, noise_dim):\n",
    "    \n",
    "    images, labels = generate_target_images(g, target_class, batch_size, noise_dim)\n",
    "    \n",
    "    assert images.shape[0] >= 16\n",
    "    assert labels is not None\n",
    "    assert len(labels) == len(images)\n",
    "\n",
    "    categories = [g.g_identifier()+str(x) for x in list(range(10))]\n",
    "    \n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    for i in range(16):\n",
    "        ax = plt.subplot(4, 4, i+1)\n",
    "        if g.is_conditional:\n",
    "            ax.title.set_text(categories[np.argmax(labels[i])])\n",
    "        plt.imshow(images[i, :, :, 0] * 255.0, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_compromised_dataset(g, original_class, target_class, original_dataset, noise_dim, images_per_batch=60):\n",
    "\n",
    "    x_clients = []\n",
    "    y_clients = []\n",
    "    \n",
    "    num_clients = 1\n",
    "    images_per_batch = images_per_batch\n",
    "\n",
    "    for client_no in range(num_clients):\n",
    "        # create images of original class but label as new class\n",
    "        new_batch = generate_target_images(g, original_class, images_per_batch, noise_dim)[0]\n",
    "        new_labels = onehot_vals(np.ones(images_per_batch, dtype='int64') * target_class)\n",
    "        \n",
    "        x_clients.append((target_class, new_batch))\n",
    "        y_clients.append((target_class, new_labels))\n",
    "    \n",
    "    return (x_clients, y_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split Dataset for Individual Evaluation\n",
    "\n",
    "def filter_dataset(input_data, label_to_filter, desired_output_label):\n",
    "    # label_to_filter is the label of images to keep\n",
    "    # desired_output_label is the label of the chosen output\n",
    "    output_label = np.zeros(10)\n",
    "    output_label[desired_output_label] = 1\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(len(input_data[1])):\n",
    "        if (input_data[1][i][label_to_filter] == 1): # if img i has label_to_filter\n",
    "            images.append(input_data[0][i])\n",
    "            labels.append(output_label)\n",
    "    \n",
    "    return (np.array(images), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset_individual = []\n",
    "for i in range(10):\n",
    "    test_dataset_individual.append(filter_dataset(split_test_dataset, i, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGSM - Inf norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_training_params:\n",
      "{'apply_gradients_after': 20,\n",
      " 'batch_limit': None,\n",
      " 'ckpt_folder': 'blackbox_checkpoint',\n",
      " 'end_id': 'split_end_model',\n",
      " 'epochs': 1,\n",
      " 'eval_batch_size': 256,\n",
      " 'full_id': 'split_model',\n",
      " 'middle_id': 'split_middle_model',\n",
      " 'minibatch_size': None,\n",
      " 'shuffle_clients': True,\n",
      " 'start_id': 'split_start_model'}\n",
      "\n",
      "cgan_training_params:\n",
      "{'batch_size': 256,\n",
      " 'batches_per_epoch': 100,\n",
      " 'bb_ckpt_folder': 'blackbox_checkpoint',\n",
      " 'counter_nudge': True,\n",
      " 'd_ckpt_folder': 'discriminator_checkpoint',\n",
      " 'd_priming_epoch_limit': 1000,\n",
      " 'd_refine_epoch_limit': 500,\n",
      " 'd_reset_percentage': 1.0,\n",
      " 'd_restore_after_nudge': True,\n",
      " 'd_trigger': 0.98,\n",
      " 'early_stop_trigger': 5,\n",
      " 'end_id': 'd_end_model',\n",
      " 'epochs': 8,\n",
      " 'extra_depth': 3,\n",
      " 'full_id': 'd_model',\n",
      " 'g_ckpt_folder': 'generator_checkpoint',\n",
      " 'g_nudge_probability': 0.2,\n",
      " 'g_nudge_trigger': 3,\n",
      " 'g_trigger': 1.01,\n",
      " 'loop_times': 0,\n",
      " 'middle_id': 'd_middle_model',\n",
      " 'minibatch_size': None,\n",
      " 'noise_dim': 100,\n",
      " 'reset_g_every_it': False,\n",
      " 'save_best_g': False,\n",
      " 'softmax_power': 2,\n",
      " 'start_id': 'd_start_model',\n",
      " 'stop_sensitivity': 0.02,\n",
      " 'uncertain_loop_times': 1,\n",
      " 'use_bb_ends': True,\n",
      " 'use_blackbox': False}\n",
      "\n",
      "fgsm_training_params:\n",
      "{'epsilon': 0.5, 'norm': 'L1'}\n",
      "\n",
      "attack_params:\n",
      "{'accumulate_g_queries': True,\n",
      " 'attack_classes': [1],\n",
      " 'attack_clients_list': [0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 50, 100],\n",
      " 'attack_trigger': 0.8,\n",
      " 'attacker_clients': 95,\n",
      " 'attacks_per_train_step': 1,\n",
      " 'batch_size': 25,\n",
      " 'cgan_query_every_n_its': 1,\n",
      " 'd_refinement_batch_num': 3,\n",
      " 'd_refinement_batch_size': 100,\n",
      " 'flip_to': [7],\n",
      " 'flush_g_queries_every_bb_train': False,\n",
      " 'our_class': 0,\n",
      " 'prime_by_ckpt': True,\n",
      " 'prime_cgan_by_ckpt': False,\n",
      " 'prime_exit_trigger': 1.0,\n",
      " 'prime_first_iteration': True,\n",
      " 'prime_trigger': 0.0,\n",
      " 'refine_exit_trigger': 1.0,\n",
      " 'refine_using_fgsm': True,\n",
      " 'reset_g_every_bb_train': False,\n",
      " 'train_bb_every_n_its': 6}\n"
     ]
    }
   ],
   "source": [
    "print('split_training_params:')\n",
    "pprint({i:split_training_params[i] for i in split_training_params if 'dataset' not in i})\n",
    "print()\n",
    "print('cgan_training_params:')\n",
    "pprint(cgan_training_params)\n",
    "print()\n",
    "print('fgsm_training_params:')\n",
    "pprint(fgsm_training_params)\n",
    "print()\n",
    "print('attack_params:')\n",
    "pprint({i:attack_params[i] for i in attack_params if 'dataset' not in i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b791b7f5bda74529a86a459ef364bd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From  0  to  8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e8b052f1f54c4da1ec57dcf8252de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 0 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4450fa848fd24ae88a7de74745ca8a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.1413%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  0\n",
      "Train Accuracy: 0.911 | Loss: 1.550\n",
      "Test Accuracy: 0.991 | Loss: 1.470\n",
      "\n",
      "Train Accuracy: 0.911 | Loss: 1.550\n",
      "Test Accuracy: 0.001 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 60 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9555c15425a4484e95dc24d485dc8df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.0349%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  0\n",
      "Train Accuracy: 0.910 | Loss: 1.551\n",
      "Test Accuracy: 0.992 | Loss: 1.470\n",
      "\n",
      "Train Accuracy: 0.910 | Loss: 1.551\n",
      "Test Accuracy: 0.001 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 120 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c5335ce9fe46d08892b257f78b41df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.0683%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  0\n",
      "Train Accuracy: 0.911 | Loss: 1.551\n",
      "Test Accuracy: 0.992 | Loss: 1.470\n",
      "\n",
      "Train Accuracy: 0.911 | Loss: 1.551\n",
      "Test Accuracy: 0.001 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 180 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fc6db79ed749eeba9fd7fd18fd45db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.9714%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  0\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.991 | Loss: 1.470\n",
      "\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.002 | Loss: 2.459\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 240 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca5a0e056e945739e6f0ccb88603e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8936%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  0\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.993 | Loss: 1.469\n",
      "\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.001 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 300 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3d0edbf61244a4958e02162a43d05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.6222%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  0\n",
      "Train Accuracy: 0.906 | Loss: 1.555\n",
      "Test Accuracy: 0.991 | Loss: 1.470\n",
      "\n",
      "Train Accuracy: 0.906 | Loss: 1.555\n",
      "Test Accuracy: 0.001 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 360 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b0df8d3ab74bcb90469ba09b990f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8556%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  0\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.992 | Loss: 1.469\n",
      "\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.003 | Loss: 2.459\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 420 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55439216c1994bda801ad9975071304a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8333%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  0\n",
      "Train Accuracy: 0.908 | Loss: 1.553\n",
      "Test Accuracy: 0.992 | Loss: 1.469\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.553\n",
      "Test Accuracy: 0.003 | Loss: 2.459\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 480 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f3d904a6134ccfa0ec4a0dea75d69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.7524%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  0\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.993 | Loss: 1.469\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.002 | Loss: 2.459\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 540 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2251a587725142cc9b7bb40c308e931d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.7444%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  0\n",
      "Train Accuracy: 0.907 | Loss: 1.555\n",
      "Test Accuracy: 0.993 | Loss: 1.468\n",
      "\n",
      "Train Accuracy: 0.907 | Loss: 1.555\n",
      "Test Accuracy: 0.002 | Loss: 2.459\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 1000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57016d1acce345c4be7ec1f771f7d7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=89.7587%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  0\n",
      "Train Accuracy: 0.898 | Loss: 1.564\n",
      "Test Accuracy: 0.944 | Loss: 1.515\n",
      "\n",
      "Train Accuracy: 0.898 | Loss: 1.564\n",
      "Test Accuracy: 0.003 | Loss: 2.458\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 2000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2be78fe72a4847a2e18c10049e39db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.6127%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  0\n",
      "Train Accuracy: 0.906 | Loss: 1.556\n",
      "Test Accuracy: 0.993 | Loss: 1.468\n",
      "\n",
      "Train Accuracy: 0.906 | Loss: 1.556\n",
      "Test Accuracy: 0.001 | Loss: 2.460\n",
      "\n",
      "From  1  to  7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d016fbf9c5d42a28fa6e5ab2e775287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 0 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670eb44ff39147cba6078c487de7dbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.1587%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  1\n",
      "Train Accuracy: 0.912 | Loss: 1.550\n",
      "Test Accuracy: 0.985 | Loss: 1.475\n",
      "\n",
      "Train Accuracy: 0.912 | Loss: 1.550\n",
      "Test Accuracy: 0.002 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 60 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a59ecf56bc46ef9543e59ce748b980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=88.4746%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  1\n",
      "Train Accuracy: 0.885 | Loss: 1.576\n",
      "Test Accuracy: 0.976 | Loss: 1.484\n",
      "\n",
      "Train Accuracy: 0.885 | Loss: 1.576\n",
      "Test Accuracy: 0.001 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 120 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d8e27277e245a7801603029ba885a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=86.9381%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  1\n",
      "Train Accuracy: 0.869 | Loss: 1.590\n",
      "Test Accuracy: 0.967 | Loss: 1.494\n",
      "\n",
      "Train Accuracy: 0.869 | Loss: 1.590\n",
      "Test Accuracy: 0.006 | Loss: 2.453\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 180 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe96feed61b459392a20942a24bdfba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=80.3508%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  1\n",
      "Train Accuracy: 0.804 | Loss: 1.655\n",
      "Test Accuracy: 0.323 | Loss: 2.160\n",
      "\n",
      "Train Accuracy: 0.804 | Loss: 1.655\n",
      "Test Accuracy: 0.506 | Loss: 1.926\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 240 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a503fa4543584f5db091cea4690bef2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=76.6714%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  1\n",
      "Train Accuracy: 0.767 | Loss: 1.687\n",
      "Test Accuracy: 0.604 | Loss: 1.887\n",
      "\n",
      "Train Accuracy: 0.767 | Loss: 1.687\n",
      "Test Accuracy: 0.328 | Loss: 2.090\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 300 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04cae53e11648389dd77d6993f3e960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=78.4921%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  1\n",
      "Train Accuracy: 0.785 | Loss: 1.669\n",
      "Test Accuracy: 0.375 | Loss: 2.101\n",
      "\n",
      "Train Accuracy: 0.785 | Loss: 1.669\n",
      "Test Accuracy: 0.581 | Loss: 1.848\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 360 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169c5f74783449ed95592e7d23affdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=78.6397%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  1\n",
      "Train Accuracy: 0.786 | Loss: 1.667\n",
      "Test Accuracy: 0.364 | Loss: 2.114\n",
      "\n",
      "Train Accuracy: 0.786 | Loss: 1.667\n",
      "Test Accuracy: 0.563 | Loss: 1.878\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 420 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f71b12caa194e35bef642ea1aac0a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=79.0825%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  1\n",
      "Train Accuracy: 0.791 | Loss: 1.664\n",
      "Test Accuracy: 0.594 | Loss: 1.895\n",
      "\n",
      "Train Accuracy: 0.791 | Loss: 1.664\n",
      "Test Accuracy: 0.316 | Loss: 2.108\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 480 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92c578ed0304be59be9f8c4277d241a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=75.8349%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  1\n",
      "Train Accuracy: 0.758 | Loss: 1.697\n",
      "Test Accuracy: 0.471 | Loss: 2.011\n",
      "\n",
      "Train Accuracy: 0.758 | Loss: 1.697\n",
      "Test Accuracy: 0.458 | Loss: 1.977\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 540 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53b5e3e785648b78828bc880c3969c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=69.6968%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  1\n",
      "Train Accuracy: 0.697 | Loss: 1.757\n",
      "Test Accuracy: 0.001 | Loss: 2.451\n",
      "\n",
      "Train Accuracy: 0.697 | Loss: 1.757\n",
      "Test Accuracy: 0.761 | Loss: 1.693\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 1000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21489b9bf1c49659f5b4827aff69dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=73.9286%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  1\n",
      "Train Accuracy: 0.739 | Loss: 1.714\n",
      "Test Accuracy: 0.004 | Loss: 2.451\n",
      "\n",
      "Train Accuracy: 0.739 | Loss: 1.714\n",
      "Test Accuracy: 0.937 | Loss: 1.530\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 2000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43bc90f496842948978ae9298325833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=66.3524%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  1\n",
      "Train Accuracy: 0.664 | Loss: 1.790\n",
      "Test Accuracy: 0.003 | Loss: 2.456\n",
      "\n",
      "Train Accuracy: 0.664 | Loss: 1.790\n",
      "Test Accuracy: 0.959 | Loss: 1.502\n",
      "\n",
      "From  2  to  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3569d29f3ead4b24bc656c0178d2964b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 0 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc22d3e7622433e85dc7da24d1307b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.9857%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  2\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.962 | Loss: 1.492\n",
      "\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.000 | Loss: 2.461\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 60 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e833eb16ed4a428a7823f9e6f8048b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=84.8651%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  2\n",
      "Train Accuracy: 0.849 | Loss: 1.613\n",
      "Test Accuracy: 0.802 | Loss: 1.680\n",
      "\n",
      "Train Accuracy: 0.849 | Loss: 1.613\n",
      "Test Accuracy: 0.007 | Loss: 2.449\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 120 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b791f70c164eaf815450d7cf8bd63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=75.6714%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  2\n",
      "Train Accuracy: 0.757 | Loss: 1.704\n",
      "Test Accuracy: 0.626 | Loss: 1.875\n",
      "\n",
      "Train Accuracy: 0.757 | Loss: 1.704\n",
      "Test Accuracy: 0.077 | Loss: 2.330\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 180 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0ff5121ab944eb97b7b21b19a7f797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=71.4063%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  2\n",
      "Train Accuracy: 0.714 | Loss: 1.746\n",
      "Test Accuracy: 0.328 | Loss: 2.163\n",
      "\n",
      "Train Accuracy: 0.714 | Loss: 1.746\n",
      "Test Accuracy: 0.342 | Loss: 2.070\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 240 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de7eae0c3674eb88a51b7998262be28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=60.6095%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  2\n",
      "Train Accuracy: 0.606 | Loss: 1.854\n",
      "Test Accuracy: 0.503 | Loss: 1.982\n",
      "\n",
      "Train Accuracy: 0.606 | Loss: 1.854\n",
      "Test Accuracy: 0.161 | Loss: 2.226\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 300 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0c4b8ebb24460ab78329cd215cb408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=56.9381%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  2\n",
      "Train Accuracy: 0.569 | Loss: 1.887\n",
      "Test Accuracy: 0.096 | Loss: 2.382\n",
      "\n",
      "Train Accuracy: 0.569 | Loss: 1.887\n",
      "Test Accuracy: 0.796 | Loss: 1.651\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 360 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e8ac32d4cb4818ab6175b89226a2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=60.7397%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  2\n",
      "Train Accuracy: 0.607 | Loss: 1.852\n",
      "Test Accuracy: 0.614 | Loss: 1.903\n",
      "\n",
      "Train Accuracy: 0.607 | Loss: 1.852\n",
      "Test Accuracy: 0.182 | Loss: 2.214\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 420 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b81b062ab43459e9b5f6aa5ec1193a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=59.3127%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  2\n",
      "Train Accuracy: 0.593 | Loss: 1.866\n",
      "Test Accuracy: 0.170 | Loss: 2.322\n",
      "\n",
      "Train Accuracy: 0.593 | Loss: 1.866\n",
      "Test Accuracy: 0.780 | Loss: 1.638\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 480 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884378fd49ca4f6a9c89472ff2110b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=85.1032%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  2\n",
      "Train Accuracy: 0.851 | Loss: 1.610\n",
      "Test Accuracy: 0.082 | Loss: 2.392\n",
      "\n",
      "Train Accuracy: 0.851 | Loss: 1.610\n",
      "Test Accuracy: 0.918 | Loss: 1.529\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 540 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07f73505e7b4d5883e47b6a8d37f358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=65.8778%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  2\n",
      "Train Accuracy: 0.659 | Loss: 1.802\n",
      "Test Accuracy: 0.054 | Loss: 2.416\n",
      "\n",
      "Train Accuracy: 0.659 | Loss: 1.802\n",
      "Test Accuracy: 0.946 | Loss: 1.505\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 1000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e65c6cfedd5434e94352b200377e722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=34.5810%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  2\n",
      "Train Accuracy: 0.346 | Loss: 2.108\n",
      "Test Accuracy: 0.033 | Loss: 2.434\n",
      "\n",
      "Train Accuracy: 0.346 | Loss: 2.108\n",
      "Test Accuracy: 0.967 | Loss: 1.487\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 2000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e924c05c51924bbea8e8f2f19e1d6bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=39.9571%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  2\n",
      "Train Accuracy: 0.400 | Loss: 2.057\n",
      "Test Accuracy: 0.000 | Loss: 2.461\n",
      "\n",
      "Train Accuracy: 0.400 | Loss: 2.057\n",
      "Test Accuracy: 1.000 | Loss: 1.462\n",
      "\n",
      "From  3  to  9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a93e2de2f524ae28c3774f4e1542644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 0 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e7679c16ed4d5ab241ac9df0c650d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.0540%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  3\n",
      "Train Accuracy: 0.911 | Loss: 1.551\n",
      "Test Accuracy: 0.978 | Loss: 1.484\n",
      "\n",
      "Train Accuracy: 0.911 | Loss: 1.551\n",
      "Test Accuracy: 0.000 | Loss: 2.461\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 60 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cc47ea9de64aad93e132b3a1172dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.9825%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  3\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.975 | Loss: 1.485\n",
      "\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.001 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 120 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f28a7cc7a074b5caf8cf917ccecfd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8556%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  3\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.975 | Loss: 1.486\n",
      "\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.000 | Loss: 2.461\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 180 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63f80ef08a347f8a80fc6a321ac4cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.9079%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  3\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.974 | Loss: 1.487\n",
      "\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.000 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 240 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868583eb82ad458d821ad0b2077b0a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.9603%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  3\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.974 | Loss: 1.487\n",
      "\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.000 | Loss: 2.461\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 300 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ad174bf64540bd880f4010aa3d6f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8206%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  3\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.975 | Loss: 1.486\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.000 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 360 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbab2ba8f77466dbecf36ca457d3ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8714%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  3\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.973 | Loss: 1.487\n",
      "\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.000 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 420 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586288ffc4e14be79599f328048cc3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.7143%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  3\n",
      "Train Accuracy: 0.907 | Loss: 1.555\n",
      "Test Accuracy: 0.973 | Loss: 1.487\n",
      "\n",
      "Train Accuracy: 0.907 | Loss: 1.555\n",
      "Test Accuracy: 0.001 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 480 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d903936ed95d4b0cab081f3c4798bafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8857%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  3\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.972 | Loss: 1.489\n",
      "\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.000 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 540 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fafc2f323e24a17a544fd74c93354f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.7698%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  3\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.973 | Loss: 1.487\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.001 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 1000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6e2c2c02b14856b4067cafe9eda2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8032%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  3\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.964 | Loss: 1.496\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.000 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 2000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61da18d47c7342eeb7ccbfbc4cdaf4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.7095%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  3\n",
      "Train Accuracy: 0.907 | Loss: 1.554\n",
      "Test Accuracy: 0.973 | Loss: 1.488\n",
      "\n",
      "Train Accuracy: 0.907 | Loss: 1.554\n",
      "Test Accuracy: 0.002 | Loss: 2.459\n",
      "\n",
      "From  4  to  6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb3f50fd4cb449385b4a6946ce6010c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 0 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187f774830ea490d9577ee2f49b950ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.9730%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  4\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.968 | Loss: 1.492\n",
      "\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.006 | Loss: 2.455\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 60 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744da09ead4a4117ab2c173aedd61141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=88.5206%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  4\n",
      "Train Accuracy: 0.885 | Loss: 1.577\n",
      "Test Accuracy: 0.924 | Loss: 1.538\n",
      "\n",
      "Train Accuracy: 0.885 | Loss: 1.577\n",
      "Test Accuracy: 0.006 | Loss: 2.454\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 120 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edebb19953804d7e8846f22c504b760c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=83.7841%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  4\n",
      "Train Accuracy: 0.838 | Loss: 1.625\n",
      "Test Accuracy: 0.915 | Loss: 1.545\n",
      "\n",
      "Train Accuracy: 0.838 | Loss: 1.625\n",
      "Test Accuracy: 0.012 | Loss: 2.448\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 180 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d74805fa8cc4113bc10eecdc518dbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=87.5079%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  4\n",
      "Train Accuracy: 0.875 | Loss: 1.587\n",
      "Test Accuracy: 0.778 | Loss: 1.675\n",
      "\n",
      "Train Accuracy: 0.875 | Loss: 1.587\n",
      "Test Accuracy: 0.158 | Loss: 2.301\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 240 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf831375b5f4380b1df2f897284b006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=85.6540%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  4\n",
      "Train Accuracy: 0.857 | Loss: 1.606\n",
      "Test Accuracy: 0.903 | Loss: 1.558\n",
      "\n",
      "Train Accuracy: 0.857 | Loss: 1.606\n",
      "Test Accuracy: 0.027 | Loss: 2.428\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 300 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3caeb56b542244cd916b7f62cae0b560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=78.1651%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  4\n",
      "Train Accuracy: 0.782 | Loss: 1.679\n",
      "Test Accuracy: 0.871 | Loss: 1.587\n",
      "\n",
      "Train Accuracy: 0.782 | Loss: 1.679\n",
      "Test Accuracy: 0.060 | Loss: 2.398\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 360 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd23918ad1240c4b669e6575f234530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8190%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  4\n",
      "Train Accuracy: 0.908 | Loss: 1.553\n",
      "Test Accuracy: 0.978 | Loss: 1.481\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.553\n",
      "Test Accuracy: 0.004 | Loss: 2.456\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 420 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5433eb1b68ef430cb87a5f3d1106a96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=82.8429%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  4\n",
      "Train Accuracy: 0.828 | Loss: 1.632\n",
      "Test Accuracy: 0.000 | Loss: 2.461\n",
      "\n",
      "Train Accuracy: 0.828 | Loss: 1.632\n",
      "Test Accuracy: 0.989 | Loss: 1.473\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 480 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90cfa7b54294d3ca32da39644a09d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=70.8683%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  4\n",
      "Train Accuracy: 0.709 | Loss: 1.752\n",
      "Test Accuracy: 0.067 | Loss: 2.380\n",
      "\n",
      "Train Accuracy: 0.709 | Loss: 1.752\n",
      "Test Accuracy: 0.841 | Loss: 1.627\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 540 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22bef38dd784e3dbb66f76685933d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=77.8889%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  4\n",
      "Train Accuracy: 0.779 | Loss: 1.680\n",
      "Test Accuracy: 0.001 | Loss: 2.459\n",
      "\n",
      "Train Accuracy: 0.779 | Loss: 1.680\n",
      "Test Accuracy: 0.994 | Loss: 1.467\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 1000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1505882681ca487c8c6066a8b635c7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=69.1460%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  4\n",
      "Train Accuracy: 0.691 | Loss: 1.769\n",
      "Test Accuracy: 0.000 | Loss: 2.461\n",
      "\n",
      "Train Accuracy: 0.691 | Loss: 1.769\n",
      "Test Accuracy: 0.996 | Loss: 1.465\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 2000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c948aa4b4ed40e4877fa598f7d52e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=59.7159%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  4\n",
      "Train Accuracy: 0.597 | Loss: 1.863\n",
      "Test Accuracy: 0.000 | Loss: 2.461\n",
      "\n",
      "Train Accuracy: 0.597 | Loss: 1.863\n",
      "Test Accuracy: 0.999 | Loss: 1.462\n",
      "\n",
      "From  5  to  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5246eaf31e42a893ad45cd87af511e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 0 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64f54eca0d74d7a80f2ff35979ee1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.0492%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  5\n",
      "Train Accuracy: 0.910 | Loss: 1.551\n",
      "Test Accuracy: 0.984 | Loss: 1.479\n",
      "\n",
      "Train Accuracy: 0.910 | Loss: 1.551\n",
      "Test Accuracy: 0.001 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 60 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffcd40158b54af69702732830bcc25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.1222%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  5\n",
      "Train Accuracy: 0.911 | Loss: 1.552\n",
      "Test Accuracy: 0.966 | Loss: 1.496\n",
      "\n",
      "Train Accuracy: 0.911 | Loss: 1.552\n",
      "Test Accuracy: 0.004 | Loss: 2.457\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 120 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76f997f997e48fc90ff3aff99ca49e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=86.0159%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  5\n",
      "Train Accuracy: 0.860 | Loss: 1.605\n",
      "Test Accuracy: 0.762 | Loss: 1.684\n",
      "\n",
      "Train Accuracy: 0.860 | Loss: 1.605\n",
      "Test Accuracy: 0.039 | Loss: 2.423\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 180 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2983a41a2b4f99a88518ccf75bc5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=85.6206%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  5\n",
      "Train Accuracy: 0.856 | Loss: 1.608\n",
      "Test Accuracy: 0.766 | Loss: 1.678\n",
      "\n",
      "Train Accuracy: 0.856 | Loss: 1.608\n",
      "Test Accuracy: 0.053 | Loss: 2.408\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 240 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4495872506245d4b98fd6b0406dee92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=82.2032%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  5\n",
      "Train Accuracy: 0.822 | Loss: 1.643\n",
      "Test Accuracy: 0.693 | Loss: 1.757\n",
      "\n",
      "Train Accuracy: 0.822 | Loss: 1.643\n",
      "Test Accuracy: 0.076 | Loss: 2.387\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 300 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879ed0d885fa49d1a6c240106a5d135b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=83.4444%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  5\n",
      "Train Accuracy: 0.834 | Loss: 1.630\n",
      "Test Accuracy: 0.339 | Loss: 2.095\n",
      "\n",
      "Train Accuracy: 0.834 | Loss: 1.630\n",
      "Test Accuracy: 0.080 | Loss: 2.384\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 360 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473d481466fc4dfe865133be91e6f8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=81.7000%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  5\n",
      "Train Accuracy: 0.817 | Loss: 1.648\n",
      "Test Accuracy: 0.381 | Loss: 2.051\n",
      "\n",
      "Train Accuracy: 0.817 | Loss: 1.648\n",
      "Test Accuracy: 0.073 | Loss: 2.392\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 420 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553bc1436c154a56bbd396fef84f21f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=85.2587%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  5\n",
      "Train Accuracy: 0.853 | Loss: 1.612\n",
      "Test Accuracy: 0.561 | Loss: 1.877\n",
      "\n",
      "Train Accuracy: 0.853 | Loss: 1.612\n",
      "Test Accuracy: 0.083 | Loss: 2.384\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 480 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecc957c18844a7cae336a69b4427f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=76.4349%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  5\n",
      "Train Accuracy: 0.764 | Loss: 1.701\n",
      "Test Accuracy: 0.003 | Loss: 2.452\n",
      "\n",
      "Train Accuracy: 0.764 | Loss: 1.701\n",
      "Test Accuracy: 0.285 | Loss: 2.185\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 540 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf0496ea9b645d6a50929816b939263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=82.4698%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  5\n",
      "Train Accuracy: 0.825 | Loss: 1.640\n",
      "Test Accuracy: 0.377 | Loss: 2.064\n",
      "\n",
      "Train Accuracy: 0.825 | Loss: 1.640\n",
      "Test Accuracy: 0.248 | Loss: 2.223\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 1000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08e7948f009419f8c158342b9c19882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=79.5889%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  5\n",
      "Train Accuracy: 0.796 | Loss: 1.670\n",
      "Test Accuracy: 0.511 | Loss: 1.930\n",
      "\n",
      "Train Accuracy: 0.796 | Loss: 1.670\n",
      "Test Accuracy: 0.248 | Loss: 2.222\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 2000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d02ac5f45c488199498aa6c0a40285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=69.3349%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  5\n",
      "Train Accuracy: 0.693 | Loss: 1.771\n",
      "Test Accuracy: 0.000 | Loss: 2.458\n",
      "\n",
      "Train Accuracy: 0.693 | Loss: 1.771\n",
      "Test Accuracy: 0.713 | Loss: 1.758\n",
      "\n",
      "From  6  to  4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4d32d86c0f4c30a8a4aa11583946c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 0 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a775233909914f6d85b1d7ab3dd1843f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.0635%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  6\n",
      "Train Accuracy: 0.911 | Loss: 1.551\n",
      "Test Accuracy: 0.983 | Loss: 1.479\n",
      "\n",
      "Train Accuracy: 0.911 | Loss: 1.551\n",
      "Test Accuracy: 0.001 | Loss: 2.459\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 60 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05006ca8400045f58ea6588a874a694e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.1032%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  6\n",
      "Train Accuracy: 0.911 | Loss: 1.551\n",
      "Test Accuracy: 0.979 | Loss: 1.481\n",
      "\n",
      "Train Accuracy: 0.911 | Loss: 1.551\n",
      "Test Accuracy: 0.003 | Loss: 2.458\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 120 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266e0125f29e4956a906cc472574267b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.0095%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  6\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.982 | Loss: 1.480\n",
      "\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.002 | Loss: 2.459\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 180 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d43b61c7c54433b0eb34d8d8c60999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.9381%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  6\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.980 | Loss: 1.481\n",
      "\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.003 | Loss: 2.458\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 240 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9b7e53fb1f494abe94dc76203cbb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8508%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  6\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.980 | Loss: 1.481\n",
      "\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.002 | Loss: 2.458\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 300 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577acd4c7e61448e87ff401730ab6600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8762%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  6\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.980 | Loss: 1.482\n",
      "\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.002 | Loss: 2.458\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 360 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50be35a9d8be44c8babafc2303a7ce1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8587%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  6\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.979 | Loss: 1.482\n",
      "\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.003 | Loss: 2.457\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 420 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70799158e1dd4b7ca9a99b79fdb545ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8349%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  6\n",
      "Train Accuracy: 0.908 | Loss: 1.553\n",
      "Test Accuracy: 0.976 | Loss: 1.484\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.553\n",
      "Test Accuracy: 0.003 | Loss: 2.457\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 480 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc5df74588843329d43af3ec16cf5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8032%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  6\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.980 | Loss: 1.482\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.003 | Loss: 2.457\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 540 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbee895ea344c24bc25ce2eb19c3bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.7921%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  6\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.978 | Loss: 1.483\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.005 | Loss: 2.457\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 1000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5978dc2f368a431db3295d8a79d581e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.7444%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  6\n",
      "Train Accuracy: 0.907 | Loss: 1.554\n",
      "Test Accuracy: 0.974 | Loss: 1.485\n",
      "\n",
      "Train Accuracy: 0.907 | Loss: 1.554\n",
      "Test Accuracy: 0.005 | Loss: 2.456\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 2000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743a10dc9730436cbbd5e32091ea9401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.7032%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  6\n",
      "Train Accuracy: 0.907 | Loss: 1.554\n",
      "Test Accuracy: 0.977 | Loss: 1.484\n",
      "\n",
      "Train Accuracy: 0.907 | Loss: 1.554\n",
      "Test Accuracy: 0.005 | Loss: 2.456\n",
      "\n",
      "From  7  to  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d4eff821104902afe088d6696597b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 0 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02fbb598811413bb91c32b6f37bc892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.0349%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  7\n",
      "Train Accuracy: 0.910 | Loss: 1.551\n",
      "Test Accuracy: 0.964 | Loss: 1.491\n",
      "\n",
      "Train Accuracy: 0.910 | Loss: 1.551\n",
      "Test Accuracy: 0.001 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 60 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5679f362fc74e1d91df66daae4c2fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.0048%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  7\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.953 | Loss: 1.498\n",
      "\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.022 | Loss: 2.443\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 120 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ba5a50eaca415693549c57a183b636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8143%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  7\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.965 | Loss: 1.489\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.000 | Loss: 2.460\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 180 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e838cfc4954dc2aa98e6bac1e54ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=84.0159%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  7\n",
      "Train Accuracy: 0.840 | Loss: 1.622\n",
      "Test Accuracy: 0.845 | Loss: 1.584\n",
      "\n",
      "Train Accuracy: 0.840 | Loss: 1.622\n",
      "Test Accuracy: 0.076 | Loss: 2.398\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 240 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde2ef7383624f2cb5ed9e9200cfe4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.7921%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  7\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.970 | Loss: 1.485\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.002 | Loss: 2.459\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 300 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a8326504034864b6f239ababfbb959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.8095%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  7\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.974 | Loss: 1.483\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.002 | Loss: 2.459\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 360 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bd4c2d5c654426b7265e1e894a0909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=85.3016%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  7\n",
      "Train Accuracy: 0.853 | Loss: 1.610\n",
      "Test Accuracy: 0.896 | Loss: 1.547\n",
      "\n",
      "Train Accuracy: 0.853 | Loss: 1.610\n",
      "Test Accuracy: 0.049 | Loss: 2.417\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 420 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58097f64d9c34555b5d5b4660f919478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=79.6476%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  7\n",
      "Train Accuracy: 0.796 | Loss: 1.666\n",
      "Test Accuracy: 0.809 | Loss: 1.614\n",
      "\n",
      "Train Accuracy: 0.796 | Loss: 1.666\n",
      "Test Accuracy: 0.115 | Loss: 2.363\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 480 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be8ce1cc68f4ba2bc3c1d3e6dbace34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.4159%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  7\n",
      "Train Accuracy: 0.904 | Loss: 1.558\n",
      "Test Accuracy: 0.973 | Loss: 1.483\n",
      "\n",
      "Train Accuracy: 0.904 | Loss: 1.558\n",
      "Test Accuracy: 0.002 | Loss: 2.459\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 540 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e39d4d3f2f42eaa400ce6e7b04ac58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.5873%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  7\n",
      "Train Accuracy: 0.906 | Loss: 1.556\n",
      "Test Accuracy: 0.973 | Loss: 1.482\n",
      "\n",
      "Train Accuracy: 0.906 | Loss: 1.556\n",
      "Test Accuracy: 0.002 | Loss: 2.459\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 1000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0785d5f411e4cdbae14e182a05ee305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=81.9397%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  7\n",
      "Train Accuracy: 0.819 | Loss: 1.643\n",
      "Test Accuracy: 0.070 | Loss: 2.384\n",
      "\n",
      "Train Accuracy: 0.819 | Loss: 1.643\n",
      "Test Accuracy: 0.929 | Loss: 1.531\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 2000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03526d762aa494fbbb3d35f180d1e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=77.0905%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  7\n",
      "Train Accuracy: 0.771 | Loss: 1.691\n",
      "Test Accuracy: 0.002 | Loss: 2.459\n",
      "\n",
      "Train Accuracy: 0.771 | Loss: 1.691\n",
      "Test Accuracy: 0.997 | Loss: 1.464\n",
      "\n",
      "From  8  to  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6bb2827f8b45f9a5d4ccab06c39af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 0 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174300b1903d4223a6fe9e66d4ecf820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.9778%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  8\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.961 | Loss: 1.500\n",
      "\n",
      "Train Accuracy: 0.910 | Loss: 1.552\n",
      "Test Accuracy: 0.008 | Loss: 2.453\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 60 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05ed85a7f964510a4e3aab245743b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.9032%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  8\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.934 | Loss: 1.527\n",
      "\n",
      "Train Accuracy: 0.909 | Loss: 1.553\n",
      "Test Accuracy: 0.006 | Loss: 2.453\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 120 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fff80d562fa4796855914f98366ce13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=78.3111%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  8\n",
      "Train Accuracy: 0.783 | Loss: 1.683\n",
      "Test Accuracy: 0.548 | Loss: 1.916\n",
      "\n",
      "Train Accuracy: 0.783 | Loss: 1.683\n",
      "Test Accuracy: 0.265 | Loss: 2.186\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 180 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f63eb4c6514688b0074f75879e7302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.7540%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  8\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.955 | Loss: 1.505\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.017 | Loss: 2.444\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 240 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a00aa8d81b40db862c03ea210855b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=75.0254%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  8\n",
      "Train Accuracy: 0.750 | Loss: 1.715\n",
      "Test Accuracy: 0.482 | Loss: 1.981\n",
      "\n",
      "Train Accuracy: 0.750 | Loss: 1.715\n",
      "Test Accuracy: 0.386 | Loss: 2.067\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 300 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8529afeafc6247ccb7d8f58ba2b7dfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.7794%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  8\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.958 | Loss: 1.502\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.016 | Loss: 2.445\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 360 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b2f6fc0ad84449bec9b3049dd87453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.6127%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  8\n",
      "Train Accuracy: 0.906 | Loss: 1.556\n",
      "Test Accuracy: 0.968 | Loss: 1.492\n",
      "\n",
      "Train Accuracy: 0.906 | Loss: 1.556\n",
      "Test Accuracy: 0.011 | Loss: 2.450\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 420 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ca6d3e22554924b145c1ad3222272f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=60.5714%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  8\n",
      "Train Accuracy: 0.606 | Loss: 1.863\n",
      "Test Accuracy: 0.005 | Loss: 2.454\n",
      "\n",
      "Train Accuracy: 0.606 | Loss: 1.863\n",
      "Test Accuracy: 0.739 | Loss: 1.716\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 480 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792def38babc41fa89c9fca4aba451bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.0524%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  8\n",
      "Train Accuracy: 0.901 | Loss: 1.561\n",
      "Test Accuracy: 0.965 | Loss: 1.495\n",
      "\n",
      "Train Accuracy: 0.901 | Loss: 1.561\n",
      "Test Accuracy: 0.009 | Loss: 2.452\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 540 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e78ad7ea68472d83a0c48d970b9486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=69.4556%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  8\n",
      "Train Accuracy: 0.695 | Loss: 1.774\n",
      "Test Accuracy: 0.138 | Loss: 2.315\n",
      "\n",
      "Train Accuracy: 0.695 | Loss: 1.774\n",
      "Test Accuracy: 0.689 | Loss: 1.768\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 1000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437566943cc54e5b8f7d949f9e9926e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=79.3810%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  8\n",
      "Train Accuracy: 0.794 | Loss: 1.670\n",
      "Test Accuracy: 0.000 | Loss: 2.461\n",
      "\n",
      "Train Accuracy: 0.794 | Loss: 1.670\n",
      "Test Accuracy: 0.992 | Loss: 1.470\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 2000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce492ca4b1464d1bb2d2910ad8556a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=75.0730%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  8\n",
      "Train Accuracy: 0.751 | Loss: 1.712\n",
      "Test Accuracy: 0.000 | Loss: 2.461\n",
      "\n",
      "Train Accuracy: 0.751 | Loss: 1.712\n",
      "Test Accuracy: 1.000 | Loss: 1.461\n",
      "\n",
      "From  9  to  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdcd51117a4489f9d3b6e94be7c2889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 0 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21055f57109242c4b720c1e04942ff6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=91.3111%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  9\n",
      "Train Accuracy: 0.913 | Loss: 1.549\n",
      "Test Accuracy: 0.956 | Loss: 1.506\n",
      "\n",
      "Train Accuracy: 0.913 | Loss: 1.549\n",
      "Test Accuracy: 0.004 | Loss: 2.456\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 60 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fc4f1e197447f4a0ddae2dd37208c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=90.7825%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  9\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.950 | Loss: 1.511\n",
      "\n",
      "Train Accuracy: 0.908 | Loss: 1.554\n",
      "Test Accuracy: 0.010 | Loss: 2.450\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 120 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3572ff020864c008513c07fcd72e788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=86.2762%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  9\n",
      "Train Accuracy: 0.863 | Loss: 1.599\n",
      "Test Accuracy: 0.941 | Loss: 1.521\n",
      "\n",
      "Train Accuracy: 0.863 | Loss: 1.599\n",
      "Test Accuracy: 0.010 | Loss: 2.449\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 180 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d62a45bb50e40719e7bf24c9896f38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=88.1587%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  9\n",
      "Train Accuracy: 0.882 | Loss: 1.580\n",
      "Test Accuracy: 0.921 | Loss: 1.541\n",
      "\n",
      "Train Accuracy: 0.882 | Loss: 1.580\n",
      "Test Accuracy: 0.013 | Loss: 2.448\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 240 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be19aa0b5f834afeaa5accafa5ac0d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=83.5095%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  9\n",
      "Train Accuracy: 0.835 | Loss: 1.626\n",
      "Test Accuracy: 0.910 | Loss: 1.553\n",
      "\n",
      "Train Accuracy: 0.835 | Loss: 1.626\n",
      "Test Accuracy: 0.015 | Loss: 2.444\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 300 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c10bea056da405a8b03e9c0f105274d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=75.6762%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  9\n",
      "Train Accuracy: 0.757 | Loss: 1.702\n",
      "Test Accuracy: 0.867 | Loss: 1.591\n",
      "\n",
      "Train Accuracy: 0.757 | Loss: 1.702\n",
      "Test Accuracy: 0.020 | Loss: 2.441\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 360 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b513d29ff4f94332821f9fcd37f27966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=82.5651%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  9\n",
      "Train Accuracy: 0.826 | Loss: 1.635\n",
      "Test Accuracy: 0.862 | Loss: 1.599\n",
      "\n",
      "Train Accuracy: 0.826 | Loss: 1.635\n",
      "Test Accuracy: 0.033 | Loss: 2.425\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 420 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879af48904b34ddf9e4b31e5c31c8dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=84.5254%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  9\n",
      "Train Accuracy: 0.845 | Loss: 1.617\n",
      "Test Accuracy: 0.907 | Loss: 1.553\n",
      "\n",
      "Train Accuracy: 0.845 | Loss: 1.617\n",
      "Test Accuracy: 0.035 | Loss: 2.424\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 480 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0ae6f276d3400a8b50e02c624cbfba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=76.2762%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  9\n",
      "Train Accuracy: 0.763 | Loss: 1.699\n",
      "Test Accuracy: 0.824 | Loss: 1.638\n",
      "\n",
      "Train Accuracy: 0.763 | Loss: 1.699\n",
      "Test Accuracy: 0.027 | Loss: 2.431\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 540 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027a2cdf97f1420282cac63895636f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=68.5698%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  9\n",
      "Train Accuracy: 0.686 | Loss: 1.772\n",
      "Test Accuracy: 0.755 | Loss: 1.707\n",
      "\n",
      "Train Accuracy: 0.686 | Loss: 1.772\n",
      "Test Accuracy: 0.160 | Loss: 2.297\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 1000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6cb638f71a649fdb0070b91f2a8af9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=58.8587%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  9\n",
      "Train Accuracy: 0.589 | Loss: 1.868\n",
      "Test Accuracy: 0.359 | Loss: 2.091\n",
      "\n",
      "Train Accuracy: 0.589 | Loss: 1.868\n",
      "Test Accuracy: 0.595 | Loss: 1.869\n",
      "\n",
      "================================================================================\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"split_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_start_model (Model)    (None, 28, 28, 33)        330       \n",
      "_________________________________________________________________\n",
      "split_middle_model (Model)   (None, 28, 28, 33)        78672     \n",
      "_________________________________________________________________\n",
      "split_end_model (Model)      (None, 10)                712700    \n",
      "=================================================================\n",
      "Total params: 791,702\n",
      "Trainable params: 791,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "For experiment fgsm-Inf-checkpoints:\n",
      "Restored latest checkpoint from fgsm-Inf-checkpoints\\it_32\\blackbox_checkpoint\n",
      "Restored c_G to latest checkpoint from fgsm-Inf-checkpoints\\it_32\\c_generator_checkpoint\n",
      "Attacking 2000 batches for every 20 normal batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e258680abf49cd8ba61ce5c7494adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc=56.6016%\n",
      "accuracy of blackbox on G dataset: 0.0000%\n",
      "Saved checkpoint: checkpoints\\it_41\\blackbox_checkpoint\\ckpt-1\n",
      "Saved checkpoint: checkpoints\\it_41\\split_start_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_middle_model_checkpoint\\checkpoint\n",
      "Saved checkpoint: checkpoints\\it_41\\split_end_model_checkpoint\\checkpoint\n",
      "\n",
      "Evaluating accuracy on input  9\n",
      "Train Accuracy: 0.566 | Loss: 1.891\n",
      "Test Accuracy: 0.308 | Loss: 2.146\n",
      "\n",
      "Train Accuracy: 0.566 | Loss: 1.891\n",
      "Test Accuracy: 0.639 | Loss: 1.817\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter Training Set to certain classes\n",
    "def filter_train(input_data, training_classes_to_keep):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(len(input_data[1])):\n",
    "        if (input_data[1][i][0] in training_classes_to_keep):\n",
    "            images.append(input_data[0][i])\n",
    "            labels.append(input_data[1][i])\n",
    "    return (images, labels)\n",
    "\n",
    "train_set_filtered = filter_train(split_train_dataset, training_classes_to_keep)\n",
    "\n",
    "# Train and Test\n",
    "\n",
    "attack_pairs = [\n",
    "    (0, 8), (1, 7), (2, 5), (3, 9), (4, 6), (5, 2), (6, 4), (7, 1), (8, 0), (9, 3)\n",
    "]\n",
    "attack_metrics = {}\n",
    "\n",
    "for attack_pair in tqdm_notebook(attack_pairs):\n",
    "    \n",
    "    flip_from = attack_pair[0]\n",
    "    flip_to = attack_pair[1]\n",
    "    print('From  {}  to  {}'.format(flip_from, flip_to))\n",
    "    \n",
    "    # generate test set to compare with later\n",
    "    test_set_flipped = filter_dataset(split_test_dataset, flip_from, flip_to)\n",
    "\n",
    "    fail_test_accs, fail_test_losses = [], []\n",
    "    succ_test_accs, succ_test_losses = [], []\n",
    "    other_class_accs = []\n",
    "\n",
    "    for attack_clients in tqdm_notebook(attack_params['attack_clients_list']):\n",
    "\n",
    "        # restore networks to their original values:\n",
    "        print('='*80)\n",
    "        #########################################################################\n",
    "        checkpoint_folder = 'fgsm-Inf-checkpoints'\n",
    "        restore_system(checkpoint_folder)\n",
    "        #########################################################################\n",
    "\n",
    "        restore_system(checkpoint_folder)\n",
    "        normal_batches = split_training_params['apply_gradients_after']\n",
    "        print('Attacking {} batches for every {} normal batches'.format(attack_clients * split_training_params['apply_gradients_after'], normal_batches))\n",
    "\n",
    "        compromised_datasets = []\n",
    "        comp_d = generate_compromised_dataset(g, flip_from, flip_to, attack_train_dataset, noise_dim, \n",
    "                                              images_per_batch=batch_average)\n",
    "        compromised_datasets.append(comp_d)\n",
    "\n",
    "        split.train([split_train_dataset, attack_train_dataset], i, \n",
    "                    batch_limit=split_training_params['batch_limit'],\n",
    "                    attack_datasets=compromised_datasets,\n",
    "                    attack_clients=attack_clients * split_training_params['apply_gradients_after'])\n",
    "\n",
    "        print()\n",
    "        other_class_acc = []\n",
    "        for i in range(10):\n",
    "            if i == flip_from:\n",
    "                print(\"Evaluating accuracy on input \", i)\n",
    "                fail_test_acc, fail_test_loss = split.evaluate(test_dataset_individual[i], verbose=True)\n",
    "                fail_test_accs.append(fail_test_acc)\n",
    "                fail_test_losses.append(fail_test_loss)\n",
    "            else:\n",
    "                test_acc, _ = split.evaluate(test_dataset_individual[i], verbose=False)\n",
    "                other_class_acc.append(test_acc)\n",
    "        other_class_accs.append(np.mean(other_class_acc))\n",
    "        \n",
    "        succ_test_acc, succ_test_loss = split.evaluate(test_set_flipped, verbose=True)\n",
    "        succ_test_accs.append(succ_test_acc)\n",
    "        succ_test_losses.append(succ_test_loss)\n",
    "        \n",
    "    attack_metrics['{}to{}'.format(flip_from, flip_to)] = {\n",
    "        'fail_test_accs': fail_test_accs,\n",
    "        'fail_test_losses': fail_test_losses,\n",
    "        'succ_test_accs': succ_test_accs,\n",
    "        'succ_test_losses': succ_test_losses,\n",
    "        'other_class_accs': other_class_accs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0to8\n",
      "1to7\n",
      "2to5\n",
      "3to9\n",
      "4to6\n",
      "5to2\n",
      "6to4\n",
      "7to1\n",
      "8to0\n",
      "9to3\n"
     ]
    }
   ],
   "source": [
    "# average out all of the metrics:\n",
    "\n",
    "avg_fail_test_accs = None\n",
    "avg_fail_test_losses = None\n",
    "avg_succ_test_accs = None\n",
    "avg_succ_test_losses = None\n",
    "avg_other_class_accs = None\n",
    "\n",
    "for key in attack_metrics:\n",
    "    print(key)\n",
    "    if avg_fail_test_accs is None:\n",
    "        avg_fail_test_accs = np.array(attack_metrics[key]['fail_test_accs'])\n",
    "        avg_fail_test_accs = np.expand_dims(avg_fail_test_accs, axis=-1)\n",
    "        \n",
    "        avg_fail_test_losses = np.array(attack_metrics[key]['fail_test_losses'])\n",
    "        avg_fail_test_losses = np.expand_dims(avg_fail_test_losses, axis=-1)\n",
    "        \n",
    "        avg_succ_test_accs = np.array(attack_metrics[key]['succ_test_accs'])\n",
    "        avg_succ_test_accs = np.expand_dims(avg_succ_test_accs, axis=-1)\n",
    "        \n",
    "        avg_succ_test_losses = np.array(attack_metrics[key]['succ_test_losses'])\n",
    "        avg_succ_test_losses = np.expand_dims(avg_succ_test_losses, axis=-1)\n",
    "        \n",
    "        avg_other_class_accs = np.array(attack_metrics[key]['other_class_accs'])\n",
    "        avg_other_class_accs = np.expand_dims(avg_other_class_accs, axis=-1)\n",
    "        \n",
    "    else:\n",
    "        avg_fail_test_accs = np.concatenate((avg_fail_test_accs, np.array([x for x in attack_metrics[key]['fail_test_accs']])[:, np.newaxis]), axis=1)\n",
    "        avg_fail_test_losses = np.concatenate((avg_fail_test_losses, np.array([x for x in attack_metrics[key]['fail_test_losses']])[:, np.newaxis]), axis=1)\n",
    "        avg_succ_test_accs = np.concatenate((avg_succ_test_accs, np.array([x for x in attack_metrics[key]['succ_test_accs']])[:, np.newaxis]), axis=1)\n",
    "        avg_succ_test_losses = np.concatenate((avg_succ_test_losses, np.array([x for x in attack_metrics[key]['succ_test_losses']])[:, np.newaxis]), axis=1)\n",
    "        avg_other_class_accs = np.concatenate((avg_other_class_accs, np.array([x for x in attack_metrics[key]['other_class_accs']])[:, np.newaxis]), axis=1)\n",
    "    \n",
    "avg_fail_test_accs = np.mean(avg_fail_test_accs, axis=1)\n",
    "avg_fail_test_losses = np.mean(avg_fail_test_losses, axis=1)\n",
    "avg_succ_test_accs = np.mean(avg_succ_test_accs, axis=1)\n",
    "avg_succ_test_losses = np.mean(avg_succ_test_losses, axis=1)\n",
    "avg_other_class_accs = np.mean(avg_other_class_accs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Attack accuracy for flipping 1s to 7s\")\n",
    "attacks_per_client = attack_params['attack_clients_list']\n",
    "plt.plot(attacks_per_client, attack_metrics['1to7']['fail_test_accs'])\n",
    "plt.plot(attacks_per_client, attack_metrics['1to7']['succ_test_accs'])\n",
    "\n",
    "plt.legend(['1s assigned as 1s', '1s assigned as 7s'])\n",
    "plt.xlabel('Attack batches per client batch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Attack accuracy for flipping targeted class to a desired class\")\n",
    "attacks_per_client = attack_params['attack_clients_list']\n",
    "plt.plot(attacks_per_client, avg_fail_test_accs)\n",
    "plt.plot(attacks_per_client, avg_succ_test_accs)\n",
    "# plt.plot(attacks_per_client, avg_other_class_accs, 'k')\n",
    "\n",
    "plt.legend(['target stays same', 'target flips'])#, 'model accuracy'])\n",
    "plt.xlabel('Attack batches per client batch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.title(\"Attack loss for flipping 1s to 7s\")\n",
    "# attacks_per_client = attack_params['attack_clients_list']\n",
    "# plt.plot(attacks_per_client, fail_test_losses)\n",
    "# plt.plot(attacks_per_client, succ_test_losses)\n",
    "\n",
    "# plt.legend(['1s assigned as 1s', '1s assigned as 7s'])\n",
    "# plt.xlabel('Attack batches per client batch')\n",
    "# plt.ylabel('Loss')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('attack_metrics.pickle', 'wb') as handle:\n",
    "    pickle.dump(attack_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
